date_posted,title,organization,description_text
2025-12-12T18:28:05.616,Sr Staff Engineer Software (Data Plane Applications),Palo Alto Networks,"Company Description
Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
Who We Are
We believe collaboration thrives in person. That’s why most of our teams work from the office full time, with flexibility when it’s needed. This model supports real-time problem-solving, stronger relationships, and the kind of precision that drives great outcomes.
Job Description
Your Career
Prisma Access™ (formally GlobalProtect Cloud Service) provides protection straight from the cloud to make access to the cloud secure. It combines the connectivity and security you need and delivers it everywhere you need it. Using cutting-edge public and private cloud technologies extending the next-generation security protection to all cloud services, customers on-premise remote networks and mobile users.
We are seeking an experienced Software Engineer to design, develop and deliver next-generation technologies within our Prisma Access team. We want passionate engineers who love to code and build great products. Engineers who bring new ideas in all facets of software development. We are looking for leaders who take ownership of their areas of focus and who are driven to solve problems at every level. Collaboration and teamwork are at the foundation of our culture and we need engineers who can communicate at a high level and work well with others towards achieving a common goal.
Your Impact
Design, develop and implement highly scalable software features and infrastructure on our next-generation security platform ready for cloud native deployment from inception to completion
Work with different development and quality assurance groups to achieve the best quality - You accomplish this by being hands-on, creating tools, processes, and systems that produce transparency, alignment, and direction
Profile, optimize and tune systems software (management/control/dataplane) for efficient cloud operation
Work with DevOps and the Technical Support teams to troubleshoot customer issues
Work with other software development team to apply PanOS features on Prisma Access
Interview, mentor and coach new team members 
Qualifications
Your Experience 
5+ years of experience in developing and troubleshooting dataplane applications
Required hands-on programming experience in Python and Go
Nice to have C/C++ Programming
Strong Data structures/Algorithms
Strong analytical skills, problem solving and debugging skills
Nice to have experience with LLMs and GenAI applications. Or Machine learning/Data science with experience in ETL, curating datasets, running evals. 
Experience with building applications in the cloud
In-depth understanding of Operating System principles and OS like Linux/Unix
In-depth understanding of networking concepts and TCP/IP stack, TLS
Exposure to building Microservices 
Enjoys working with many different teams with strong collaboration and communication skills
Solid foundation in design, data structures, and algorithms, and strong analytical and debugging skills
Education : M.S./B.S. degree in Computer Science or equivalent military experience required
Additional Information
The Team
Our engineering team is at the core of our products – connected directly to the mission of preventing cyberattacks. We are constantly innovating – challenging the way we, and the industry, think about cybersecurity. Our engineers don’t shy away from building products to solve problems no one has pursued before.
We define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment.
Compensation Disclosure
The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $170,000 - $190,000/YR. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.
Our Commitment

We’re problem solvers that take risks and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at [email protected].
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
Is role eligible for Immigration Sponsorship?: Yes"
2025-12-12T18:20:27,Data Engineer,Real Chemistry,"At Real Chemistry, making the world a healthier place isn’t just an aspiration—it’s our everyday reality. Our drive to transform healthcare is informed by our blend of deep scientific expertise, human-centred creativity, and AI-driven insights, fostering a unique environment where innovation thrives and our people are impact-obsessed. As a global agency, we provide a full suite of services across healthcare communications and marketing to our clients, including top players in the pharmaceutical and biotech industries.
Our #LifeatRealChem culture is rooted in our people—we believe we are best together and are committed to excellence for both our clients and colleagues. Whether you're a seasoned professional or just starting your career, if you share our passion for healthcare and connection, we invite you to explore our opportunities.
Discover your purpose. Embrace innovation. Experience #LifeatRealChem.
Job Summary 
We’re looking for a hands-on Data Engineer to help build and maintain the data infrastructure that powers our AI products and solutions. This role sits within our AI organization and focuses on designing, developing, and optimizing scalable data pipelines, data models, and cloud-based data systems. You’ll collaborate closely with data scientists, ML engineers, product teams, and other technical partners to ensure high-quality, reliable, and well-structured data is available across the organization. 
Key Responsibilities 
Data Pipeline Development 
Build, optimize, and maintain scalable ETL/ELT pipelines for structured and unstructured data. 
Implement reliable, fault-tolerant ingestion and transformation workflows. 
Automate routine data processes where possible. 
Data Architecture & Modeling 
Develop well-structured data models that support analytics, ML use cases, and downstream applications. 
Support the design and enhancement of AI-related data architecture across cloud environments. 
Data Quality & Governance 
Implement automated data validation, monitoring, and alerting. 
Ensure high data accuracy, completeness, and integrity across ingestion and transformation layers. 
Cross-Functional Collaboration 
Partner with data scientists, ML engineers, product managers, and IT teams to understand data requirements and translate them into technical solutions. 
Troubleshoot issues and support stakeholders with data access and pipeline improvements. 
Cloud & Infrastructure 
Work with modern cloud platforms (AWS, Azure, or GCP) and associated data storage, compute, and orchestration services. 
Support deployment, scaling, and operational health of data systems. 
Innovation & Continuous Improvement 
Stay current with emerging data engineering tools and best practices. 
Propose opportunities to improve performance, efficiency, or reliability within the data stack. 
Qualifications & Skills 
Education & Experience 
Bachelor’s degree in Computer Science, Data Engineering, or related technical field (or equivalent experience). 
3–7 years of hands-on experience in data engineering or data pipeline development. 
Technical Skills 
Strong SQL skills and proficiency in Python or Scala. 
Experience with data warehousing technologies such as Snowflake, BigQuery, Redshift, or Databricks. 
Hands-on experience with cloud services (AWS, Azure, or GCP). 
Knowledge of data modeling, schema design, and ETL/ELT principles. 
Familiarity with distributed computing frameworks such as Spark or Flink. 
Experience with workflow orchestration tools like Airflow, Prefect, or Dagster is a plus. 
Soft Skills 
Strong problem-solving skills and attention to detail. 
Ability to communicate technical concepts clearly to peers and cross-functional partners. 
Comfortable working in a fast-moving, collaborative environment. 
Preferred Qualifications 
Experience with streaming data tools such as Kafka or Kinesis. 
Experience building CI/CD pipelines for data workflows. 
Experience in healthcare, biotech, life sciences, or commercial/marketing data environments. 
Experience in agency or consulting settings. 
Posting Salary
$140,000—$175,000 USD
Real Chemistry is proud to be Great Place to Work® certified; check out what our people shared about our culture and workplace on our Great Places to Work Profile here.
We believe we can do our best when feeling our best, which is why we’ve put together a benefits program designed to give you the support you and your family need at every stage of life. Real Chemistry offers a comprehensive benefit program and perks, tailored to your region. Globally, this includes offices in our key markets with free snacks to keep you running all day long, generous holiday and paid time off, options for private medical, dental, and vison plans, and support in saving for the future. Other perks include mental wellness coaching and support and access to more than 13,000 online classes with LinkedIn Learning. Learn more about our great benefits and perks and search specific offerings in your region at: www.realchemistrybenefits.com.
Working with Real HART: Since the pandemic, we have adapted to how our people told us they want to work. We have office locations in cities in the US, UK, and Europe with many employees and clients that serve as hubs where and when they need us. For employees who are within an hour of one of our offices, we expect attendance in the office two days per week, either at a Real Chemistry office or onsite with clients. We are also actively opening new office locations, so if one opens near you, our Real HART policy will apply. We are not looking for attendance for the sake of attendance but believe that the opportunity to coordinate in-office team meetings, 1:1 meetings with managers, taking advantage of on-site learning, and connecting with client partners is a critical to delivering on our purpose of making healthcare what it should be. Outside of these offices, we have regions, where people work remotely but come together quarterly for collaboration, culture and learning opportunities. We call this our Real Hybrid and Regional Teams (Real HART) approach. Real Chemistry believes we are best together – and our workplace strategy fosters connection and collaboration in person – but also supports flexibility for our people.
Real Chemistry is an Equal Opportunity employer. We continually strive to build and sustain an inclusive and equitable work environment where our employees feel empowered to leverage all they bring from their personal lived experience and professional expertise, to make our team the best in the industry. We encourage motivated and qualified applicants to apply without regard to race, color, religion, sex (including pregnancy), sexual orientation, gender identity/expression, ethnic or national origin, age, physical or mental disability, genetic information, marital information, or any other characteristic protected by federal, state, or local employment discrimination laws where Real Chemistry operates. Should you require accommodations throughout the interview process please let your recruiter know.
*Notice: Real Chemistry and its affiliates' names are being misused by scammers through messaging services, fake websites, and apps. Do not share personal or financial information or make payments to any unverified sources claiming to be connected to Real Chemistry. We are working to stop these unauthorized activities and protect our community. Read more here."
2025-12-12T17:29:23,Senior Python Data Engineer - (Remote)  ,KBRA,"Position Title: Senior Python Data Engineer - (Remote) 
Entity: KBRA Holdings LLC
Employment Type: Full-Time
Location: Remote (Remote only in CA, CO, DC, FL, IL, MD, NJ, MA, NY, PA, SC, TX, VA)
Summary/Overview:
KBRA (KBRA Holdings, LLC) is seeking an engaged and proactive Senior Python Data Engineer to work on our financial analytical system. We want someone who loves solving difficult problems, digs deeply to understand the domain in which they’re working, and excels at creating high-quality software in a collaborative environment.
About the Team:
We believe that small, empowered teams can do amazing things. Across the engineering organization, we work hard to make the best systems for our customers using modern engineering practices. We are intentional in our investments in time and effort around creating a safe and successful workplace for our team members. We understand software engineering goes beyond the 1’s and 0’s and prioritize concrete value for our customers.
About the Job:

This role involves joining an existing team with a well-defined product vision. This team operates collaboratively, and there is an expectation to get involved in all aspects of design, delivery, and support of our systems.

This role emphasizes collaboration with our technical and non-technical counterparts to learn our domain and its unique challenges, while delivering value to our customers. It also requires collaboration with our other engineering, design, product, and platform teams to develop, build, run, and support the system.
About You:

You will be successful in this role if you:
Develop, test, and maintain scalable Python applications.
Collaborate with product managers, designers, and other engineers to deliver high-quality software.
Write clean, efficient, and reusable code following best practices.
Participate in code reviews to ensure code quality and share knowledge with the team.
Troubleshoot and debug issues in a timely manner.
Contribute to the design and architecture of new features and systems.
Have a sense of ownership and craftsmanship around the code base and your work.
Enjoy helping other developers grow and learn new technologies.
Display a strong track record of mentorship with engineers at various levels.
Are mindful of application security and performance.
Take pride in learning, and want opportunities to learn throughout your day-to-day.
Possess a pragmatic mindset. 
Familiarity with Generative AI tools such as ChatGPT for research, data insights, and general productivity is a plus.
Must have skills:
3–6 years of professional software engineering experience, with a strong portfolio of full stack development work.
Proficiency in Python, including experience with web frameworks such as Flask.
Cloud experience, particularly with AWS (Amazon Web Services).
Experience integrating frontend applications with RESTful APIs and backend services.
Relational and non-relational databases (SQL Server, Snowflake and MongoDB).
Debugging, issue resolution, and troubleshooting.
Nice to have skills:
Familiarity with UX design tools (Figma) and solid understanding of the design-engineering hand-off process
Containerized development and deployment (i.e. Docker, Docker swarm, Kubernetes)
Infrastructure as Code (Terraform)
Familiarity with deployment pipelines, CICD tools.
Exposure to financial systems or credit modeling is strongly preferred.
Salary Range:
The anticipated annual base salary range for this full-time position is $130,000 - $160,000. Offer amounts are determined by factors such as experience, skills, geography, and other job-related factors.
Benefits:
Competitive benefits and paid time off
Paid family and disability leave
401(k) plan, including employer match (100% vested)
Educational and professional development financial assistance
Employee referral bonus program
About Us:
KBRA is a full-service credit rating agency registered in the U.S., the EU and the UK, and is designated to provide structured finance ratings in Canada. KBRA’s ratings can be used by investors for regulatory capital purposes in multiple jurisdictions.
More Info:
KBRA encourages applications from all qualified individuals without regard to race, color, religion, gender, sexual orientation, gender identity or expression, age, national origin, marital status, citizenship, disability, and veteran status or any other basis prohibited by federal, state or local law.
#LI-KS1
#REMOTE"
2025-12-12T17:19:54,Data Platform Engineer,Dragonfli Group,"Dragonfli Group is a cybersecurity and IT consulting firm providing services to federal agencies and Fortune 100 enterprises. Headquartered in Washington, DC, Dragonfli supports clients in securing mission-critical systems across on-site, hybrid, and fully remote environments.

This contract Data Platform Engineer role supports a large federal agency in protecting security data platforms within a large-scale IT environment. The engineer will manage security data platforms such as Splunk and data lakes, ensuring effective data flows, integrations, and platform support. Key technologies include Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS. The role requires seasoned IT security expertise, hands-on technical skills, and strong communication and planning abilities. It's a high-impact opportunity to shape security analytics capabilities within a major federal agency.

This is a multi-year contract position involving a large US federal agency. Candidates with previous federal contracting experience are preferred. U.S. Citizenship or Permanent Residency required. If hired, all work related to this role must be performed within the continental U.S.

Responsibilities:
Manage security data platforms, such as Splunk and data lakes.
Ensure effective data flows, integrations, and platform support.
Support event ingestion, platform maintenance, and technical add-ons.
Troubleshoot to support operational and compliance reporting.
Optimize data use for security monitoring, incident response, and threat analysis.
Collaborate across teams to enhance security analytics capabilities.
Configure and maintain various event ingestion methods.
Create and maintain custom TAs for data parsing into Splunk CIM format.
Monitor and perform routine maintenance of data systems.
Drive process improvements and attention to detail.

Requirements
Four (4)+ years of experience supporting enterprise data platforms.
BS/BA in a cyber-related field or equivalent experience/certifications.
Experience with installing, updating, and maintaining ELM and SIEM.
Proficiency with Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS.
Experience configuring and maintaining event ingestion methods.
Ability to create and maintain custom TAs for Splunk.
Experience in troubleshooting, monitoring, and maintaining data systems.
Familiarity with enterprise security operations.
Strong cross-functional communication skills.

Skill(s)
Hands-on management of security data platforms.
Expertise in data flows and platform integrations.
Proficiency in Splunk and related technologies.
Strong troubleshooting and problem-solving skills.
Ability to optimize security monitoring and incident response.
Excellent cross-functional communication abilities.
Attention to detail and process improvement mindset.
Ability to work collaboratively across teams.
Strong planning and organizational skills.

Benefits
Insurance – health, dental, and vision
Paid Time Off (PTO) and 11 Federal Holidays
401(k) employer match

Travel
null"
2025-12-12T16:50:01,Staff Configuration Data Engineer,Archer,"Archer is an aerospace company based in San Jose, California building an all-electric vertical takeoff and landing aircraft with a mission to advance the benefits of sustainable air mobility. We are designing, manufacturing, and operating an all-electric aircraft that can carry four passengers while producing minimal noise.
Our sights are set high and our problems are hard, and we believe that diversity in the workplace is what makes us smarter, drives better insights, and will ultimately lift us all to success. We are dedicated to cultivating an equitable and inclusive environment that embraces our differences, and supports and celebrates all of our team members.
What you'll do:
As the Configuration Data Engineer, you will combine software development expertise with configuration management practices to safeguard product data integrity, traceability, and compliance. You will design tools, reports, and automations that enable engineering and product teams to make faster, more accurate configuration decisions.
Develop and maintain tools and reports to monitor bills of materials (BOMs), effectivity assignments, and configuration changes
Create automated quality checks to validate workflows and ensure compliance with configuration management standards
Integrate with Teamcenter APIs and background services to access, analyze, and validate engineering data
Build automation scripts to support NX, CATIA, and other CAD-driven workflows (NX Open, CATIA VB, Check-Mate, NX Check-Mate)
Support the definition, maintenance, and auditing of BOM structures, unit effectivity, and date-based effectivity for engineering changes
Develop dashboards and metrics reporting to provide visibility into change requests, change notices, and configuration status accounting
Collaborate with configuration management, engineering, and IT teams to streamline data flow across systems
Investigate data anomalies and provide corrective recommendations to maintain design and change integrity
Partner with project teams to ensure effectivity assignments are properly implemented and reflected in reports
Contribute to the improvement of enterprise configuration management processes through data-driven insights
Serve as a technical resource to CM specialists for reporting, automation, and API usage
What You Need
To be a self starter with a strong desire to learn new technologies
Ability to translate engineering/CM requirements into automated solutions
2+ years of experience developing tools and reports for a Product Lifecycle Management (PLM) tools (e.g., Teamcenter, Windchill, Enovia, 3DX) or equivalent engineering data environments
Experience with relational databases (SQL, PostgreSQL, Oracle) for reporting and automation
Ability to interpret engineering drawings, CAD data, and metadata
Understanding of BOM structures, unit effectivity, and date-based effectivity methods
Familiarity with engineering change processes, including Change Requests (CRs) and Change Notices (CNs)
Experience with scripting or automation in CAD/PLM environments (NX Open, CATIA VB, or similar)
Strong problem-solving skills and ability to analyze complex datasets for process improvements
Effective written communication skills to document procedures and produce clear reports
Ability to work in a collaborative environment across engineering, CM, and IT teams
Bonus Qualifications
Hands-on experience with Siemens Teamcenter APIs or integrations
Experience with Business Intelligence tools such as Power BI, Sigma, or SAP Hana
Experience with ITI CADIQ tools and CAD data validation workflows
Experience with Elysium CAD Translation tools
Familiarity with NX Check-Mate and automations
Familiarity with ASME Y14.5 Dimensioning and Tolerancing
Experience developing Adobe Forms with JavaScript and PDF publishing workflows
Exposure to aerospace, automotive, or other complex product development environments
Knowledge of configuration management standards and compliance practices (CMII, EIA-649, etc.)
This role is ideal for engineers who enjoy bridging software development with product lifecycle control. You will directly impact how engineering data is managed, ensuring accuracy, efficiency, and compliance across the enterprise
Archer is committed to working with and providing reasonable accommodations to job applicants with physical or mental disabilities, and those with sincerely held religious beliefs. Applicants who may require reasonable accommodation for any part of the application or hiring process should provide their name and contact information to Archer’s People Team at people@archer.com. Reasonable accommodations will be determined on a case-by-case basis.
Information collected and processed as part of any job applications you choose to submit is subject to Archer's Candidate Privacy Policy.
Archer is unable to provide work visa sponsorship for this position at the present time.
Archer is proud to be an Equal Opportunity employer committed to diversity and inclusivity in the workplace. All aspects of employment are decided on the basis of merit, qualifications, and business needs. We do not discriminate based upon race, color, religion, sex, sexual orientation, age, national origin, disability status, protected veteran status, gender identity or any other characteristic protected by federal, state or local laws.
Archer Aviation does not engage with external recruiting agencies/individual recruiters with whom it does not have a prior written agreement. Archer reserves the right to make use of any unsolicited resumes that it receives and bears no responsibility for payment of any fees asserted from the use of unsolicited resumes. If you are a recruiting agency or individual recruiter wishing to do business with Archer, please reach out to People@archer.com. All employment processes are managed by the Archer People Team."
2025-12-12T16:14:31,Data Engineer - Integrated Supply Chain,Textron,"Data Engineers build and maintain data systems in support of data analytics and data science activities. The Data Engineer will implement methods to improve data reliability, data quality, and ensure success in data-driven initiatives.
This position within Integrated Supply Chain Analytics is responsible for identifying, developing, and executing solutions that support reliable and efficient extraction of data from source systems and loading of that data into analytic platforms. The Data Engineer will help administer data platforms and consult with data analysts and data scientists on process optimization and data quality improvements.
At Textron Aviation, we are building a community of Data & Analytics professionals with an emphasis on collaboration and cross functional support. You will have the opportunity to work closely with your peers throughout the organization toward a vision of data driven strategy.


JOB RESPONSIBILITIES:
· Gain core business understanding of Textron Aviation and aircraft design, operation, and support
· Query, clean, transform, and stage data (ETL/ELT) across on-prem and cloud environments
· Support data analytics and data science activities by implementing, maintaining, and optimizing production ready data pipelines
· Install and update software to ensure data platform continuity
· Administer a CI/CD compliant code repository during development and update activities
· Research and help implement new technologies to support analytics function
· Interface with other data professionals throughout the organization to embrace cross functional growth in analytics capabilities
· Work to improve data quality by assisting data governance efforts in creating and maintaining data quality standards
· Plan and execute projects according to established milestones and schedules
· Train users in data & analytic tools and processes per best practices and compliance standards
· Contribute to the resolution of service tickets pertaining to data infrastructure
· Serve as an internal consultant to business leaders by advising on system capabilities
EDUCATION/ EXPERIENCE:
· Bachelor’s degree in Computer Science, Software Engineering, Data Science/Analytics, MIS, or other related technical field
· Minimum 2 years relevant technical experience required, focused on data collection, utilization, and analysis.
· Aviation experience preferred
Textron Aviation Inc. must comply with U.S export control laws and regulations. If a position requires access to sensitive information controlled under these laws and regulations, a successful applicant must be eligible to meet any requirements to access controlled information."
2025-12-12T16:07:56,Senior Data Engineer ,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:55,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:54,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T15:01:13.806,"Software Engineer III, Infrastructure, Audience Data Processing",Google,"MINIMUM QUALIFICATIONS:

 * Bachelor’s degree or equivalent practical experience.
   
 * 2 years of experience with software development in C++, SQL, Borg, Flume, or
   1 year of experience with an advanced degree.
 * 2 years of experience with developing large-scale infrastructure, distributed
   systems or networks, or experience with compute technologies, storage or
   hardware architecture.



PREFERRED QUALIFICATIONS:

 * Master's degree or PhD in Computer Science or related technical fields.
   
 * 2 years of experience with data structures and algorithms.
 * Experience with Flume and large scale data processing pipelines.
 * Experience developing accessible technologies.
   


ABOUT THE JOB:

Google's software engineers develop the next-generation technologies that change
how billions of users connect, explore, and interact with information and one
another. Our products need to handle information at massive scale, and extend
well beyond web search. We're looking for engineers who bring fresh ideas from
all areas, including information retrieval, distributed computing, large-scale
system design, networking and data storage, security, artificial intelligence,
natural language processing, UI design and mobile; the list goes on and is
growing every day. As a software engineer, you will work on a specific project
critical to Google’s needs with opportunities to switch teams and projects as
you and our fast-paced business grow and evolve. We need our engineers to be
versatile, display leadership qualities and be enthusiastic to take on new
problems across the full-stack as we continue to push technology forward.

As a Software Engineer on the Audience Data Processing Infrastructure team, you
will innovate and optimize planet-scale data processing flows to support Google
Ads.

While we're an infrastructure team, we operate in a fast-paced environment with
evolving requirements. Our focus is on supporting client data processing needs,
enhancing operational excellence and developer velocity, and significantly
improving resource efficiency.


Google Ads is helping power the open internet with the best technology that
connects and creates value for people, publishers, advertisers, and Google.
We’re made up of multiple teams, building Google’s Advertising products
including search, display, shopping, travel and video advertising, as well as
analytics. Our teams create trusted experiences between people and businesses
with useful ads. We help grow businesses of all sizes from small businesses, to
large brands, to YouTube creators, with effective advertiser tools that deliver
measurable results. We also enable Google to engage with customers at scale.

The US base salary range for this full-time position is $141,000-$202,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Write product or system development code in C++ for infrastructure
   responsible for managing and optimizing processing of planet-scale data
   processing.
 * Investigate data storage and processing use cases, techniques, and
   identifying opportunities for future innovation.
 * Review code developed by other developers and provide feedback to ensure best
   practices (e.g., style guidelines, checking code in, accuracy, testability,
   and efficiency).
 * Contribute to existing documentation or educational content and adapt content
   based on product/program updates and user feedback.
 * Triage product or system issues and debug/track/resolve by analyzing the
   sources of issues and the impact on hardware, network, or service operations
   and quality."
2025-12-12T13:26:27,Cleared On Site Data Engineer (4899),SMX,"SMX is seeking a Senior Data Architect to provide strategic and technical leadership for enterprise data architecture and analytics modernization efforts. This individual will design, optimize, and oversee data solutions that enable advanced analytics, business intelligence, and reporting capabilities across multiple secure environments. This role will focus on designing, developing, optimizing, and maintaining data pipelines and backend data engineering solutions that power critical analytical products used by senior FBI leadership. The ideal candidate brings deep technical expertise in ETL processes, SQL, Python, AWS data services, and enterprise-scale data warehousing, with strong familiarity in BI ecosystems such as MicroStrategy (Strategy), ThoughtSpot, and related tools used within the HR Reports program. The position requires close collaboration with government leads, senior data developers, BI engineers, and cross-functional analytics teams to ensure high reliability, performance, and security of data products supporting mission-critical operations. 
This is a full-time position requiring on-site work five days a week at a client’s office in Washington, D.C. An active Top Secret clearance is mandatory.
Essential Duties and Responsibilities: 
Design, build, and maintain scalable, secure ETL/ELT pipelines supporting HR Reports analytics and dashboard products.
Develop and optimize SQL-based transformations, stored procedures, and data models for high-volume enterprise datasets.
Implement data orchestration workflows using AWS services (e.g., Glue, Lambda, Step Functions, CloudWatch).
Ensure data quality, lineage, and integrity across multiple enterprise data sources.
Support and enhance cloud-based warehouse environments within AWS (e.g., Redshift, S3, IAM).
Collaborate with BI developers to ensure backend data structures meet MicroStrategy/Strategy and ThoughtSpot reporting needs.
Troubleshoot complex data pipeline or performance issues and implement long-term remediation solutions.
Translate government stakeholder requirements into technical specifications for new data sources and pipelines.
Partner with Data Analysts, Data Scientists, and BI Developers to support advanced analytics and ad-hoc data requests.
Apply data governance, security, and compliance best practices in alignment with FBI and SMX standards.
Recommend and implement improvements to automation, data architecture, pipeline reliability, and overall performance.
Maintain documentation for pipelines, logic, data flows, and system dependencies.
Stay current with modern data engineering practices and AWS service enhancements relevant to pipeline automation and warehousing.
Required Skills: 
10+ years of experience in data architecture, data warehousing, or enterprise analytics systems.
Expert-level proficiency in SQL and data modeling
Hands-on experience designing and implementing ETL/ELT frameworks (e.g., Apache Airflow, dbt, AWS Glue, Informatica).
Demonstrated success architecting and optimizing large-scale BI/reporting solutions (MicroStrategy, ThoughtSpot, Power BI, Tableau).
Strong knowledge of AWS data ecosystem (Redshift, Athena, S3, Glue, Lambda) or similar cloud environments.
Experience defining and enforcing data governance, quality, and security standards.
Ability to design and document end-to-end data flows and integrations between transactional and analytical systems.
Excellent communication, analytical, and problem-solving skills.
Desired Skills/Experience:
Bachelor’s or Master’s degree in Computer Science, Information Systems, Data Engineering, or related technical field.
10+ years of experience in data engineering, backend data development, or enterprise-scale ETL development.
Experience supporting federal government IT systems or analytics programs.
Familiarity with Agile methodologies and Jira-based workload management.
Experience supporting or modernizing enterprise BI ecosystems.
**This position requires five days a week on site at customer location in Washington DC.
Application deadline 1-16-2026
#LI-SA
#cjpost
The SMX salary determination process takes into account a number of factors, including but not limited to, geographic location, Federal Government contract labor categories, relevant prior work experience, specific skills, education and certifications. At SMX, one of our Core Values is to Invest in Our People so we offer a competitive mix of compensation, learning & development opportunities, and benefits. Some key components of our robust benefits include health insurance, paid leave, and retirement.
The proposed salary for this position is:
$114,600—$192,500 USD
At SMX®, we are a team of technical and domain experts dedicated to enabling your mission. From priority national security initiatives for the DoD to highly assured and compliant solutions for healthcare, we understand that digital transformation is key to your future success.
We share your vision for the future and strive to accelerate your impact on the world. We bring both cutting edge technology and an expansive view of what’s possible to every engagement. Our delivery model and unique approaches harness our deep technical and domain knowledge, providing forward-looking insights and practical solutions to power secure mission acceleration.
SMX is an Equal Opportunity employer including disabilities and veterans.
Selected applicant may be subject to a background investigation and/or education verification.
SMX does not sponsor a new applicant for employment authorization or immigration related support for this position (i.e. H1B, F-1 OPT, F-1 STEM OPT, F-1 CPT, J-1, TN, E-2, E-3, L-1 and O-1, or any EADs or other forms of work authorization that require immigration support from an employer)."
2025-12-12T12:29:19.508,"Data Center Plant Engineer, Mechanical, Electrical",Google,"MINIMUM QUALIFICATIONS:

 * Associate's degree, trade school certification, or other certified training
   in a related technical field, or equivalent practical experience.
 * 7 years of experience in electrical, mechanical/HVAC, or controls/automation
   experience in an industrial or commercial environment.



PREFERRED QUALIFICATIONS:

 * Experience working in data centers, hospitals, or power plants.
 * Knowledge of electrical and mechanical systems used in a data center
   environment (e.g., Feeders, Transformers, Generators, Switchgear, UPS
   systems, ATS/STS units, PDU/PMM units, Chillers, Air handling units, and CRAC
   units).
   
 * Knowledge of meters, devices, sensors, and troubleshooting utilizing standard
   hand tools, digital metering, or calibration/diagnostic equipment.
   
 * Ability to communicate with contractors who perform maintenance or upgrade
   work on the data center systems.
   


ABOUT THE JOB:

The Data Center team designs and operates some of the most sophisticated
electrical engineering, mechanical engineering and HVAC systems in the world.
Facilities Technicians at Google data centers operate, monitor and support
physical facilities conditions. Some of these duties will include heating and
cooling of air and water, power supply, generators, UPS systems, electrical
distribution and control and monitoring systems. You regularly help inspect,
maintain and repair various data center systems such as piping and non-critical
electrical or mechanical system components). You provide daily assistance to
senior technicians as you read blueprints/schematics, conduct tours of systems
and assess their working order.

As a master of exceptional practices, you develop creative approaches to
reducing operational costs while improving overall data center efficiency. You
ensure that environmental and safety standards are consistently met, identifying
problems and making repairs quickly In emergency situations or abnormal
conditions, you manage data center performance issues and outages to minimize
the recovery time from failures.The AI and Infrastructure team is redefining
what’s possible. We empower Google customers with breakthrough capabilities and
insights by delivering AI and Infrastructure at unparalleled scale, efficiency,
reliability and velocity. Our customers include Googlers, Google Cloud
customers, and billions of Google users worldwide.

We're the driving force behind Google's groundbreaking innovations, empowering
the development of our cutting-edge AI models, delivering unparalleled computing
power to global services, and providing the essential platforms that enable
developers to build the future. From software to hardware our teams are shaping
the future of world-leading hyperscale computing, with key teams working on the
development of our TPUs, Vertex AI for Google Cloud, Google Global Networking,
Data Center operations, systems research, and much more.

The US base salary range for this full-time position is $105,000-$151,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Inspect, maintain, and repair various data center systems such as piping and
   non-critical electrical or mechanical system components.
   
 * Provide daily assistance to technicians as you read blueprints/schematics,
   conduct tours of systems, and assess their working order.
   
 * Manage the uptime and maintenance of water pumps and treatment systems, HVAC,
   UPS, generators, electrical distribution, and control and monitoring systems.
   
 * Operate, monitor, maintain, and respond to abnormal conditions in the data
   center facilities systems and equipment.
   
 * Support startup, commissioning, and integration of new equipment and systems
   into facilities infrastructure.
   "
2025-12-12T09:01:55.769,Data Engineer II,Microsoft,"Overview
With continued growth in digital data and the desire to leverage data to measure in-production quality and address problems that touch all aspects of our lives, Microsoft’s Windows Servicing & Delivery Org is looking for an equally data- and quality-minded engineer to meet these challenges! Join the Update Platform team for the chance to have an impact on billions of customers every day. The Update Platform Team is responsible for ensuring the seamless delivery and integration of software updates and keeping our customers up-to-date and secure at all times.
As a Data Engineer II member of the Update Platform Insights team, you will be at the forefront of leveraging data to assess the quality of the product, detect issues before they reach broad customer application to assure top product quality for partners and customers alike while keeping billions of devices secure and up-2-date.

In this exciting role, you'll work with a diverse group of talented professionals, innovate for greater platform efficiency as well as leveraging the latest technologies and best practices to streamline our update processes with timely in-depth insights and intelligent features.

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.


Responsibilities
Data Management and Transformation: With guidance, you will apply modification techniques to transform raw data into compatible formats for downstream systems. Utilize software and computing tools to ensure data quality and completeness. Implement code to extract and validate raw data from upstream sources, ensuring accuracy and reliability.
Drive Customer Success: Through Data and Business Insight: You will play a pivotal role in building a metrics-driven culture that directly impacts product quality and customer outcomes. This role goes beyond technical execution—you will design and implement measurement frameworks from the ground up while applying a strategic, top-down perspective to ensure the right metrics are in place. Your ability to translate data into actionable insights, aligned with business priorities and rhythm of business, will enable informed decisions that drive high-quality product outcomes and measurable customer success.

Data Requirements and Modeling: Collaborate with stakeholders to document and understand data requirements. Evaluate project plans to assess data costs, access, and availability. Draft design specifications to model data flow and storage, ensuring data is easy to connect and manage.
Compliance: You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams. You’ll also learn about permissions and approvals for data access within a data pipeline.

Validation and Quality Mindset: Apply and use operational fundamentals to validate and ensure quality of the product as well as the underlying data pipeline and assets to secure trustworthiness in your data daily.

Customer Focus: Be driven by a focus on customer happiness and success. We as a team only succeed if our customers are secure and protected via the updates we deliver.


Qualifications
Required Qualifications:
Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 1+ year(s) experience in business analytics, data science, software development, data modeling, or data engineering
OR Bachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 2+ years experience in business analytics, data science, software development, data modeling, or data engineering
OR equivalent experience.
Other Requirements:
Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include but are not limited to the following specialized security screenings:
Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.
Preferred Qualifications:
3+ years with scripting and coding languages with a focus on data engineering, like SQL, KQL, python, Scope, C# (or similar object-oriented languages) and others.
1+ years of experience with building large data processing frameworks using technologies like Azure Data Factory, Azure Data Explorer, PowerBI and/or other public and Microsoft internal tools.
1+ years of experience in analytics to define, monitor, and optimize key performance indicators (KPIs) and connected business metrics that ensure measurable customer success.
1+ years of proven ability to orchestrate and sustain a data-driven rhythm of business, transforming insights into actionable strategies that align with organizational priorities and deliver impactful outcomes.
A solid quality mindset with the ability to deliver end-to-end data solutions that build partner and customer confidence, ensuring alignment with business objectives and measurable outcomes.
Experience with Git, ADO or equivalent Source Control Systems.
Experience with data visualization tools and how to effectively communicate Insights to consumers of varying types of audiences.
Experience leveraging AI to define and evaluate quality standards


Data Engineering IC3 - The typical base pay range for this role across the U.S. is USD $100,600 - $199,000 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $131,400 - $215,400 per year. 
Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:
https://careers.microsoft.com/us/en/us-corporate-pay

This position will be open for a minimum of 5 days, with applications accepted on an ongoing basis until the position is filled.


Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance with religious accommodations and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations."
2025-12-12T01:54:02.588,"Data Science Engineer, New College Grad- Master's/PhD (Santa Clara, CA)",Applied Materials,"Assist in developing data science software prototypes and interfaces for monitoring semiconductor process tools Develop Python scripts to implement key concepts Collaborate closely with algorithm developers to characterize the algorithms and benchmark their performance, collecting quantitative data assessing effectiveness Evaluate the effectiveness and accuracy of the algorithms by working closely with process and equipment experts, providing feedback to algorithm developers Provide solutions which can be implemented by engineers without a deep statistical or mathematical background Deploy and maintain solutions at service sites Troubleshoot solutions, provide workarounds, and assist users in using solutions Assess effectiveness of solutions and provide data science insight Communicate well with algorithm developers and process experts Train field engineers to use solutions Present work and conclusions clearly and succinctly to peers Work well in team, providing and receiving constructive input with team members Monitor and quantify the results of complex algorithms in a production environment. Train a variety of individuals on the operation of these algorithms. Experience with various Artificial Intelligence Solutions, including Large Language Models, Computer Vision and Generative AI applications. Python, MATLAB Familiarity with common data science techniques, including regression, decision trees, Principle components, PLS, various Neural networks, time-series techniques, Bayesian techniques, etc. Ability to troubleshoot software applications and perform basic DevOps for deployment Ability to interact with Process and Customer Engineers Semiconductor process or equipment experience preferred. Demonstrates depth and/or breadth of expertise in own specialized discipline or field May lead small functional teams or projects with moderate resource requirements, risk, and/or complexity Communicates difficult concepts and negotiates with others to adopt a different point of view Master's or PhD in Computer Science, Data Science, Software Engineering, Mechanical Engineering, or related field. Preferred GPA of 3.0 or above"
2025-12-12T01:52:09.253,"Vice President, Data Engineer",BNY,"Bachelor's or master's degree in computer science or a related discipline, or equivalent work experience is required. 10+ years of data modeling, database design and development or related experience is required. Prior experience in managing DB development team Experience modeling Financial data Prior experience modeling Client and Entitlement Data Good knowledge of Financial Accounts, Transactions and Positions data Hands-on experience with any RDBMS, preferably MS SQL Server or Oracle Good SQL knowledge Excellent communication skills Good Problem Solving & Analytical Skills Work experience in Financial Services Work experience on any data modeling tool, viz. Erwin, DBArtisan etc. Experience with writing ANSI SQL code Prior Experience with a scripting language, preferably Python Experience working with Cloud native databases Bachelor's or Master's degree in Computer Science or a related discipline, or equivalent work experience is required. Advanced degree is preferred. Experience in the Securities or Financial Services industry."
2025-12-12T01:08:33,Data Analytics Engineer,Masimo,"The Data Analytics Engineer will support Masimo’s Quality organization by developing dashboards, performing data analysis, and transforming large datasets into meaningful insights. This role partners closely with Quality Compliance, Product Assurance, Engineering, Operations and cross-functional stakeholders to enhance data visibility, drive data-informed decisions, and support continuous improvement across the organization. The ideal candidate is technically strong in analytics tools, comfortable working with structured and unstructured data, and eager to grow in a fast-paced and evolving environment.
Duties & Responsibilities
Develop and maintain Power BI dashboards and reports that translate complex data sets into clear, actionable information.
Perform data transformation and modeling using SQL, Power Query (M), and DAX to support quality metrics, KPIs, and trend analysis.
Support routine and ad-hoc data analytics requests related to customer feedback, failure analysis, operations, and compliance activities.
Analyze large datasets to identify trends and process improvement opportunities.
Collaborate with Quality Compliance, Product Assurance, and cross-functional engineering teams to ensure data accuracy, consistency, and alignment with business needs.
Communicate findings through effective data storytelling, written summaries, and monthly presentations to cross functional leaders across the organization.
Contribute to continuous improvement efforts in reporting automation, dashboard optimization, and analytics best practices.
Minimum & Preferred Qualifications and Experience
Experience
0–2+ years of experience in data analytics, business intelligence, or engineering analytics; internship or project experience considered.
Hands-on experience with SQL and Power BI (including Power Query/M and DAX).
Experience using Python or R for data manipulation, modeling, or visualization preferred.
Familiarity with data visualization tools (Power BI highly preferred; Tableau or Looker a plus).
Understanding of statistics, data modeling, or quantitative analysis techniques.
Skills & Competencies
Strong analytical and problem-solving skills with high attention to detail.
Ability to translate data into clear insights for technical and non-technical partners.
Strong verbal, written, and visual communication skills, with the ability to present confidently and engage diverse audiences.
Ability to work independently and in a team environment.
Curiosity and willingness to learn new tools, systems, and techniques.
Education
Bachelor’s degree in Data Analytics, Data Science, Business Intelligence, Computer Science, Engineering, or a related field required.
Master’s degree in a relevant field is a plus but not required.
Compensation:
The anticipated salary range for this position is $90,000 - $110,000 plus benefits. Actual placement within the range is dependent on multiple factors, including but not limited to skills, education, and experience. 
This position also qualifies for up to 10% annual bonus based on Company, department, and individual performance. 
Masimo offers benefits such as Medical, Dental, Vision, Life/AD&D, Disability Insurance, 401(k), Vacation, Sick, Holiday, Paid Maternity Leave, Flexible Spending Accounts, Voluntary Accident, Critical Illness, Hospital, Long-Term Care, Employee Assistance Program, Pet Insurance, On-site wellness clinic, fitness center, and cafe. All benefits are subject to eligibility requirements."
2025-12-12T00:39:10,Data Engineer,HealthPartners/GHI,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:39:10,Data Engineer,HealthPartners,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:14:05.56,Sr. Data Engineer,Apple,"As a Data Engineer on the Capacity Engineering team, you will help design,
build, and operate the data foundation that drives capacity, cost, and
power-related decisions across Apple’s infrastructure footprint. In this role,
you will: Architect, implement, and maintain large-scale batch and streaming
pipelines that ingest, process, and model infrastructure telemetry, cost,
metering, utilization, forecasting, and power metrics from multiple clouds and
bare metal environments. Design and evolve robust data models (with a strong
focus on dimensional modeling) and storage patterns that support analytics,
internal billing, and efficiency use-cases. Treat data as a product: define
quality checks, SLAs, and observability to ensure data is accurate, timely, and
trusted by stakeholders across Apple. Integrate and enrich raw signals with
metadata and attribution to power use cases such as internal billing/showback,
usage understanding, efficiency and optimization, clawbacks, planning, and
procurement. Collaborate closely with data scientists, software engineers,
platform teams, finance partners, program managers, and leadership to translate
requirements into scalable, reliable data solutions and services. Implement
standard methodologies for data governance, lineage, metadata management, and
security, in alignment with Apple’s standards for data protection and privacy.
Build end-to-end data solutions that include logging, anomaly detection, data
validation, cleaning, and transformation, with strong emphasis on monitoring,
debuggability, and continuous improvement. Contribute to the evolution of our
data and platform stack, including tooling, frameworks, and standards for
development, testing, deployment, and operations (CI/CD, infrastructure as code,
etc.).


DESCRIPTION


Apple’s Capacity data engineering team, within the Apple Services Engineering
organization, is building the centralized data backbone that powers how Apple
understands, plans, and optimizes its cloud and data center infrastructure. We
engineer a unified, trusted data lake that consolidates cost, metering,
utilization, forecasting, and power metrics produced by Apple platforms and
systems (including bare metal) across both third-party and Apple internal
clouds. Enriched with metadata and attribution, this becomes the single source
of truth for internal billing, understanding usage and utilization, clawbacks,
planning, procurement, and efficiency initiatives. We collaborate with platform
engineering, finance, capacity engineering, and leadership teams to build
large-scale data pipelines, enable descriptive and predictive analytics, and
power dashboards and products that support critical business decisions. This is
your opportunity to help design and operate highly visible, global-scale systems
processing petabytes of data and supporting hundreds of users across Apple. Come
join us to help deliver the next generation of infrastructure insights at Apple.


MINIMUM QUALIFICATIONS


Bachelors degree or equivalent experience in Computer Science, Information
systems, Software Engineering, Data Science or related field. Advanced degree in
a related field a plus. 5+ years of experience in data engineering (or
equivalent practical experience), including: Building and maintaining
large-scale ETL/ELT data pipelines Distributed computing (e.g., Spark / PySpark)
for data processing and automation Query performance optimization and tuning at
scale Hands-on experience with: Apache Spark and Airflow (or similar
workflow/orchestration tools) for efficient large-scale data pipelines Data
modeling, especially dimensional modeling, and designing schemas optimized for
analytics and reporting Big data platforms and/or data lake architectures


PREFERRED QUALIFICATIONS


Experience with cloud technologies, specifically AWS (e.g., S3, EMR, Lambda,
Glue, RDS/Redshift, or similar services) Tooling & ecosystem: Experience with
CI/CD tooling such as Jenkins (or similar tools) Experience with data
visualization / BI tools, such as Superset or Tableau (other tools like
QuickSight, QlikView, Cognos, or Business Objects are a plus) Experience with
containerization and orchestration, such as Docker and Kubernetes/EKS is a plus
Understanding of authentication and authorization (AuthN/AuthZ) patterns
Knowledge of data governance principles, data security best practices, and data
privacy regulations"
2025-12-12T00:00:00,Lead Data Engineer,Nuna,"At Nuna, our mission is to make high-quality healthcare affordable for everyone. We are dedicated to tackling one of our nation’s biggest problems with ingenuity, creativity, and a keen moral compass.
Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why.
Nuna has established its brand in the B2B space over the last decade by shifting the US healthcare system towards an incentive model that rewards healthcare providers for positive outcomes. Marshalling our collective backgrounds and insights, we are now crafting an innovative, consumer app - a clinically driven healthcare companion experience that leverages AI, gamification and social support techniques to improve outcomes for people with chronic conditions.
As a sign of the impact Nuna has already made in this space, Nuna was recently selected to join the Centers for Medicare & Medicaid Services (CMS) Health Tech Ecosystem, a landmark public-private initiative designed to transform healthcare for Americans.
YOUR TEAM
The Data org at Nuna is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research.
The Data Engineer team is a core part of the broader Data organization, which is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research. The Data Engineer team acts as the technical backbone for data architecture, platform development, and data operations, empowering the organization to deliver impactful data-driven solutions in healthcare.
YOUR OPPORTUNITIES
We are looking for someone who is excited to use their creativity and engineering skills to make a difference in healthcare. You will have a foundational role on a team building a consumer product that incentivizes healthy behavior. You will be responsible for the data architecture and direction of the data platform that powers our data operations and data science initiatives.
Own the architecture and evolution of the data platform, based on business needs and considering trade-offs in timelines, cost, and resources
Define and enforce standards for code development, contribution, and deployment for data engineering workflows.
Oversee integrations with external services, including data ingestion, distribution, and service-to-service data flows.
Contribute hands-on to data transformations and optimizations
Establish security, governance, and operational best practices for the data platform in collaboration with security and enterprise data engineering teams.
Curate and develop datasets needed to support Data org project deliverables
Collaborate with cross-functional partners in engineering, design, and product to develop solutions
Generate and prioritize new opportunities for improvements
Provide build vs buy assessments and recommendations as the platform expands
QUALIFICATIONS
Required Qualifications
Deep hands-on expertise in designing, coding, developing, and maintaining data platforms that support data analytics and data science use cases
Proven ability to design, develop and implement robust data ingestion pipelines (ETL) from external sources into a data platform.
Experience establishing standards for code development, deployment, and contributions in a data engineering environment.
Ability to solicit and translate customer and business needs into requirements and an evaluation framework
Interest in improving healthcare and working with interdisciplinary project teams
Clear communication and presentation skills
Experience with Databricks
Expertise in data platform languages such as python, pyspark and SQL
+ 5-10 years of industry experience with technical lead experience of running a data platform for business operations
Preferred Qualifications
MS in quantitative field (e.g. Data Science, Economics, Statistics, Engineering)
Experience building a data platform from zero to one
Experience working with healthcare data
Experience with SDLC and management of machine learning models (MLOps)
Bonus points if experience with MLOps on LLM/GenAi features (evals, context building, …)
We take into account an individual’s qualifications, skillset, and experience in determining final salary. This role is eligible for health insurance, life insurance, retirement benefits, participation in the company’s equity program, paid time off, including vacation and sick leave. The expected salary range for this position is $208,000 - $260,000. The actual offer will be at the company’s sole discretion and determined by relevant business considerations, including the final candidate’s qualifications, years of experience, and skillset.
Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status.
#LI-FK1"
2025-12-12T00:00:00,Development Project Engineer (Data Center Construction),QTS Data Centers,"Who we are: It's pretty exciting to find yourself standing in a pivotal moment in time. It’s even more exciting to be out front leading it. At QTS, our world-class data centers are supporting our customers’ most strategic growth initiatives, positioning us at the forefront of today’s dynamic digital transformation. As AI and cloud drive the demand for increased speed, capacity and capability, QTS has emerged as the global digital infrastructure leader, committed to connecting the world for good. Driven by purpose and fueled by a spirit of innovation, QTS designs, builds and operates some of the world’s most advanced, forward-thinking data centers. QTS is a portfolio company of Blackstone. QTS is Powered by People. People who play a vital role in our company’s culture, innovation and growth. People who are committed to contributing to the communities where we operate and work. People who are knowledgeable, resourceful and mission driven. Together, we do great things. Who You Are: The Development Project Engineer (Data Center Construction) is primarily responsible for assisting with the design, preconstruction and construction activities on a given project(s). The Development Project Engineer will interact on a daily basis with Facilities, Contractors, Designers, Engineers, Commissioning Agents, Vendors, and Data Center Operations & Corporate real estate staff and should have both written and oral communication skills commensurate with this level of regular communication. What You Will Do: Assist Development leadership and Project Manager with day to day activities and responsibilities Assist with multiple projects on a campus(es) and maintain updated budgets, schedules, and status reports for each Assist with updates on development program & project status on a monthly basis suitable for executive level reviews. Work with QTS stakeholders, design, and construction teams to help with master development program for site(s), including a complete campus design solution and capital budget. Assist with entitlement and permitting needs for each assigned site project(s) Assist with scopes of work for design, construction, commissioning services & participate in procurement and project cost estimates Evaluate and level pricing proposals for design, construction, and commissioning services Work closely with strategic procurement team on equipment procurement and delivery process Ensure appropriate submittals are coordinated with site stakeholders Assist with monitoring project budget / cost-to-date against overall project budget. Review project schedules and manage teams to on-time completion Review change order requests from contractors and negotiate pricing Assist with establishing site construction security procedures in conjunction with site security team Establish and maintain relationships serving as liaison with key QTS stakeholders Represent QTS Interests in OAC meetings Create & build relationships that enhance QTS’s ability to be a leader in creating the World’s Most Valuable Data Center Real Estate Aid in due diligence efforts on an as-needed basis by participating with real estate efforts on potential or new land banks and properties, including: Evaluate opportunities to design & build new data centers by working with key stakeholders: Corporate Real Estate, Connectivity, Power & Construction teams. Assist with establishing and monitoring entitlement and permit processes for individual projects as needed Work with the internal development team to enhance project management processes and protocols What You Will Need to be Successful (basic qualifications): Bachelor’s degree in Engineering or Construction Management field or equivalent professional experience Experience with Microsoft Office suite, specifically PowerPoint for use in communicating program updates to executive level, and Excel to create and maintain site program & individual project budgets Excellent interpersonal skills with the ability to interface with all levels of the organization Must be a capable, proven team player that both fosters and operates well within internal and external team environments. Able to solve problems at a tactical and functional level Strong Verbal and Written Communication Skills Ability to manage multiple projects simultaneously Other Key Skills: One or more years of professional experience in commercial construction practices and procedures, including management of Lump Sum, Construction Management @ Risk, and Design Build project delivery methods from conceptual development through procurement to close out Documented experience using AutoCAD, BlueBeam, P6, and CxAlloy Experience or exposure in mission critical data center facilities Experience with management of MEP trades Experience managing document control for active data center build sites The Perks (and these are just a few!): Q-Rest Sabbatical Employee Stock Purchase Plan QTS scholarship for dependents Eagle Club Award Trip Eligibility Paid Volunteer and Floating days Tuition Assistance, Parental Leave and Military Leave Assistance We conform to all the laws, statutes, and regulations concerning equal employment opportunities and affirmative action. We strongly encourage women, minorities, individuals with disabilities and veterans to apply to all of our job openings. We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, gender identity, or national origin, age, disability status, Genetic Information & Testing, Family & Medical Leave, protected veteran status, or any other characteristic protected by law. We prohibit retaliation against individuals who bring forth any complaint, orally or in writing, to the employer or the government, or against any individuals who assist or participate in the investigation of any complaint or discrimination claim. The ""Know Your Rights"" Poster is included here: Know Your Rights (English) Know Your Rights (Spanish) The pay transparency policy is available here: Pay Transparency Nondiscrimination Poster-Formatted QTS is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please send an e-mail to talentacquisition@qtsdatacenters.com and let us know the nature of your request and your contact information. It’s exhilarating to find yourself at a pivotal moment in history— and even more so to be leading the way. At QTS Data Centers, we are proud to stand at the forefront of today’s dynamic digital transformation. Our world-class data centers empower our customers’ most strategic growth initiatives, positioning us as a global leader in digital infrastructure. As AI and cloud technologies fuel the demand for increased speed, capacity, and innovation, QTS has emerged as the global digital infrastructure leader. We are committed to connecting the globe for good. Driven by purpose and a spirit of innovation, we design, build, and operate some of the most advanced data centers worldwide. In addition to our cutting-edge technology, we are dedicated to sustainability, incorporating renewable energy solutions to minimize our environmental footprint and drive meaningful impact. As a proud portfolio company of Blackstone, QTS is uniquely positioned to achieve ambitious growth and innovation goals. At QTS, we are Powered by People. Our team members are the cornerstone of our culture, innovation, and growth. They are mission-driven, resourceful, and committed to making a positive impact in the communities where we live and work. Together, we’re achieving remarkable things and shaping the future of digital infrastructure. And we’d like to invite you to join us. In addition to a variety of benefit packages, QTS goes above and beyond for our employees: Roth and Traditional 401(k) matching contributions with immediate vesting Every employee is bonus or commission eligible Generous PTO, Paid Volunteer Days Plus Floating Holidays Stock Purchase Plan (SPP) 11 paid Holidays Annually/Holiday compensation when worked Pet and Legal Insurance Q-Rest Sabbatical Program Q-Anniversary Service Award Program Parental Leave for primary and secondary caregivers Military Benefits Package QTS Charitable Matching Gift Program QTS Scholarship for Employee Dependents QTS Crisis Fund Wellness Program Tuition Reimbursement Program"
2025-12-12T00:00:00,"Data Engineer I, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $109,300.00 - $180,200.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data across the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape by designing, building, and deploying data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning, and business intelligence initiatives. You will work closely with Data Science and Decision Science teams to build, test, and maintain data pipelines and model workflows that support both analytical research and production use cases in our Databricks/AWS/Snowflake environment. In addition to your strong analytical mind, you will bring an inquisitive attitude and the ability to translate the stories found in data into actionable insights while contributing to technical discussions and process improvements. Applicants must be authorized to work for ANY employer in the U.S. The company does not sponsor/support H-1B petitions, TN, or Forms I-983/STEM OPT, for this role. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions. Design data solutions. Analyze sources to determine value and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Collaborate within and across teams to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate. Test data movement, transformation code, and data components. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent. Six years of related experience. Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions. Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on. Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems. Strong verbal and written communication skills with the ability to interact with team members and business partners. Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Four years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,"Senior Data Engineer, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $139,400.00 - $230,000.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions. Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies. Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate. Collaborate across team to support delivery and educate end users on complex data products/analytic environment. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent Ten years of related experience Primary Job Requirements: Architect and design scalable, secure data solutions using AWS, Databricks, and Ab Initio. Lead technical direction for data engineering initiatives across cloud and on-premises infrastructure. Hands-on development: build ETL pipelines, optimize Spark jobs, and create Ab Initio graphs. Troubleshoot production issues and provide technical guidance to junior engineers. Conduct mentoring sessions and offer technical guidance to the 20-person admin team. Collaborate with DBA teams, business analysts, and QA teams to ensure data governance and quality. Manage infrastructure deployment and optimize cloud resources. Lead technical design reviews and architecture discussions. Implement data integration solutions and ensure compliance with data protection regulations. Establish and enforce coding standards, best practices, and data governance policies. Technical Skills: AbInitio: Expert proficiency with GDE, Co>Operating System, EME, BRE, Express>It, metaprogramming (PDL) Programming: Python, PySpark, SQL Cloud: AWS architecture and services Databricks: Workspace management, cluster configuration, Delta Lake, Unity Catalog Data Warehousing: Strong understanding of data modeling, dimensional modeling (star/snowflake schemas) ETL/ELT: End-to-end ETL development lifecycle Version Control: Git, CI/CD pipelines Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices. Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems. Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers. Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize. Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas. Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Five years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,Data Flow Engineer,Scientific Research Corporation,"Description
The Data Flow Engineer will be a member of a Cryptologic Carry-On Program (CCOP) and Ship’s Signals Exploitation Equipment (SSEE) Systems Engineering team primarily responsible for ensuring the processing and distribution of data to and from intelligence community networks. The ideal candidate will have a history of direct involvement with successful NiFi data flow engineering and resolving Navy hardware and software functionality problems by providing a high degree of timely customer service and technical expertise in support of the US Navy information warfare community.
Installing, configuring, integrating, and maintaining NiFi servers and processors into new or existing system architectures
Verifying and maintaining all NiFi processors and flows to and from deployed (and test) systems, from the field system through customer back-end repositories
Assisting end users with the operational readiness and configuration of deployed systems for optimal data flow to satisfy customer requirements
Designing and developing NiFi processors and flows for deployed systems, containing multiple subsystems and requiring integration with external networks
Implementing expression language in NiFi processors in response to emerging customer requirements
Exhibiting developed verbal and written communication skills and the ability to express concepts and ideas in a clear and concise manner; employing technical writing techniques
Performing as a team player, dedicated to the endeavors of the mission, the customer, and the team itself
Being a self-starter who is accountable and requires minimal direction and supervision; capable of multitasking and working several complex and diverse tasks with simultaneous or near simultaneous deadlines
#LI-LL1
Requirements
Must possess an active TS/SCI clearance and be able to obtain a CI Polygraph
Requires a bachelor’s degree in related technical field or equivalent work experience
Intermediate Linux Command Line Interface (CLI) experience
1-3 years of Apache Niagara Files (NiFi) experience (negotiable with other qualifications)
Strong background in using and troubleshooting Software Defined Radio (SDR) systems
Fundamental knowledge of wireless protocols in common use
Experience providing technical support to customers over Internet Relay Chat (IRC) or similar applications
Familiarity with back-end databases and repositories
Must be willing to travel up to 10% of the year
Must currently be DoD 8570-compliant with the equivalent of an IAT II certification or have the ability to do so within 6 months of employment
Desired Skills
Current Linux+/LPIC 1 and/or Network+ certification
Familiarity with Regular Expression (REGEX), Cisco Networking, and Amazon Web Services (AWS)
Expert-level SDR knowledge and experience
Experience with strategic-level intelligence processes
Basic computer programing experience (i.e. Python, JavaScript, bash)
Prior Navy CTR/CTM/CTN with shipborne, expeditionary, or other comparable experience 
Clearance Information
SRC IS A CONTRACTOR FOR THE U.S. GOVERNMENT. THIS POSITION WILL REQUIRE U.S. CITIZENSHIP AS WELL AS A U.S. GOVERNMENT SECURITY CLEARANCE AT THE TOP SECRET / SCI LEVEL with CI POLY ELIGIBILITY
Travel Requirements
up to 10% travel may be required
About Us
Scientific Research Corporation is an advanced information technology and engineering company that provides innovative products and services to government and private industry, as well as independent institutions. At the core of our capabilities is a seasoned team of highly skilled engineers and scientists with multidisciplinary backgrounds. This team is challenged daily to provide cutting edge technology solutions to our clients.
SRC offers a generous benefit package, including medical, dental, and vision plans, 401(k) with a company match, life insurance, vacation and sick paid time off accruals starting at 10 days of vacation and 5 days of sick leave annually, 11 paid holidays, tuition reimbursement, and a work environment that encourages excellence and more. For positions requiring a security clearance, selected applicants will be subject to a government security investigation and must meet eligibility requirements for access to classified information.
EEO
Scientific Research Corporation is an equal opportunity employer that does not discriminate in employment.
All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other protected characteristic under federal, state or local law.
Scientific Research Corporation endeavors to make www.scires.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact jobs@scires.com for assistance. This contact information is for accommodation requests only and cannot be used to inquire about the status of applications."
2025-12-12T00:00:00,"Research Data Engineer II, CHeT Analytics",University of Rochester,"As a community, the University of Rochester is defined by a deep commitment to Meliora - Ever Better. Embedded in that ideal are the values we share: equity, leadership, integrity, openness, respect, and accountability. Together, we will set the highest standards for how we treat each other to ensure our community is welcoming to all and is a place where all can thrive. Job Location (Full Address): 265 Crittenden Blvd, Rochester, New York, United States of America, 14642 Opening: Worker Subtype: Regular Time Type: Full time Scheduled Weekly Hours: 40 Department: 400980 Neuro-Ctr Health & Tech/Admin Work Shift: UR - Day (United States of America) Range: UR URG 113 Compensation Range: $77,216.00 - $115,824.00 The referenced pay range represents the minimum and maximum compensation for this job. Individual annual salaries/hourly rates will be set within the job's compensation range, and will be determined by considering factors including, but not limited to, market data, education, experience, qualifications, expertise of the individual, and internal equity considerations. Responsibilities: GENERAL PURPOSE Participates in the design, implementation and maintenance of analytical and data science-based software and data pipelines to support scientific workflows. Focuses on developing and supporting data collection frameworks that integrate structured and unstructured data from multiple sources and systems to support specific research study teams. Supports the development and maintenance of infrastructure systems (e.g., data warehouses, data lakes), including data access Application Programming Interface(s) (APIs). Works in partnership with team members to provide robust, scalable software solutions to the research enterprise. ESSENTIAL FUNCTIONS Builds, maintains and evolves general Extract, Transform and Load (ETL) data pipelines and overall data architecture to accommodate a growing amount of data from a variety of large research data sources. Works with research team members to convert business and technical requirements into professional software solutions. Ensures timely completion of tasks while managing multiple assignments, project timelines and business user expectations. Designs and implements custom research project-specific data workflow solutions for data collection, management, reporting and analytics. Contributes to the scientific research. Adheres to defined application development life-cycle practices, including but not limited to, requirements gathering, writing test plans, source code management, peer code review and quality assurance through unit/system/user acceptance testing. Participates in specification, implementation and execution of testing procedures to ensure quality of deliverables, system and data workflow reliability. Produces and maintains comprehensive technical documentation for all systems under the Engineer's responsibilities. Keeps abreast of current application developments through continuing education, professional reading, online forums, conferences, workshops and professional groups. Other duties as assigned. MINIMUM EDUCATION & EXPERIENCE Bachelor's degree in Data Science, Biomedical Science, Computer Science, Mathematics, Statistics or similar discipline and 2 years of experience in technology and data intensive roles and environments required Or equivalent combination of education and experience Programming experience in Structured Query Language (SQL) and one other applicable language (Java, Python, and/or R) required Experience with Change Management solutions required Experience with Version Control solutions (e.g. Git) required Experience implementing and supporting data management systems in a scientific, research context (e.g. biospecimen software, electronic laboratory notebooks, REDCap) preferred Experience with Linux, container and cloud technologies (e.g. HPC, IaaS and PaaS) preferred KNOWLEDGE, SKILLS AND ABILITIES Understanding of data analytics and statistical methods required Expertise of software engineering best practices such as version control and software release management required Strong analytical and problem-solving skills required Strong organizational skills required Ability to work with others in a matrix management environment required Excellent communication skills for describing progress and challenges to stakeholders required Attention to detail, patience and a positive, customer-centric attitude required Strong technical presentation skills required Demonstrated ability to develop proficiency with unfamiliar toolsets preferred Familiarity with file formats, metadata, and data exchange and storage standards applicable in management of scientific and clinical research required The University of Rochester is committed to fostering, cultivating, and preserving an inclusive and welcoming culture to advance the University’s Mission to Learn, Discover, Heal, Create – and Make the World Ever Better. In support of our values and those of our society, the University is committed to not discriminating on the basis of age, color, disability, ethnicity, gender identity or expression, genetic information, marital status, military/veteran status, national origin, race, religion, creed, sex, sexual orientation, citizenship status, or any other characteristic protected by federal, state, or local law (Protected Characteristics). This commitment extends to non-discrimination in the administration of our policies, admissions, employment, access, and recruitment of candidates, for all persons consistent with our values and based on applicable law. Notice: If you are a Current Employee, please log into myURHR to search for and apply to jobs using the Jobs Hub. Your application, if submitted using this portal, cannot be moved forward. Learn. Discover. Heal. Create. Located in western New York, Rochester is our namesake and our home. One of the world’s leading research universities, Rochester has a long tradition of breaking boundaries—always pushing and questioning, learning and unlearning. We transform ideas into enterprises that create value and make the world ever better. If you’re looking for a career in higher education or health care, the University of Rochester may offer the perfect opportunity for your background and goals. At the University of Rochester, we are committed to fostering, cultivating, and preserving an inclusive and welcoming culture and are united by a strong commitment to be ever better—Meliora. It is an ideal that informs our shared mission to ensure all members of our community feel safe, respected, included, and valued."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,Data Engineer II (Onsite),RTX,"Date Posted: 2025-12-12 Country: United States of America Location: PW147: PW OKC Campus 8120 S. Air Depot Blvd , Oklahoma City, OK, 73135 USA Position Role Type: Onsite U.S. Citizen, U.S. Person, or Immigration Status Requirements: U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Security Clearance: None/Not Required Pratt & Whitney is working to once again transform the future of flight—designing, building and servicing engines unlike any the world has ever seen. And because transformation begins from within, we’re seeking the people to drive it. So, calling all curious. Come ready to explore and you’ll find a place where your talent takes flight—beyond the borders of title, a country or your comfort zone. Bring your passion and commitment and we’ll welcome you into a tight-knit team that takes our mission personally. Channel your drive to make a difference into shaping an organization and an industry that’s evolving fast to the future. At Pratt & Whitney, the difference you make is on display every day. Just look up. Are you ready to go beyond? You will be an integral part of Pratt & Whitney’s Sustainment Operational Excellence Data Engineering & Analytics team. This team supports the global aftermarket maintenance and overhaul of engines for the F117, F119, and F135 programs. We are looking for a Data Engineer II to advance the digital and data capability of the Military Engines Global Depot Network organization. You will be working on exciting new technologies like cloud and open-source tools among others, and be responsible for cleaning, standardizing, transforming, and configuring data products within our emerging data mesh. What You Will Do: Create and maintain scripts written in Spark SQL or Pyspark in Databricks Notebooks. Also, work with SMEs to understand complex datasets for next generation data products and data visualizations to create data mesh tables. Develop scalable and sustainable data product transformations that curate, clean and store data efficiently; perform statistical analysis to quantify completeness and validity; perform bug fixes and apply enhancements to the models when the need arises. Ensure high performance and reliability of data transformation processes and pipelines. Collaborate cross-functionally to gather insights, refine requirements, and ensure alignment between product goals and team efforts. Document data processes, logic, and data sources to ensure transparency and knowledge sharing as well as support the overall team with any ad-hoc data related tasks. Work to convert our existing data visualizations in Power BI to use Databricks instead of Azure Synapse. Keep up to date with technologies and use advanced cloud data warehouse and data transformation techniques to build innovative solutions. Qualifications You Must Have: A degree in Science, Technology, Engineering or Mathematics (STEM) with 2+ years of experience in the use of SQL and/or Python to transform, clean, and integrate data from a variety of source pipelines. U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Qualifications We Prefer: Experience with transformation tools such as dbt, Databricks pipelines, or relevant tools such as SSIS, ADF, or Matillion. Demonstrated experience with Git/GitHub; experience working in cloud data warehouses like Databricks. Familiarity with agile methodologies and Kanban boards. Self-motivated, team player with good communication skills. Ability to focus on results and successfully manage multiple tasks/projects. An astute individual, with the ability to build strong cross-functional relationships; excited at the prospect of developing and implementing new data products that add organizational value & improve decision making capabilities. Business experience with Aerospace or other heavy manufacturing industry. An understanding of ER Diagrams for data modeling. Demonstrated understanding of data mesh design principles and data engineering best practices. Learn More & Apply Now! What is my role type? In addition to transforming the future of flight, we are also transforming how and where we work. We’ve introduced role types to help you understand how you will operate in our blended work environment. This role is: Onsite: Employees who are working in Onsite roles will work primarily onsite. This includes all production and maintenance workers, as they are essential to the development of our engines. Candidates will learn more about role type and current site status throughout the recruiting process. For onsite and hybrid roles, commuting to and from the assigned site is the employee’s personal responsibility. As part of our commitment to maintaining a secure hiring process, candidates may be asked to attend select steps of the interview process in-person at one of our office locations, regardless of whether the role is designated as on-site, hybrid or remote. The salary range for this role is 66,000 USD - 130,000 USD. The salary range provided is a good faith estimate representative of all experience levels. RTX considers several factors when extending an offer, including but not limited to, the role, function and associated responsibilities, a candidate’s work experience, location, education/training, and key skills. Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement. Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company’s performance. This role is a U.S.-based role. If the successful candidate resides in a U.S. territory, the appropriate pay structure and benefits will apply. RTX anticipates the application window closing approximately 40 days from the date the notice was posted. However, factors such as candidate flow and business necessity may require RTX to shorten or extend the application window. RTX is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or veteran status, or any other applicable state or federal protected class. RTX provides affirmative action in employment for qualified Individuals with a Disability and Protected Veterans in compliance with Section 503 of the Rehabilitation Act and the Vietnam Era Veterans’ Readjustment Assistance Act. Privacy Policy and Terms: Click on this link to read the Policy and Terms RTX is an aerospace and defense company that provides advanced systems and services for commercial, military and government customers worldwide. It comprises three industry-leading businesses – Collins Aerospace, Pratt & Whitney, and Raytheon. Its 195,000 employees enable the company to operate at the edge of known science as they imagine and deliver solutions that push the boundaries in quantum physics, electric propulsion, directed energy, hypersonics, avionics and cybersecurity. The company, formed in 2020 through the combination of Raytheon Company and the United Technologies Corporation aerospace businesses, is headquartered in Arlington, Virginia."
2025-12-12T00:00:00,"Senior Engineer, BAW R&D Trimming and Data Infrastructure",Qorvo,"
                Qorvo (Nasdaq: QRVO) supplies innovative semiconductor solutions that make a better world possible. We combine product and technology leadership, systems-level expertise and global manufacturing scale to quickly solve our customers' most complex technical challenges. Qorvo serves multiple high-growth segments of large global markets, including consumer electronics, smart home/IoT, automotive, EVs, battery-powered appliances, network infrastructure, healthcare and aerospace/defense. Visit www.qorvo.com to learn how our innovative team is helping connect, protect and power our planet.

 
Summary:
 Qorvo’s BAW R&D Data Infrastructure team is seeking a talented engineer for semiconductor data infrastructure, frequency trimming and process automation. The candidate chosen for this role will develop data infrastructure and software tools to support efficient development and production of new Bulk Acoustic Wave (BAW) filter technologies. The candidate will use MATLAB, data analysis tools (SpotFire), databases and other software tools for process control improvements, faster design cycles, and general automation to efficiently develop and produce new technologies.
 
Key Roles and responsibilities:

Research, implement, deploy, and maintain internal software applications used by Manufacturing and R&D Engineering teams to process and trim BAW filters wafers.
Work closely with Process Integration and Process Engineering teams to understand new BAW technology needs to define requirements and implement.
Provide comprehensive support to internal customers: resolve outstanding issues for R&D engineers, designers, and production at Qorvo’s fabrication facility.
Own critical data infrastructure projects and successfully deliver results in a timely manner

 
Technical Knowledge/Skills/Abilities Required:

Excellent MATLAB or Python programming capabilities
Knowledge of semiconductor processing
Practical knowledge of software development and object-oriented programming
Excellent debugging and problem-solving skills


Strong data analysis and mathematical skills


Experience with version control utilizing Git and GitLab
Good knowledge of SQL database (Oracle is a plus)
Experience in the full life cycle of the software design process including requirement analysis, design, prototyping, coding, documentation, implementation, and maintenance

 
Personal Skills:

Self-motivated, independent, proactive, detail oriented, and responsible team-player
Excellent analytical skills
Comfortable working in a dynamic and fast paced environment
Passion for innovation and emerging technologies
Excellent communication and interpersonal skills
Able to handle multiple priorities
Proficient in English

 
Desired experiences:

Experience with software development for semiconductor processing 
Expertise in electromagnetics, physics, or material science
Expertise in Oracle PL/SQL databases
Experience with data analysis tools such as Spotfire or similar application
Experience with GitLab workflows and pipeline automation 
Experience with Visual Studio Code and GitHub Copilot
Experience with unit testing in past development projects

 
Qualifications:
Education & Experience:

BS or MS in Computer Science, Electrical Engineering, Physics or Material Science
5+ years of code development experience.(or if Master's degree 2+ years experience)

 
This position is not eligible for visa sponsorship by the Company.
 
#LI-KR1
 MAKE A DIFFERENCE AT QORVO   

 We are Qorvo. We do more than create innovative RF and Power solutions for the mobile, defense and infrastructure markets – we are a place to innovate and shape the future of wireless communications. It starts with our employees. As a unified global team, we bring a commitment to excellence, growth and a passion for creating what's next. Explore the possibilities with us.

We are an Equal Employment Opportunity (EEO) employer and welcome all qualified applicants. Applicants will receive fair and impartial consideration without regard to any characteristics protected by applicable law, including race, color, religion, sex (as defined by law), national origin, age, military or veteran status, genetic information, or disability.  
                
    "
2025-12-12T18:28:05.616,Sr Staff Engineer Software (Data Plane Applications),Palo Alto Networks,"Company Description
Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
Who We Are
We believe collaboration thrives in person. That’s why most of our teams work from the office full time, with flexibility when it’s needed. This model supports real-time problem-solving, stronger relationships, and the kind of precision that drives great outcomes.
Job Description
Your Career
Prisma Access™ (formally GlobalProtect Cloud Service) provides protection straight from the cloud to make access to the cloud secure. It combines the connectivity and security you need and delivers it everywhere you need it. Using cutting-edge public and private cloud technologies extending the next-generation security protection to all cloud services, customers on-premise remote networks and mobile users.
We are seeking an experienced Software Engineer to design, develop and deliver next-generation technologies within our Prisma Access team. We want passionate engineers who love to code and build great products. Engineers who bring new ideas in all facets of software development. We are looking for leaders who take ownership of their areas of focus and who are driven to solve problems at every level. Collaboration and teamwork are at the foundation of our culture and we need engineers who can communicate at a high level and work well with others towards achieving a common goal.
Your Impact
Design, develop and implement highly scalable software features and infrastructure on our next-generation security platform ready for cloud native deployment from inception to completion
Work with different development and quality assurance groups to achieve the best quality - You accomplish this by being hands-on, creating tools, processes, and systems that produce transparency, alignment, and direction
Profile, optimize and tune systems software (management/control/dataplane) for efficient cloud operation
Work with DevOps and the Technical Support teams to troubleshoot customer issues
Work with other software development team to apply PanOS features on Prisma Access
Interview, mentor and coach new team members 
Qualifications
Your Experience 
5+ years of experience in developing and troubleshooting dataplane applications
Required hands-on programming experience in Python and Go
Nice to have C/C++ Programming
Strong Data structures/Algorithms
Strong analytical skills, problem solving and debugging skills
Nice to have experience with LLMs and GenAI applications. Or Machine learning/Data science with experience in ETL, curating datasets, running evals. 
Experience with building applications in the cloud
In-depth understanding of Operating System principles and OS like Linux/Unix
In-depth understanding of networking concepts and TCP/IP stack, TLS
Exposure to building Microservices 
Enjoys working with many different teams with strong collaboration and communication skills
Solid foundation in design, data structures, and algorithms, and strong analytical and debugging skills
Education : M.S./B.S. degree in Computer Science or equivalent military experience required
Additional Information
The Team
Our engineering team is at the core of our products – connected directly to the mission of preventing cyberattacks. We are constantly innovating – challenging the way we, and the industry, think about cybersecurity. Our engineers don’t shy away from building products to solve problems no one has pursued before.
We define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment.
Compensation Disclosure
The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $170,000 - $190,000/YR. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.
Our Commitment

We’re problem solvers that take risks and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at [email protected].
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
Is role eligible for Immigration Sponsorship?: Yes"
2025-12-12T18:20:27,Data Engineer,Real Chemistry,"At Real Chemistry, making the world a healthier place isn’t just an aspiration—it’s our everyday reality. Our drive to transform healthcare is informed by our blend of deep scientific expertise, human-centred creativity, and AI-driven insights, fostering a unique environment where innovation thrives and our people are impact-obsessed. As a global agency, we provide a full suite of services across healthcare communications and marketing to our clients, including top players in the pharmaceutical and biotech industries.
Our #LifeatRealChem culture is rooted in our people—we believe we are best together and are committed to excellence for both our clients and colleagues. Whether you're a seasoned professional or just starting your career, if you share our passion for healthcare and connection, we invite you to explore our opportunities.
Discover your purpose. Embrace innovation. Experience #LifeatRealChem.
Job Summary 
We’re looking for a hands-on Data Engineer to help build and maintain the data infrastructure that powers our AI products and solutions. This role sits within our AI organization and focuses on designing, developing, and optimizing scalable data pipelines, data models, and cloud-based data systems. You’ll collaborate closely with data scientists, ML engineers, product teams, and other technical partners to ensure high-quality, reliable, and well-structured data is available across the organization. 
Key Responsibilities 
Data Pipeline Development 
Build, optimize, and maintain scalable ETL/ELT pipelines for structured and unstructured data. 
Implement reliable, fault-tolerant ingestion and transformation workflows. 
Automate routine data processes where possible. 
Data Architecture & Modeling 
Develop well-structured data models that support analytics, ML use cases, and downstream applications. 
Support the design and enhancement of AI-related data architecture across cloud environments. 
Data Quality & Governance 
Implement automated data validation, monitoring, and alerting. 
Ensure high data accuracy, completeness, and integrity across ingestion and transformation layers. 
Cross-Functional Collaboration 
Partner with data scientists, ML engineers, product managers, and IT teams to understand data requirements and translate them into technical solutions. 
Troubleshoot issues and support stakeholders with data access and pipeline improvements. 
Cloud & Infrastructure 
Work with modern cloud platforms (AWS, Azure, or GCP) and associated data storage, compute, and orchestration services. 
Support deployment, scaling, and operational health of data systems. 
Innovation & Continuous Improvement 
Stay current with emerging data engineering tools and best practices. 
Propose opportunities to improve performance, efficiency, or reliability within the data stack. 
Qualifications & Skills 
Education & Experience 
Bachelor’s degree in Computer Science, Data Engineering, or related technical field (or equivalent experience). 
3–7 years of hands-on experience in data engineering or data pipeline development. 
Technical Skills 
Strong SQL skills and proficiency in Python or Scala. 
Experience with data warehousing technologies such as Snowflake, BigQuery, Redshift, or Databricks. 
Hands-on experience with cloud services (AWS, Azure, or GCP). 
Knowledge of data modeling, schema design, and ETL/ELT principles. 
Familiarity with distributed computing frameworks such as Spark or Flink. 
Experience with workflow orchestration tools like Airflow, Prefect, or Dagster is a plus. 
Soft Skills 
Strong problem-solving skills and attention to detail. 
Ability to communicate technical concepts clearly to peers and cross-functional partners. 
Comfortable working in a fast-moving, collaborative environment. 
Preferred Qualifications 
Experience with streaming data tools such as Kafka or Kinesis. 
Experience building CI/CD pipelines for data workflows. 
Experience in healthcare, biotech, life sciences, or commercial/marketing data environments. 
Experience in agency or consulting settings. 
Posting Salary
$140,000—$175,000 USD
Real Chemistry is proud to be Great Place to Work® certified; check out what our people shared about our culture and workplace on our Great Places to Work Profile here.
We believe we can do our best when feeling our best, which is why we’ve put together a benefits program designed to give you the support you and your family need at every stage of life. Real Chemistry offers a comprehensive benefit program and perks, tailored to your region. Globally, this includes offices in our key markets with free snacks to keep you running all day long, generous holiday and paid time off, options for private medical, dental, and vison plans, and support in saving for the future. Other perks include mental wellness coaching and support and access to more than 13,000 online classes with LinkedIn Learning. Learn more about our great benefits and perks and search specific offerings in your region at: www.realchemistrybenefits.com.
Working with Real HART: Since the pandemic, we have adapted to how our people told us they want to work. We have office locations in cities in the US, UK, and Europe with many employees and clients that serve as hubs where and when they need us. For employees who are within an hour of one of our offices, we expect attendance in the office two days per week, either at a Real Chemistry office or onsite with clients. We are also actively opening new office locations, so if one opens near you, our Real HART policy will apply. We are not looking for attendance for the sake of attendance but believe that the opportunity to coordinate in-office team meetings, 1:1 meetings with managers, taking advantage of on-site learning, and connecting with client partners is a critical to delivering on our purpose of making healthcare what it should be. Outside of these offices, we have regions, where people work remotely but come together quarterly for collaboration, culture and learning opportunities. We call this our Real Hybrid and Regional Teams (Real HART) approach. Real Chemistry believes we are best together – and our workplace strategy fosters connection and collaboration in person – but also supports flexibility for our people.
Real Chemistry is an Equal Opportunity employer. We continually strive to build and sustain an inclusive and equitable work environment where our employees feel empowered to leverage all they bring from their personal lived experience and professional expertise, to make our team the best in the industry. We encourage motivated and qualified applicants to apply without regard to race, color, religion, sex (including pregnancy), sexual orientation, gender identity/expression, ethnic or national origin, age, physical or mental disability, genetic information, marital information, or any other characteristic protected by federal, state, or local employment discrimination laws where Real Chemistry operates. Should you require accommodations throughout the interview process please let your recruiter know.
*Notice: Real Chemistry and its affiliates' names are being misused by scammers through messaging services, fake websites, and apps. Do not share personal or financial information or make payments to any unverified sources claiming to be connected to Real Chemistry. We are working to stop these unauthorized activities and protect our community. Read more here."
2025-12-12T17:29:23,Senior Python Data Engineer - (Remote)  ,KBRA,"Position Title: Senior Python Data Engineer - (Remote) 
Entity: KBRA Holdings LLC
Employment Type: Full-Time
Location: Remote (Remote only in CA, CO, DC, FL, IL, MD, NJ, MA, NY, PA, SC, TX, VA)
Summary/Overview:
KBRA (KBRA Holdings, LLC) is seeking an engaged and proactive Senior Python Data Engineer to work on our financial analytical system. We want someone who loves solving difficult problems, digs deeply to understand the domain in which they’re working, and excels at creating high-quality software in a collaborative environment.
About the Team:
We believe that small, empowered teams can do amazing things. Across the engineering organization, we work hard to make the best systems for our customers using modern engineering practices. We are intentional in our investments in time and effort around creating a safe and successful workplace for our team members. We understand software engineering goes beyond the 1’s and 0’s and prioritize concrete value for our customers.
About the Job:

This role involves joining an existing team with a well-defined product vision. This team operates collaboratively, and there is an expectation to get involved in all aspects of design, delivery, and support of our systems.

This role emphasizes collaboration with our technical and non-technical counterparts to learn our domain and its unique challenges, while delivering value to our customers. It also requires collaboration with our other engineering, design, product, and platform teams to develop, build, run, and support the system.
About You:

You will be successful in this role if you:
Develop, test, and maintain scalable Python applications.
Collaborate with product managers, designers, and other engineers to deliver high-quality software.
Write clean, efficient, and reusable code following best practices.
Participate in code reviews to ensure code quality and share knowledge with the team.
Troubleshoot and debug issues in a timely manner.
Contribute to the design and architecture of new features and systems.
Have a sense of ownership and craftsmanship around the code base and your work.
Enjoy helping other developers grow and learn new technologies.
Display a strong track record of mentorship with engineers at various levels.
Are mindful of application security and performance.
Take pride in learning, and want opportunities to learn throughout your day-to-day.
Possess a pragmatic mindset. 
Familiarity with Generative AI tools such as ChatGPT for research, data insights, and general productivity is a plus.
Must have skills:
3–6 years of professional software engineering experience, with a strong portfolio of full stack development work.
Proficiency in Python, including experience with web frameworks such as Flask.
Cloud experience, particularly with AWS (Amazon Web Services).
Experience integrating frontend applications with RESTful APIs and backend services.
Relational and non-relational databases (SQL Server, Snowflake and MongoDB).
Debugging, issue resolution, and troubleshooting.
Nice to have skills:
Familiarity with UX design tools (Figma) and solid understanding of the design-engineering hand-off process
Containerized development and deployment (i.e. Docker, Docker swarm, Kubernetes)
Infrastructure as Code (Terraform)
Familiarity with deployment pipelines, CICD tools.
Exposure to financial systems or credit modeling is strongly preferred.
Salary Range:
The anticipated annual base salary range for this full-time position is $130,000 - $160,000. Offer amounts are determined by factors such as experience, skills, geography, and other job-related factors.
Benefits:
Competitive benefits and paid time off
Paid family and disability leave
401(k) plan, including employer match (100% vested)
Educational and professional development financial assistance
Employee referral bonus program
About Us:
KBRA is a full-service credit rating agency registered in the U.S., the EU and the UK, and is designated to provide structured finance ratings in Canada. KBRA’s ratings can be used by investors for regulatory capital purposes in multiple jurisdictions.
More Info:
KBRA encourages applications from all qualified individuals without regard to race, color, religion, gender, sexual orientation, gender identity or expression, age, national origin, marital status, citizenship, disability, and veteran status or any other basis prohibited by federal, state or local law.
#LI-KS1
#REMOTE"
2025-12-12T17:19:54,Data Platform Engineer,Dragonfli Group,"Dragonfli Group is a cybersecurity and IT consulting firm providing services to federal agencies and Fortune 100 enterprises. Headquartered in Washington, DC, Dragonfli supports clients in securing mission-critical systems across on-site, hybrid, and fully remote environments.

This contract Data Platform Engineer role supports a large federal agency in protecting security data platforms within a large-scale IT environment. The engineer will manage security data platforms such as Splunk and data lakes, ensuring effective data flows, integrations, and platform support. Key technologies include Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS. The role requires seasoned IT security expertise, hands-on technical skills, and strong communication and planning abilities. It's a high-impact opportunity to shape security analytics capabilities within a major federal agency.

This is a multi-year contract position involving a large US federal agency. Candidates with previous federal contracting experience are preferred. U.S. Citizenship or Permanent Residency required. If hired, all work related to this role must be performed within the continental U.S.

Responsibilities:
Manage security data platforms, such as Splunk and data lakes.
Ensure effective data flows, integrations, and platform support.
Support event ingestion, platform maintenance, and technical add-ons.
Troubleshoot to support operational and compliance reporting.
Optimize data use for security monitoring, incident response, and threat analysis.
Collaborate across teams to enhance security analytics capabilities.
Configure and maintain various event ingestion methods.
Create and maintain custom TAs for data parsing into Splunk CIM format.
Monitor and perform routine maintenance of data systems.
Drive process improvements and attention to detail.

Requirements
Four (4)+ years of experience supporting enterprise data platforms.
BS/BA in a cyber-related field or equivalent experience/certifications.
Experience with installing, updating, and maintaining ELM and SIEM.
Proficiency with Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS.
Experience configuring and maintaining event ingestion methods.
Ability to create and maintain custom TAs for Splunk.
Experience in troubleshooting, monitoring, and maintaining data systems.
Familiarity with enterprise security operations.
Strong cross-functional communication skills.

Skill(s)
Hands-on management of security data platforms.
Expertise in data flows and platform integrations.
Proficiency in Splunk and related technologies.
Strong troubleshooting and problem-solving skills.
Ability to optimize security monitoring and incident response.
Excellent cross-functional communication abilities.
Attention to detail and process improvement mindset.
Ability to work collaboratively across teams.
Strong planning and organizational skills.

Benefits
Insurance – health, dental, and vision
Paid Time Off (PTO) and 11 Federal Holidays
401(k) employer match

Travel
null"
2025-12-12T16:50:01,Staff Configuration Data Engineer,Archer,"Archer is an aerospace company based in San Jose, California building an all-electric vertical takeoff and landing aircraft with a mission to advance the benefits of sustainable air mobility. We are designing, manufacturing, and operating an all-electric aircraft that can carry four passengers while producing minimal noise.
Our sights are set high and our problems are hard, and we believe that diversity in the workplace is what makes us smarter, drives better insights, and will ultimately lift us all to success. We are dedicated to cultivating an equitable and inclusive environment that embraces our differences, and supports and celebrates all of our team members.
What you'll do:
As the Configuration Data Engineer, you will combine software development expertise with configuration management practices to safeguard product data integrity, traceability, and compliance. You will design tools, reports, and automations that enable engineering and product teams to make faster, more accurate configuration decisions.
Develop and maintain tools and reports to monitor bills of materials (BOMs), effectivity assignments, and configuration changes
Create automated quality checks to validate workflows and ensure compliance with configuration management standards
Integrate with Teamcenter APIs and background services to access, analyze, and validate engineering data
Build automation scripts to support NX, CATIA, and other CAD-driven workflows (NX Open, CATIA VB, Check-Mate, NX Check-Mate)
Support the definition, maintenance, and auditing of BOM structures, unit effectivity, and date-based effectivity for engineering changes
Develop dashboards and metrics reporting to provide visibility into change requests, change notices, and configuration status accounting
Collaborate with configuration management, engineering, and IT teams to streamline data flow across systems
Investigate data anomalies and provide corrective recommendations to maintain design and change integrity
Partner with project teams to ensure effectivity assignments are properly implemented and reflected in reports
Contribute to the improvement of enterprise configuration management processes through data-driven insights
Serve as a technical resource to CM specialists for reporting, automation, and API usage
What You Need
To be a self starter with a strong desire to learn new technologies
Ability to translate engineering/CM requirements into automated solutions
2+ years of experience developing tools and reports for a Product Lifecycle Management (PLM) tools (e.g., Teamcenter, Windchill, Enovia, 3DX) or equivalent engineering data environments
Experience with relational databases (SQL, PostgreSQL, Oracle) for reporting and automation
Ability to interpret engineering drawings, CAD data, and metadata
Understanding of BOM structures, unit effectivity, and date-based effectivity methods
Familiarity with engineering change processes, including Change Requests (CRs) and Change Notices (CNs)
Experience with scripting or automation in CAD/PLM environments (NX Open, CATIA VB, or similar)
Strong problem-solving skills and ability to analyze complex datasets for process improvements
Effective written communication skills to document procedures and produce clear reports
Ability to work in a collaborative environment across engineering, CM, and IT teams
Bonus Qualifications
Hands-on experience with Siemens Teamcenter APIs or integrations
Experience with Business Intelligence tools such as Power BI, Sigma, or SAP Hana
Experience with ITI CADIQ tools and CAD data validation workflows
Experience with Elysium CAD Translation tools
Familiarity with NX Check-Mate and automations
Familiarity with ASME Y14.5 Dimensioning and Tolerancing
Experience developing Adobe Forms with JavaScript and PDF publishing workflows
Exposure to aerospace, automotive, or other complex product development environments
Knowledge of configuration management standards and compliance practices (CMII, EIA-649, etc.)
This role is ideal for engineers who enjoy bridging software development with product lifecycle control. You will directly impact how engineering data is managed, ensuring accuracy, efficiency, and compliance across the enterprise
Archer is committed to working with and providing reasonable accommodations to job applicants with physical or mental disabilities, and those with sincerely held religious beliefs. Applicants who may require reasonable accommodation for any part of the application or hiring process should provide their name and contact information to Archer’s People Team at people@archer.com. Reasonable accommodations will be determined on a case-by-case basis.
Information collected and processed as part of any job applications you choose to submit is subject to Archer's Candidate Privacy Policy.
Archer is unable to provide work visa sponsorship for this position at the present time.
Archer is proud to be an Equal Opportunity employer committed to diversity and inclusivity in the workplace. All aspects of employment are decided on the basis of merit, qualifications, and business needs. We do not discriminate based upon race, color, religion, sex, sexual orientation, age, national origin, disability status, protected veteran status, gender identity or any other characteristic protected by federal, state or local laws.
Archer Aviation does not engage with external recruiting agencies/individual recruiters with whom it does not have a prior written agreement. Archer reserves the right to make use of any unsolicited resumes that it receives and bears no responsibility for payment of any fees asserted from the use of unsolicited resumes. If you are a recruiting agency or individual recruiter wishing to do business with Archer, please reach out to People@archer.com. All employment processes are managed by the Archer People Team."
2025-12-12T16:14:31,Data Engineer - Integrated Supply Chain,Textron,"Data Engineers build and maintain data systems in support of data analytics and data science activities. The Data Engineer will implement methods to improve data reliability, data quality, and ensure success in data-driven initiatives.
This position within Integrated Supply Chain Analytics is responsible for identifying, developing, and executing solutions that support reliable and efficient extraction of data from source systems and loading of that data into analytic platforms. The Data Engineer will help administer data platforms and consult with data analysts and data scientists on process optimization and data quality improvements.
At Textron Aviation, we are building a community of Data & Analytics professionals with an emphasis on collaboration and cross functional support. You will have the opportunity to work closely with your peers throughout the organization toward a vision of data driven strategy.


JOB RESPONSIBILITIES:
· Gain core business understanding of Textron Aviation and aircraft design, operation, and support
· Query, clean, transform, and stage data (ETL/ELT) across on-prem and cloud environments
· Support data analytics and data science activities by implementing, maintaining, and optimizing production ready data pipelines
· Install and update software to ensure data platform continuity
· Administer a CI/CD compliant code repository during development and update activities
· Research and help implement new technologies to support analytics function
· Interface with other data professionals throughout the organization to embrace cross functional growth in analytics capabilities
· Work to improve data quality by assisting data governance efforts in creating and maintaining data quality standards
· Plan and execute projects according to established milestones and schedules
· Train users in data & analytic tools and processes per best practices and compliance standards
· Contribute to the resolution of service tickets pertaining to data infrastructure
· Serve as an internal consultant to business leaders by advising on system capabilities
EDUCATION/ EXPERIENCE:
· Bachelor’s degree in Computer Science, Software Engineering, Data Science/Analytics, MIS, or other related technical field
· Minimum 2 years relevant technical experience required, focused on data collection, utilization, and analysis.
· Aviation experience preferred
Textron Aviation Inc. must comply with U.S export control laws and regulations. If a position requires access to sensitive information controlled under these laws and regulations, a successful applicant must be eligible to meet any requirements to access controlled information."
2025-12-12T16:07:56,Senior Data Engineer ,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:55,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:54,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T15:01:13.806,"Software Engineer III, Infrastructure, Audience Data Processing",Google,"MINIMUM QUALIFICATIONS:

 * Bachelor’s degree or equivalent practical experience.
   
 * 2 years of experience with software development in C++, SQL, Borg, Flume, or
   1 year of experience with an advanced degree.
 * 2 years of experience with developing large-scale infrastructure, distributed
   systems or networks, or experience with compute technologies, storage or
   hardware architecture.



PREFERRED QUALIFICATIONS:

 * Master's degree or PhD in Computer Science or related technical fields.
   
 * 2 years of experience with data structures and algorithms.
 * Experience with Flume and large scale data processing pipelines.
 * Experience developing accessible technologies.
   


ABOUT THE JOB:

Google's software engineers develop the next-generation technologies that change
how billions of users connect, explore, and interact with information and one
another. Our products need to handle information at massive scale, and extend
well beyond web search. We're looking for engineers who bring fresh ideas from
all areas, including information retrieval, distributed computing, large-scale
system design, networking and data storage, security, artificial intelligence,
natural language processing, UI design and mobile; the list goes on and is
growing every day. As a software engineer, you will work on a specific project
critical to Google’s needs with opportunities to switch teams and projects as
you and our fast-paced business grow and evolve. We need our engineers to be
versatile, display leadership qualities and be enthusiastic to take on new
problems across the full-stack as we continue to push technology forward.

As a Software Engineer on the Audience Data Processing Infrastructure team, you
will innovate and optimize planet-scale data processing flows to support Google
Ads.

While we're an infrastructure team, we operate in a fast-paced environment with
evolving requirements. Our focus is on supporting client data processing needs,
enhancing operational excellence and developer velocity, and significantly
improving resource efficiency.


Google Ads is helping power the open internet with the best technology that
connects and creates value for people, publishers, advertisers, and Google.
We’re made up of multiple teams, building Google’s Advertising products
including search, display, shopping, travel and video advertising, as well as
analytics. Our teams create trusted experiences between people and businesses
with useful ads. We help grow businesses of all sizes from small businesses, to
large brands, to YouTube creators, with effective advertiser tools that deliver
measurable results. We also enable Google to engage with customers at scale.

The US base salary range for this full-time position is $141,000-$202,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Write product or system development code in C++ for infrastructure
   responsible for managing and optimizing processing of planet-scale data
   processing.
 * Investigate data storage and processing use cases, techniques, and
   identifying opportunities for future innovation.
 * Review code developed by other developers and provide feedback to ensure best
   practices (e.g., style guidelines, checking code in, accuracy, testability,
   and efficiency).
 * Contribute to existing documentation or educational content and adapt content
   based on product/program updates and user feedback.
 * Triage product or system issues and debug/track/resolve by analyzing the
   sources of issues and the impact on hardware, network, or service operations
   and quality."
2025-12-12T13:26:27,Cleared On Site Data Engineer (4899),SMX,"SMX is seeking a Senior Data Architect to provide strategic and technical leadership for enterprise data architecture and analytics modernization efforts. This individual will design, optimize, and oversee data solutions that enable advanced analytics, business intelligence, and reporting capabilities across multiple secure environments. This role will focus on designing, developing, optimizing, and maintaining data pipelines and backend data engineering solutions that power critical analytical products used by senior FBI leadership. The ideal candidate brings deep technical expertise in ETL processes, SQL, Python, AWS data services, and enterprise-scale data warehousing, with strong familiarity in BI ecosystems such as MicroStrategy (Strategy), ThoughtSpot, and related tools used within the HR Reports program. The position requires close collaboration with government leads, senior data developers, BI engineers, and cross-functional analytics teams to ensure high reliability, performance, and security of data products supporting mission-critical operations. 
This is a full-time position requiring on-site work five days a week at a client’s office in Washington, D.C. An active Top Secret clearance is mandatory.
Essential Duties and Responsibilities: 
Design, build, and maintain scalable, secure ETL/ELT pipelines supporting HR Reports analytics and dashboard products.
Develop and optimize SQL-based transformations, stored procedures, and data models for high-volume enterprise datasets.
Implement data orchestration workflows using AWS services (e.g., Glue, Lambda, Step Functions, CloudWatch).
Ensure data quality, lineage, and integrity across multiple enterprise data sources.
Support and enhance cloud-based warehouse environments within AWS (e.g., Redshift, S3, IAM).
Collaborate with BI developers to ensure backend data structures meet MicroStrategy/Strategy and ThoughtSpot reporting needs.
Troubleshoot complex data pipeline or performance issues and implement long-term remediation solutions.
Translate government stakeholder requirements into technical specifications for new data sources and pipelines.
Partner with Data Analysts, Data Scientists, and BI Developers to support advanced analytics and ad-hoc data requests.
Apply data governance, security, and compliance best practices in alignment with FBI and SMX standards.
Recommend and implement improvements to automation, data architecture, pipeline reliability, and overall performance.
Maintain documentation for pipelines, logic, data flows, and system dependencies.
Stay current with modern data engineering practices and AWS service enhancements relevant to pipeline automation and warehousing.
Required Skills: 
10+ years of experience in data architecture, data warehousing, or enterprise analytics systems.
Expert-level proficiency in SQL and data modeling
Hands-on experience designing and implementing ETL/ELT frameworks (e.g., Apache Airflow, dbt, AWS Glue, Informatica).
Demonstrated success architecting and optimizing large-scale BI/reporting solutions (MicroStrategy, ThoughtSpot, Power BI, Tableau).
Strong knowledge of AWS data ecosystem (Redshift, Athena, S3, Glue, Lambda) or similar cloud environments.
Experience defining and enforcing data governance, quality, and security standards.
Ability to design and document end-to-end data flows and integrations between transactional and analytical systems.
Excellent communication, analytical, and problem-solving skills.
Desired Skills/Experience:
Bachelor’s or Master’s degree in Computer Science, Information Systems, Data Engineering, or related technical field.
10+ years of experience in data engineering, backend data development, or enterprise-scale ETL development.
Experience supporting federal government IT systems or analytics programs.
Familiarity with Agile methodologies and Jira-based workload management.
Experience supporting or modernizing enterprise BI ecosystems.
**This position requires five days a week on site at customer location in Washington DC.
Application deadline 1-16-2026
#LI-SA
#cjpost
The SMX salary determination process takes into account a number of factors, including but not limited to, geographic location, Federal Government contract labor categories, relevant prior work experience, specific skills, education and certifications. At SMX, one of our Core Values is to Invest in Our People so we offer a competitive mix of compensation, learning & development opportunities, and benefits. Some key components of our robust benefits include health insurance, paid leave, and retirement.
The proposed salary for this position is:
$114,600—$192,500 USD
At SMX®, we are a team of technical and domain experts dedicated to enabling your mission. From priority national security initiatives for the DoD to highly assured and compliant solutions for healthcare, we understand that digital transformation is key to your future success.
We share your vision for the future and strive to accelerate your impact on the world. We bring both cutting edge technology and an expansive view of what’s possible to every engagement. Our delivery model and unique approaches harness our deep technical and domain knowledge, providing forward-looking insights and practical solutions to power secure mission acceleration.
SMX is an Equal Opportunity employer including disabilities and veterans.
Selected applicant may be subject to a background investigation and/or education verification.
SMX does not sponsor a new applicant for employment authorization or immigration related support for this position (i.e. H1B, F-1 OPT, F-1 STEM OPT, F-1 CPT, J-1, TN, E-2, E-3, L-1 and O-1, or any EADs or other forms of work authorization that require immigration support from an employer)."
2025-12-12T12:29:19.508,"Data Center Plant Engineer, Mechanical, Electrical",Google,"MINIMUM QUALIFICATIONS:

 * Associate's degree, trade school certification, or other certified training
   in a related technical field, or equivalent practical experience.
 * 7 years of experience in electrical, mechanical/HVAC, or controls/automation
   experience in an industrial or commercial environment.



PREFERRED QUALIFICATIONS:

 * Experience working in data centers, hospitals, or power plants.
 * Knowledge of electrical and mechanical systems used in a data center
   environment (e.g., Feeders, Transformers, Generators, Switchgear, UPS
   systems, ATS/STS units, PDU/PMM units, Chillers, Air handling units, and CRAC
   units).
   
 * Knowledge of meters, devices, sensors, and troubleshooting utilizing standard
   hand tools, digital metering, or calibration/diagnostic equipment.
   
 * Ability to communicate with contractors who perform maintenance or upgrade
   work on the data center systems.
   


ABOUT THE JOB:

The Data Center team designs and operates some of the most sophisticated
electrical engineering, mechanical engineering and HVAC systems in the world.
Facilities Technicians at Google data centers operate, monitor and support
physical facilities conditions. Some of these duties will include heating and
cooling of air and water, power supply, generators, UPS systems, electrical
distribution and control and monitoring systems. You regularly help inspect,
maintain and repair various data center systems such as piping and non-critical
electrical or mechanical system components). You provide daily assistance to
senior technicians as you read blueprints/schematics, conduct tours of systems
and assess their working order.

As a master of exceptional practices, you develop creative approaches to
reducing operational costs while improving overall data center efficiency. You
ensure that environmental and safety standards are consistently met, identifying
problems and making repairs quickly In emergency situations or abnormal
conditions, you manage data center performance issues and outages to minimize
the recovery time from failures.The AI and Infrastructure team is redefining
what’s possible. We empower Google customers with breakthrough capabilities and
insights by delivering AI and Infrastructure at unparalleled scale, efficiency,
reliability and velocity. Our customers include Googlers, Google Cloud
customers, and billions of Google users worldwide.

We're the driving force behind Google's groundbreaking innovations, empowering
the development of our cutting-edge AI models, delivering unparalleled computing
power to global services, and providing the essential platforms that enable
developers to build the future. From software to hardware our teams are shaping
the future of world-leading hyperscale computing, with key teams working on the
development of our TPUs, Vertex AI for Google Cloud, Google Global Networking,
Data Center operations, systems research, and much more.

The US base salary range for this full-time position is $105,000-$151,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Inspect, maintain, and repair various data center systems such as piping and
   non-critical electrical or mechanical system components.
   
 * Provide daily assistance to technicians as you read blueprints/schematics,
   conduct tours of systems, and assess their working order.
   
 * Manage the uptime and maintenance of water pumps and treatment systems, HVAC,
   UPS, generators, electrical distribution, and control and monitoring systems.
   
 * Operate, monitor, maintain, and respond to abnormal conditions in the data
   center facilities systems and equipment.
   
 * Support startup, commissioning, and integration of new equipment and systems
   into facilities infrastructure.
   "
2025-12-12T09:01:55.769,Data Engineer II,Microsoft,"Overview
With continued growth in digital data and the desire to leverage data to measure in-production quality and address problems that touch all aspects of our lives, Microsoft’s Windows Servicing & Delivery Org is looking for an equally data- and quality-minded engineer to meet these challenges! Join the Update Platform team for the chance to have an impact on billions of customers every day. The Update Platform Team is responsible for ensuring the seamless delivery and integration of software updates and keeping our customers up-to-date and secure at all times.
As a Data Engineer II member of the Update Platform Insights team, you will be at the forefront of leveraging data to assess the quality of the product, detect issues before they reach broad customer application to assure top product quality for partners and customers alike while keeping billions of devices secure and up-2-date.

In this exciting role, you'll work with a diverse group of talented professionals, innovate for greater platform efficiency as well as leveraging the latest technologies and best practices to streamline our update processes with timely in-depth insights and intelligent features.

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.


Responsibilities
Data Management and Transformation: With guidance, you will apply modification techniques to transform raw data into compatible formats for downstream systems. Utilize software and computing tools to ensure data quality and completeness. Implement code to extract and validate raw data from upstream sources, ensuring accuracy and reliability.
Drive Customer Success: Through Data and Business Insight: You will play a pivotal role in building a metrics-driven culture that directly impacts product quality and customer outcomes. This role goes beyond technical execution—you will design and implement measurement frameworks from the ground up while applying a strategic, top-down perspective to ensure the right metrics are in place. Your ability to translate data into actionable insights, aligned with business priorities and rhythm of business, will enable informed decisions that drive high-quality product outcomes and measurable customer success.

Data Requirements and Modeling: Collaborate with stakeholders to document and understand data requirements. Evaluate project plans to assess data costs, access, and availability. Draft design specifications to model data flow and storage, ensuring data is easy to connect and manage.
Compliance: You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams. You’ll also learn about permissions and approvals for data access within a data pipeline.

Validation and Quality Mindset: Apply and use operational fundamentals to validate and ensure quality of the product as well as the underlying data pipeline and assets to secure trustworthiness in your data daily.

Customer Focus: Be driven by a focus on customer happiness and success. We as a team only succeed if our customers are secure and protected via the updates we deliver.


Qualifications
Required Qualifications:
Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 1+ year(s) experience in business analytics, data science, software development, data modeling, or data engineering
OR Bachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 2+ years experience in business analytics, data science, software development, data modeling, or data engineering
OR equivalent experience.
Other Requirements:
Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include but are not limited to the following specialized security screenings:
Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.
Preferred Qualifications:
3+ years with scripting and coding languages with a focus on data engineering, like SQL, KQL, python, Scope, C# (or similar object-oriented languages) and others.
1+ years of experience with building large data processing frameworks using technologies like Azure Data Factory, Azure Data Explorer, PowerBI and/or other public and Microsoft internal tools.
1+ years of experience in analytics to define, monitor, and optimize key performance indicators (KPIs) and connected business metrics that ensure measurable customer success.
1+ years of proven ability to orchestrate and sustain a data-driven rhythm of business, transforming insights into actionable strategies that align with organizational priorities and deliver impactful outcomes.
A solid quality mindset with the ability to deliver end-to-end data solutions that build partner and customer confidence, ensuring alignment with business objectives and measurable outcomes.
Experience with Git, ADO or equivalent Source Control Systems.
Experience with data visualization tools and how to effectively communicate Insights to consumers of varying types of audiences.
Experience leveraging AI to define and evaluate quality standards


Data Engineering IC3 - The typical base pay range for this role across the U.S. is USD $100,600 - $199,000 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $131,400 - $215,400 per year. 
Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:
https://careers.microsoft.com/us/en/us-corporate-pay

This position will be open for a minimum of 5 days, with applications accepted on an ongoing basis until the position is filled.


Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance with religious accommodations and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations."
2025-12-12T01:54:02.588,"Data Science Engineer, New College Grad- Master's/PhD (Santa Clara, CA)",Applied Materials,"Assist in developing data science software prototypes and interfaces for monitoring semiconductor process tools Develop Python scripts to implement key concepts Collaborate closely with algorithm developers to characterize the algorithms and benchmark their performance, collecting quantitative data assessing effectiveness Evaluate the effectiveness and accuracy of the algorithms by working closely with process and equipment experts, providing feedback to algorithm developers Provide solutions which can be implemented by engineers without a deep statistical or mathematical background Deploy and maintain solutions at service sites Troubleshoot solutions, provide workarounds, and assist users in using solutions Assess effectiveness of solutions and provide data science insight Communicate well with algorithm developers and process experts Train field engineers to use solutions Present work and conclusions clearly and succinctly to peers Work well in team, providing and receiving constructive input with team members Monitor and quantify the results of complex algorithms in a production environment. Train a variety of individuals on the operation of these algorithms. Experience with various Artificial Intelligence Solutions, including Large Language Models, Computer Vision and Generative AI applications. Python, MATLAB Familiarity with common data science techniques, including regression, decision trees, Principle components, PLS, various Neural networks, time-series techniques, Bayesian techniques, etc. Ability to troubleshoot software applications and perform basic DevOps for deployment Ability to interact with Process and Customer Engineers Semiconductor process or equipment experience preferred. Demonstrates depth and/or breadth of expertise in own specialized discipline or field May lead small functional teams or projects with moderate resource requirements, risk, and/or complexity Communicates difficult concepts and negotiates with others to adopt a different point of view Master's or PhD in Computer Science, Data Science, Software Engineering, Mechanical Engineering, or related field. Preferred GPA of 3.0 or above"
2025-12-12T01:52:09.253,"Vice President, Data Engineer",BNY,"Bachelor's or master's degree in computer science or a related discipline, or equivalent work experience is required. 10+ years of data modeling, database design and development or related experience is required. Prior experience in managing DB development team Experience modeling Financial data Prior experience modeling Client and Entitlement Data Good knowledge of Financial Accounts, Transactions and Positions data Hands-on experience with any RDBMS, preferably MS SQL Server or Oracle Good SQL knowledge Excellent communication skills Good Problem Solving & Analytical Skills Work experience in Financial Services Work experience on any data modeling tool, viz. Erwin, DBArtisan etc. Experience with writing ANSI SQL code Prior Experience with a scripting language, preferably Python Experience working with Cloud native databases Bachelor's or Master's degree in Computer Science or a related discipline, or equivalent work experience is required. Advanced degree is preferred. Experience in the Securities or Financial Services industry."
2025-12-12T01:08:33,Data Analytics Engineer,Masimo,"The Data Analytics Engineer will support Masimo’s Quality organization by developing dashboards, performing data analysis, and transforming large datasets into meaningful insights. This role partners closely with Quality Compliance, Product Assurance, Engineering, Operations and cross-functional stakeholders to enhance data visibility, drive data-informed decisions, and support continuous improvement across the organization. The ideal candidate is technically strong in analytics tools, comfortable working with structured and unstructured data, and eager to grow in a fast-paced and evolving environment.
Duties & Responsibilities
Develop and maintain Power BI dashboards and reports that translate complex data sets into clear, actionable information.
Perform data transformation and modeling using SQL, Power Query (M), and DAX to support quality metrics, KPIs, and trend analysis.
Support routine and ad-hoc data analytics requests related to customer feedback, failure analysis, operations, and compliance activities.
Analyze large datasets to identify trends and process improvement opportunities.
Collaborate with Quality Compliance, Product Assurance, and cross-functional engineering teams to ensure data accuracy, consistency, and alignment with business needs.
Communicate findings through effective data storytelling, written summaries, and monthly presentations to cross functional leaders across the organization.
Contribute to continuous improvement efforts in reporting automation, dashboard optimization, and analytics best practices.
Minimum & Preferred Qualifications and Experience
Experience
0–2+ years of experience in data analytics, business intelligence, or engineering analytics; internship or project experience considered.
Hands-on experience with SQL and Power BI (including Power Query/M and DAX).
Experience using Python or R for data manipulation, modeling, or visualization preferred.
Familiarity with data visualization tools (Power BI highly preferred; Tableau or Looker a plus).
Understanding of statistics, data modeling, or quantitative analysis techniques.
Skills & Competencies
Strong analytical and problem-solving skills with high attention to detail.
Ability to translate data into clear insights for technical and non-technical partners.
Strong verbal, written, and visual communication skills, with the ability to present confidently and engage diverse audiences.
Ability to work independently and in a team environment.
Curiosity and willingness to learn new tools, systems, and techniques.
Education
Bachelor’s degree in Data Analytics, Data Science, Business Intelligence, Computer Science, Engineering, or a related field required.
Master’s degree in a relevant field is a plus but not required.
Compensation:
The anticipated salary range for this position is $90,000 - $110,000 plus benefits. Actual placement within the range is dependent on multiple factors, including but not limited to skills, education, and experience. 
This position also qualifies for up to 10% annual bonus based on Company, department, and individual performance. 
Masimo offers benefits such as Medical, Dental, Vision, Life/AD&D, Disability Insurance, 401(k), Vacation, Sick, Holiday, Paid Maternity Leave, Flexible Spending Accounts, Voluntary Accident, Critical Illness, Hospital, Long-Term Care, Employee Assistance Program, Pet Insurance, On-site wellness clinic, fitness center, and cafe. All benefits are subject to eligibility requirements."
2025-12-12T00:39:10,Data Engineer,HealthPartners/GHI,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:39:10,Data Engineer,HealthPartners,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:14:05.56,Sr. Data Engineer,Apple,"As a Data Engineer on the Capacity Engineering team, you will help design,
build, and operate the data foundation that drives capacity, cost, and
power-related decisions across Apple’s infrastructure footprint. In this role,
you will: Architect, implement, and maintain large-scale batch and streaming
pipelines that ingest, process, and model infrastructure telemetry, cost,
metering, utilization, forecasting, and power metrics from multiple clouds and
bare metal environments. Design and evolve robust data models (with a strong
focus on dimensional modeling) and storage patterns that support analytics,
internal billing, and efficiency use-cases. Treat data as a product: define
quality checks, SLAs, and observability to ensure data is accurate, timely, and
trusted by stakeholders across Apple. Integrate and enrich raw signals with
metadata and attribution to power use cases such as internal billing/showback,
usage understanding, efficiency and optimization, clawbacks, planning, and
procurement. Collaborate closely with data scientists, software engineers,
platform teams, finance partners, program managers, and leadership to translate
requirements into scalable, reliable data solutions and services. Implement
standard methodologies for data governance, lineage, metadata management, and
security, in alignment with Apple’s standards for data protection and privacy.
Build end-to-end data solutions that include logging, anomaly detection, data
validation, cleaning, and transformation, with strong emphasis on monitoring,
debuggability, and continuous improvement. Contribute to the evolution of our
data and platform stack, including tooling, frameworks, and standards for
development, testing, deployment, and operations (CI/CD, infrastructure as code,
etc.).


DESCRIPTION


Apple’s Capacity data engineering team, within the Apple Services Engineering
organization, is building the centralized data backbone that powers how Apple
understands, plans, and optimizes its cloud and data center infrastructure. We
engineer a unified, trusted data lake that consolidates cost, metering,
utilization, forecasting, and power metrics produced by Apple platforms and
systems (including bare metal) across both third-party and Apple internal
clouds. Enriched with metadata and attribution, this becomes the single source
of truth for internal billing, understanding usage and utilization, clawbacks,
planning, procurement, and efficiency initiatives. We collaborate with platform
engineering, finance, capacity engineering, and leadership teams to build
large-scale data pipelines, enable descriptive and predictive analytics, and
power dashboards and products that support critical business decisions. This is
your opportunity to help design and operate highly visible, global-scale systems
processing petabytes of data and supporting hundreds of users across Apple. Come
join us to help deliver the next generation of infrastructure insights at Apple.


MINIMUM QUALIFICATIONS


Bachelors degree or equivalent experience in Computer Science, Information
systems, Software Engineering, Data Science or related field. Advanced degree in
a related field a plus. 5+ years of experience in data engineering (or
equivalent practical experience), including: Building and maintaining
large-scale ETL/ELT data pipelines Distributed computing (e.g., Spark / PySpark)
for data processing and automation Query performance optimization and tuning at
scale Hands-on experience with: Apache Spark and Airflow (or similar
workflow/orchestration tools) for efficient large-scale data pipelines Data
modeling, especially dimensional modeling, and designing schemas optimized for
analytics and reporting Big data platforms and/or data lake architectures


PREFERRED QUALIFICATIONS


Experience with cloud technologies, specifically AWS (e.g., S3, EMR, Lambda,
Glue, RDS/Redshift, or similar services) Tooling & ecosystem: Experience with
CI/CD tooling such as Jenkins (or similar tools) Experience with data
visualization / BI tools, such as Superset or Tableau (other tools like
QuickSight, QlikView, Cognos, or Business Objects are a plus) Experience with
containerization and orchestration, such as Docker and Kubernetes/EKS is a plus
Understanding of authentication and authorization (AuthN/AuthZ) patterns
Knowledge of data governance principles, data security best practices, and data
privacy regulations"
2025-12-12T00:00:00,Lead Data Engineer,Nuna,"At Nuna, our mission is to make high-quality healthcare affordable for everyone. We are dedicated to tackling one of our nation’s biggest problems with ingenuity, creativity, and a keen moral compass.
Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why.
Nuna has established its brand in the B2B space over the last decade by shifting the US healthcare system towards an incentive model that rewards healthcare providers for positive outcomes. Marshalling our collective backgrounds and insights, we are now crafting an innovative, consumer app - a clinically driven healthcare companion experience that leverages AI, gamification and social support techniques to improve outcomes for people with chronic conditions.
As a sign of the impact Nuna has already made in this space, Nuna was recently selected to join the Centers for Medicare & Medicaid Services (CMS) Health Tech Ecosystem, a landmark public-private initiative designed to transform healthcare for Americans.
YOUR TEAM
The Data org at Nuna is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research.
The Data Engineer team is a core part of the broader Data organization, which is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research. The Data Engineer team acts as the technical backbone for data architecture, platform development, and data operations, empowering the organization to deliver impactful data-driven solutions in healthcare.
YOUR OPPORTUNITIES
We are looking for someone who is excited to use their creativity and engineering skills to make a difference in healthcare. You will have a foundational role on a team building a consumer product that incentivizes healthy behavior. You will be responsible for the data architecture and direction of the data platform that powers our data operations and data science initiatives.
Own the architecture and evolution of the data platform, based on business needs and considering trade-offs in timelines, cost, and resources
Define and enforce standards for code development, contribution, and deployment for data engineering workflows.
Oversee integrations with external services, including data ingestion, distribution, and service-to-service data flows.
Contribute hands-on to data transformations and optimizations
Establish security, governance, and operational best practices for the data platform in collaboration with security and enterprise data engineering teams.
Curate and develop datasets needed to support Data org project deliverables
Collaborate with cross-functional partners in engineering, design, and product to develop solutions
Generate and prioritize new opportunities for improvements
Provide build vs buy assessments and recommendations as the platform expands
QUALIFICATIONS
Required Qualifications
Deep hands-on expertise in designing, coding, developing, and maintaining data platforms that support data analytics and data science use cases
Proven ability to design, develop and implement robust data ingestion pipelines (ETL) from external sources into a data platform.
Experience establishing standards for code development, deployment, and contributions in a data engineering environment.
Ability to solicit and translate customer and business needs into requirements and an evaluation framework
Interest in improving healthcare and working with interdisciplinary project teams
Clear communication and presentation skills
Experience with Databricks
Expertise in data platform languages such as python, pyspark and SQL
+ 5-10 years of industry experience with technical lead experience of running a data platform for business operations
Preferred Qualifications
MS in quantitative field (e.g. Data Science, Economics, Statistics, Engineering)
Experience building a data platform from zero to one
Experience working with healthcare data
Experience with SDLC and management of machine learning models (MLOps)
Bonus points if experience with MLOps on LLM/GenAi features (evals, context building, …)
We take into account an individual’s qualifications, skillset, and experience in determining final salary. This role is eligible for health insurance, life insurance, retirement benefits, participation in the company’s equity program, paid time off, including vacation and sick leave. The expected salary range for this position is $208,000 - $260,000. The actual offer will be at the company’s sole discretion and determined by relevant business considerations, including the final candidate’s qualifications, years of experience, and skillset.
Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status.
#LI-FK1"
2025-12-12T00:00:00,Development Project Engineer (Data Center Construction),QTS Data Centers,"Who we are: It's pretty exciting to find yourself standing in a pivotal moment in time. It’s even more exciting to be out front leading it. At QTS, our world-class data centers are supporting our customers’ most strategic growth initiatives, positioning us at the forefront of today’s dynamic digital transformation. As AI and cloud drive the demand for increased speed, capacity and capability, QTS has emerged as the global digital infrastructure leader, committed to connecting the world for good. Driven by purpose and fueled by a spirit of innovation, QTS designs, builds and operates some of the world’s most advanced, forward-thinking data centers. QTS is a portfolio company of Blackstone. QTS is Powered by People. People who play a vital role in our company’s culture, innovation and growth. People who are committed to contributing to the communities where we operate and work. People who are knowledgeable, resourceful and mission driven. Together, we do great things. Who You Are: The Development Project Engineer (Data Center Construction) is primarily responsible for assisting with the design, preconstruction and construction activities on a given project(s). The Development Project Engineer will interact on a daily basis with Facilities, Contractors, Designers, Engineers, Commissioning Agents, Vendors, and Data Center Operations & Corporate real estate staff and should have both written and oral communication skills commensurate with this level of regular communication. What You Will Do: Assist Development leadership and Project Manager with day to day activities and responsibilities Assist with multiple projects on a campus(es) and maintain updated budgets, schedules, and status reports for each Assist with updates on development program & project status on a monthly basis suitable for executive level reviews. Work with QTS stakeholders, design, and construction teams to help with master development program for site(s), including a complete campus design solution and capital budget. Assist with entitlement and permitting needs for each assigned site project(s) Assist with scopes of work for design, construction, commissioning services & participate in procurement and project cost estimates Evaluate and level pricing proposals for design, construction, and commissioning services Work closely with strategic procurement team on equipment procurement and delivery process Ensure appropriate submittals are coordinated with site stakeholders Assist with monitoring project budget / cost-to-date against overall project budget. Review project schedules and manage teams to on-time completion Review change order requests from contractors and negotiate pricing Assist with establishing site construction security procedures in conjunction with site security team Establish and maintain relationships serving as liaison with key QTS stakeholders Represent QTS Interests in OAC meetings Create & build relationships that enhance QTS’s ability to be a leader in creating the World’s Most Valuable Data Center Real Estate Aid in due diligence efforts on an as-needed basis by participating with real estate efforts on potential or new land banks and properties, including: Evaluate opportunities to design & build new data centers by working with key stakeholders: Corporate Real Estate, Connectivity, Power & Construction teams. Assist with establishing and monitoring entitlement and permit processes for individual projects as needed Work with the internal development team to enhance project management processes and protocols What You Will Need to be Successful (basic qualifications): Bachelor’s degree in Engineering or Construction Management field or equivalent professional experience Experience with Microsoft Office suite, specifically PowerPoint for use in communicating program updates to executive level, and Excel to create and maintain site program & individual project budgets Excellent interpersonal skills with the ability to interface with all levels of the organization Must be a capable, proven team player that both fosters and operates well within internal and external team environments. Able to solve problems at a tactical and functional level Strong Verbal and Written Communication Skills Ability to manage multiple projects simultaneously Other Key Skills: One or more years of professional experience in commercial construction practices and procedures, including management of Lump Sum, Construction Management @ Risk, and Design Build project delivery methods from conceptual development through procurement to close out Documented experience using AutoCAD, BlueBeam, P6, and CxAlloy Experience or exposure in mission critical data center facilities Experience with management of MEP trades Experience managing document control for active data center build sites The Perks (and these are just a few!): Q-Rest Sabbatical Employee Stock Purchase Plan QTS scholarship for dependents Eagle Club Award Trip Eligibility Paid Volunteer and Floating days Tuition Assistance, Parental Leave and Military Leave Assistance We conform to all the laws, statutes, and regulations concerning equal employment opportunities and affirmative action. We strongly encourage women, minorities, individuals with disabilities and veterans to apply to all of our job openings. We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, gender identity, or national origin, age, disability status, Genetic Information & Testing, Family & Medical Leave, protected veteran status, or any other characteristic protected by law. We prohibit retaliation against individuals who bring forth any complaint, orally or in writing, to the employer or the government, or against any individuals who assist or participate in the investigation of any complaint or discrimination claim. The ""Know Your Rights"" Poster is included here: Know Your Rights (English) Know Your Rights (Spanish) The pay transparency policy is available here: Pay Transparency Nondiscrimination Poster-Formatted QTS is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please send an e-mail to talentacquisition@qtsdatacenters.com and let us know the nature of your request and your contact information. It’s exhilarating to find yourself at a pivotal moment in history— and even more so to be leading the way. At QTS Data Centers, we are proud to stand at the forefront of today’s dynamic digital transformation. Our world-class data centers empower our customers’ most strategic growth initiatives, positioning us as a global leader in digital infrastructure. As AI and cloud technologies fuel the demand for increased speed, capacity, and innovation, QTS has emerged as the global digital infrastructure leader. We are committed to connecting the globe for good. Driven by purpose and a spirit of innovation, we design, build, and operate some of the most advanced data centers worldwide. In addition to our cutting-edge technology, we are dedicated to sustainability, incorporating renewable energy solutions to minimize our environmental footprint and drive meaningful impact. As a proud portfolio company of Blackstone, QTS is uniquely positioned to achieve ambitious growth and innovation goals. At QTS, we are Powered by People. Our team members are the cornerstone of our culture, innovation, and growth. They are mission-driven, resourceful, and committed to making a positive impact in the communities where we live and work. Together, we’re achieving remarkable things and shaping the future of digital infrastructure. And we’d like to invite you to join us. In addition to a variety of benefit packages, QTS goes above and beyond for our employees: Roth and Traditional 401(k) matching contributions with immediate vesting Every employee is bonus or commission eligible Generous PTO, Paid Volunteer Days Plus Floating Holidays Stock Purchase Plan (SPP) 11 paid Holidays Annually/Holiday compensation when worked Pet and Legal Insurance Q-Rest Sabbatical Program Q-Anniversary Service Award Program Parental Leave for primary and secondary caregivers Military Benefits Package QTS Charitable Matching Gift Program QTS Scholarship for Employee Dependents QTS Crisis Fund Wellness Program Tuition Reimbursement Program"
2025-12-12T00:00:00,"Data Engineer I, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $109,300.00 - $180,200.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data across the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape by designing, building, and deploying data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning, and business intelligence initiatives. You will work closely with Data Science and Decision Science teams to build, test, and maintain data pipelines and model workflows that support both analytical research and production use cases in our Databricks/AWS/Snowflake environment. In addition to your strong analytical mind, you will bring an inquisitive attitude and the ability to translate the stories found in data into actionable insights while contributing to technical discussions and process improvements. Applicants must be authorized to work for ANY employer in the U.S. The company does not sponsor/support H-1B petitions, TN, or Forms I-983/STEM OPT, for this role. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions. Design data solutions. Analyze sources to determine value and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Collaborate within and across teams to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate. Test data movement, transformation code, and data components. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent. Six years of related experience. Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions. Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on. Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems. Strong verbal and written communication skills with the ability to interact with team members and business partners. Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Four years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,"Senior Data Engineer, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $139,400.00 - $230,000.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions. Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies. Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate. Collaborate across team to support delivery and educate end users on complex data products/analytic environment. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent Ten years of related experience Primary Job Requirements: Architect and design scalable, secure data solutions using AWS, Databricks, and Ab Initio. Lead technical direction for data engineering initiatives across cloud and on-premises infrastructure. Hands-on development: build ETL pipelines, optimize Spark jobs, and create Ab Initio graphs. Troubleshoot production issues and provide technical guidance to junior engineers. Conduct mentoring sessions and offer technical guidance to the 20-person admin team. Collaborate with DBA teams, business analysts, and QA teams to ensure data governance and quality. Manage infrastructure deployment and optimize cloud resources. Lead technical design reviews and architecture discussions. Implement data integration solutions and ensure compliance with data protection regulations. Establish and enforce coding standards, best practices, and data governance policies. Technical Skills: AbInitio: Expert proficiency with GDE, Co>Operating System, EME, BRE, Express>It, metaprogramming (PDL) Programming: Python, PySpark, SQL Cloud: AWS architecture and services Databricks: Workspace management, cluster configuration, Delta Lake, Unity Catalog Data Warehousing: Strong understanding of data modeling, dimensional modeling (star/snowflake schemas) ETL/ELT: End-to-end ETL development lifecycle Version Control: Git, CI/CD pipelines Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices. Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems. Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers. Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize. Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas. Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Five years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,Data Flow Engineer,Scientific Research Corporation,"Description
The Data Flow Engineer will be a member of a Cryptologic Carry-On Program (CCOP) and Ship’s Signals Exploitation Equipment (SSEE) Systems Engineering team primarily responsible for ensuring the processing and distribution of data to and from intelligence community networks. The ideal candidate will have a history of direct involvement with successful NiFi data flow engineering and resolving Navy hardware and software functionality problems by providing a high degree of timely customer service and technical expertise in support of the US Navy information warfare community.
Installing, configuring, integrating, and maintaining NiFi servers and processors into new or existing system architectures
Verifying and maintaining all NiFi processors and flows to and from deployed (and test) systems, from the field system through customer back-end repositories
Assisting end users with the operational readiness and configuration of deployed systems for optimal data flow to satisfy customer requirements
Designing and developing NiFi processors and flows for deployed systems, containing multiple subsystems and requiring integration with external networks
Implementing expression language in NiFi processors in response to emerging customer requirements
Exhibiting developed verbal and written communication skills and the ability to express concepts and ideas in a clear and concise manner; employing technical writing techniques
Performing as a team player, dedicated to the endeavors of the mission, the customer, and the team itself
Being a self-starter who is accountable and requires minimal direction and supervision; capable of multitasking and working several complex and diverse tasks with simultaneous or near simultaneous deadlines
#LI-LL1
Requirements
Must possess an active TS/SCI clearance and be able to obtain a CI Polygraph
Requires a bachelor’s degree in related technical field or equivalent work experience
Intermediate Linux Command Line Interface (CLI) experience
1-3 years of Apache Niagara Files (NiFi) experience (negotiable with other qualifications)
Strong background in using and troubleshooting Software Defined Radio (SDR) systems
Fundamental knowledge of wireless protocols in common use
Experience providing technical support to customers over Internet Relay Chat (IRC) or similar applications
Familiarity with back-end databases and repositories
Must be willing to travel up to 10% of the year
Must currently be DoD 8570-compliant with the equivalent of an IAT II certification or have the ability to do so within 6 months of employment
Desired Skills
Current Linux+/LPIC 1 and/or Network+ certification
Familiarity with Regular Expression (REGEX), Cisco Networking, and Amazon Web Services (AWS)
Expert-level SDR knowledge and experience
Experience with strategic-level intelligence processes
Basic computer programing experience (i.e. Python, JavaScript, bash)
Prior Navy CTR/CTM/CTN with shipborne, expeditionary, or other comparable experience 
Clearance Information
SRC IS A CONTRACTOR FOR THE U.S. GOVERNMENT. THIS POSITION WILL REQUIRE U.S. CITIZENSHIP AS WELL AS A U.S. GOVERNMENT SECURITY CLEARANCE AT THE TOP SECRET / SCI LEVEL with CI POLY ELIGIBILITY
Travel Requirements
up to 10% travel may be required
About Us
Scientific Research Corporation is an advanced information technology and engineering company that provides innovative products and services to government and private industry, as well as independent institutions. At the core of our capabilities is a seasoned team of highly skilled engineers and scientists with multidisciplinary backgrounds. This team is challenged daily to provide cutting edge technology solutions to our clients.
SRC offers a generous benefit package, including medical, dental, and vision plans, 401(k) with a company match, life insurance, vacation and sick paid time off accruals starting at 10 days of vacation and 5 days of sick leave annually, 11 paid holidays, tuition reimbursement, and a work environment that encourages excellence and more. For positions requiring a security clearance, selected applicants will be subject to a government security investigation and must meet eligibility requirements for access to classified information.
EEO
Scientific Research Corporation is an equal opportunity employer that does not discriminate in employment.
All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other protected characteristic under federal, state or local law.
Scientific Research Corporation endeavors to make www.scires.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact jobs@scires.com for assistance. This contact information is for accommodation requests only and cannot be used to inquire about the status of applications."
2025-12-12T00:00:00,"Research Data Engineer II, CHeT Analytics",University of Rochester,"As a community, the University of Rochester is defined by a deep commitment to Meliora - Ever Better. Embedded in that ideal are the values we share: equity, leadership, integrity, openness, respect, and accountability. Together, we will set the highest standards for how we treat each other to ensure our community is welcoming to all and is a place where all can thrive. Job Location (Full Address): 265 Crittenden Blvd, Rochester, New York, United States of America, 14642 Opening: Worker Subtype: Regular Time Type: Full time Scheduled Weekly Hours: 40 Department: 400980 Neuro-Ctr Health & Tech/Admin Work Shift: UR - Day (United States of America) Range: UR URG 113 Compensation Range: $77,216.00 - $115,824.00 The referenced pay range represents the minimum and maximum compensation for this job. Individual annual salaries/hourly rates will be set within the job's compensation range, and will be determined by considering factors including, but not limited to, market data, education, experience, qualifications, expertise of the individual, and internal equity considerations. Responsibilities: GENERAL PURPOSE Participates in the design, implementation and maintenance of analytical and data science-based software and data pipelines to support scientific workflows. Focuses on developing and supporting data collection frameworks that integrate structured and unstructured data from multiple sources and systems to support specific research study teams. Supports the development and maintenance of infrastructure systems (e.g., data warehouses, data lakes), including data access Application Programming Interface(s) (APIs). Works in partnership with team members to provide robust, scalable software solutions to the research enterprise. ESSENTIAL FUNCTIONS Builds, maintains and evolves general Extract, Transform and Load (ETL) data pipelines and overall data architecture to accommodate a growing amount of data from a variety of large research data sources. Works with research team members to convert business and technical requirements into professional software solutions. Ensures timely completion of tasks while managing multiple assignments, project timelines and business user expectations. Designs and implements custom research project-specific data workflow solutions for data collection, management, reporting and analytics. Contributes to the scientific research. Adheres to defined application development life-cycle practices, including but not limited to, requirements gathering, writing test plans, source code management, peer code review and quality assurance through unit/system/user acceptance testing. Participates in specification, implementation and execution of testing procedures to ensure quality of deliverables, system and data workflow reliability. Produces and maintains comprehensive technical documentation for all systems under the Engineer's responsibilities. Keeps abreast of current application developments through continuing education, professional reading, online forums, conferences, workshops and professional groups. Other duties as assigned. MINIMUM EDUCATION & EXPERIENCE Bachelor's degree in Data Science, Biomedical Science, Computer Science, Mathematics, Statistics or similar discipline and 2 years of experience in technology and data intensive roles and environments required Or equivalent combination of education and experience Programming experience in Structured Query Language (SQL) and one other applicable language (Java, Python, and/or R) required Experience with Change Management solutions required Experience with Version Control solutions (e.g. Git) required Experience implementing and supporting data management systems in a scientific, research context (e.g. biospecimen software, electronic laboratory notebooks, REDCap) preferred Experience with Linux, container and cloud technologies (e.g. HPC, IaaS and PaaS) preferred KNOWLEDGE, SKILLS AND ABILITIES Understanding of data analytics and statistical methods required Expertise of software engineering best practices such as version control and software release management required Strong analytical and problem-solving skills required Strong organizational skills required Ability to work with others in a matrix management environment required Excellent communication skills for describing progress and challenges to stakeholders required Attention to detail, patience and a positive, customer-centric attitude required Strong technical presentation skills required Demonstrated ability to develop proficiency with unfamiliar toolsets preferred Familiarity with file formats, metadata, and data exchange and storage standards applicable in management of scientific and clinical research required The University of Rochester is committed to fostering, cultivating, and preserving an inclusive and welcoming culture to advance the University’s Mission to Learn, Discover, Heal, Create – and Make the World Ever Better. In support of our values and those of our society, the University is committed to not discriminating on the basis of age, color, disability, ethnicity, gender identity or expression, genetic information, marital status, military/veteran status, national origin, race, religion, creed, sex, sexual orientation, citizenship status, or any other characteristic protected by federal, state, or local law (Protected Characteristics). This commitment extends to non-discrimination in the administration of our policies, admissions, employment, access, and recruitment of candidates, for all persons consistent with our values and based on applicable law. Notice: If you are a Current Employee, please log into myURHR to search for and apply to jobs using the Jobs Hub. Your application, if submitted using this portal, cannot be moved forward. Learn. Discover. Heal. Create. Located in western New York, Rochester is our namesake and our home. One of the world’s leading research universities, Rochester has a long tradition of breaking boundaries—always pushing and questioning, learning and unlearning. We transform ideas into enterprises that create value and make the world ever better. If you’re looking for a career in higher education or health care, the University of Rochester may offer the perfect opportunity for your background and goals. At the University of Rochester, we are committed to fostering, cultivating, and preserving an inclusive and welcoming culture and are united by a strong commitment to be ever better—Meliora. It is an ideal that informs our shared mission to ensure all members of our community feel safe, respected, included, and valued."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,Data Engineer II (Onsite),RTX,"Date Posted: 2025-12-12 Country: United States of America Location: PW147: PW OKC Campus 8120 S. Air Depot Blvd , Oklahoma City, OK, 73135 USA Position Role Type: Onsite U.S. Citizen, U.S. Person, or Immigration Status Requirements: U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Security Clearance: None/Not Required Pratt & Whitney is working to once again transform the future of flight—designing, building and servicing engines unlike any the world has ever seen. And because transformation begins from within, we’re seeking the people to drive it. So, calling all curious. Come ready to explore and you’ll find a place where your talent takes flight—beyond the borders of title, a country or your comfort zone. Bring your passion and commitment and we’ll welcome you into a tight-knit team that takes our mission personally. Channel your drive to make a difference into shaping an organization and an industry that’s evolving fast to the future. At Pratt & Whitney, the difference you make is on display every day. Just look up. Are you ready to go beyond? You will be an integral part of Pratt & Whitney’s Sustainment Operational Excellence Data Engineering & Analytics team. This team supports the global aftermarket maintenance and overhaul of engines for the F117, F119, and F135 programs. We are looking for a Data Engineer II to advance the digital and data capability of the Military Engines Global Depot Network organization. You will be working on exciting new technologies like cloud and open-source tools among others, and be responsible for cleaning, standardizing, transforming, and configuring data products within our emerging data mesh. What You Will Do: Create and maintain scripts written in Spark SQL or Pyspark in Databricks Notebooks. Also, work with SMEs to understand complex datasets for next generation data products and data visualizations to create data mesh tables. Develop scalable and sustainable data product transformations that curate, clean and store data efficiently; perform statistical analysis to quantify completeness and validity; perform bug fixes and apply enhancements to the models when the need arises. Ensure high performance and reliability of data transformation processes and pipelines. Collaborate cross-functionally to gather insights, refine requirements, and ensure alignment between product goals and team efforts. Document data processes, logic, and data sources to ensure transparency and knowledge sharing as well as support the overall team with any ad-hoc data related tasks. Work to convert our existing data visualizations in Power BI to use Databricks instead of Azure Synapse. Keep up to date with technologies and use advanced cloud data warehouse and data transformation techniques to build innovative solutions. Qualifications You Must Have: A degree in Science, Technology, Engineering or Mathematics (STEM) with 2+ years of experience in the use of SQL and/or Python to transform, clean, and integrate data from a variety of source pipelines. U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Qualifications We Prefer: Experience with transformation tools such as dbt, Databricks pipelines, or relevant tools such as SSIS, ADF, or Matillion. Demonstrated experience with Git/GitHub; experience working in cloud data warehouses like Databricks. Familiarity with agile methodologies and Kanban boards. Self-motivated, team player with good communication skills. Ability to focus on results and successfully manage multiple tasks/projects. An astute individual, with the ability to build strong cross-functional relationships; excited at the prospect of developing and implementing new data products that add organizational value & improve decision making capabilities. Business experience with Aerospace or other heavy manufacturing industry. An understanding of ER Diagrams for data modeling. Demonstrated understanding of data mesh design principles and data engineering best practices. Learn More & Apply Now! What is my role type? In addition to transforming the future of flight, we are also transforming how and where we work. We’ve introduced role types to help you understand how you will operate in our blended work environment. This role is: Onsite: Employees who are working in Onsite roles will work primarily onsite. This includes all production and maintenance workers, as they are essential to the development of our engines. Candidates will learn more about role type and current site status throughout the recruiting process. For onsite and hybrid roles, commuting to and from the assigned site is the employee’s personal responsibility. As part of our commitment to maintaining a secure hiring process, candidates may be asked to attend select steps of the interview process in-person at one of our office locations, regardless of whether the role is designated as on-site, hybrid or remote. The salary range for this role is 66,000 USD - 130,000 USD. The salary range provided is a good faith estimate representative of all experience levels. RTX considers several factors when extending an offer, including but not limited to, the role, function and associated responsibilities, a candidate’s work experience, location, education/training, and key skills. Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement. Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company’s performance. This role is a U.S.-based role. If the successful candidate resides in a U.S. territory, the appropriate pay structure and benefits will apply. RTX anticipates the application window closing approximately 40 days from the date the notice was posted. However, factors such as candidate flow and business necessity may require RTX to shorten or extend the application window. RTX is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or veteran status, or any other applicable state or federal protected class. RTX provides affirmative action in employment for qualified Individuals with a Disability and Protected Veterans in compliance with Section 503 of the Rehabilitation Act and the Vietnam Era Veterans’ Readjustment Assistance Act. Privacy Policy and Terms: Click on this link to read the Policy and Terms RTX is an aerospace and defense company that provides advanced systems and services for commercial, military and government customers worldwide. It comprises three industry-leading businesses – Collins Aerospace, Pratt & Whitney, and Raytheon. Its 195,000 employees enable the company to operate at the edge of known science as they imagine and deliver solutions that push the boundaries in quantum physics, electric propulsion, directed energy, hypersonics, avionics and cybersecurity. The company, formed in 2020 through the combination of Raytheon Company and the United Technologies Corporation aerospace businesses, is headquartered in Arlington, Virginia."
2025-12-12T00:00:00,"Senior Engineer, BAW R&D Trimming and Data Infrastructure",Qorvo,"
                Qorvo (Nasdaq: QRVO) supplies innovative semiconductor solutions that make a better world possible. We combine product and technology leadership, systems-level expertise and global manufacturing scale to quickly solve our customers' most complex technical challenges. Qorvo serves multiple high-growth segments of large global markets, including consumer electronics, smart home/IoT, automotive, EVs, battery-powered appliances, network infrastructure, healthcare and aerospace/defense. Visit www.qorvo.com to learn how our innovative team is helping connect, protect and power our planet.

 
Summary:
 Qorvo’s BAW R&D Data Infrastructure team is seeking a talented engineer for semiconductor data infrastructure, frequency trimming and process automation. The candidate chosen for this role will develop data infrastructure and software tools to support efficient development and production of new Bulk Acoustic Wave (BAW) filter technologies. The candidate will use MATLAB, data analysis tools (SpotFire), databases and other software tools for process control improvements, faster design cycles, and general automation to efficiently develop and produce new technologies.
 
Key Roles and responsibilities:

Research, implement, deploy, and maintain internal software applications used by Manufacturing and R&D Engineering teams to process and trim BAW filters wafers.
Work closely with Process Integration and Process Engineering teams to understand new BAW technology needs to define requirements and implement.
Provide comprehensive support to internal customers: resolve outstanding issues for R&D engineers, designers, and production at Qorvo’s fabrication facility.
Own critical data infrastructure projects and successfully deliver results in a timely manner

 
Technical Knowledge/Skills/Abilities Required:

Excellent MATLAB or Python programming capabilities
Knowledge of semiconductor processing
Practical knowledge of software development and object-oriented programming
Excellent debugging and problem-solving skills


Strong data analysis and mathematical skills


Experience with version control utilizing Git and GitLab
Good knowledge of SQL database (Oracle is a plus)
Experience in the full life cycle of the software design process including requirement analysis, design, prototyping, coding, documentation, implementation, and maintenance

 
Personal Skills:

Self-motivated, independent, proactive, detail oriented, and responsible team-player
Excellent analytical skills
Comfortable working in a dynamic and fast paced environment
Passion for innovation and emerging technologies
Excellent communication and interpersonal skills
Able to handle multiple priorities
Proficient in English

 
Desired experiences:

Experience with software development for semiconductor processing 
Expertise in electromagnetics, physics, or material science
Expertise in Oracle PL/SQL databases
Experience with data analysis tools such as Spotfire or similar application
Experience with GitLab workflows and pipeline automation 
Experience with Visual Studio Code and GitHub Copilot
Experience with unit testing in past development projects

 
Qualifications:
Education & Experience:

BS or MS in Computer Science, Electrical Engineering, Physics or Material Science
5+ years of code development experience.(or if Master's degree 2+ years experience)

 
This position is not eligible for visa sponsorship by the Company.
 
#LI-KR1
 MAKE A DIFFERENCE AT QORVO   

 We are Qorvo. We do more than create innovative RF and Power solutions for the mobile, defense and infrastructure markets – we are a place to innovate and shape the future of wireless communications. It starts with our employees. As a unified global team, we bring a commitment to excellence, growth and a passion for creating what's next. Explore the possibilities with us.

We are an Equal Employment Opportunity (EEO) employer and welcome all qualified applicants. Applicants will receive fair and impartial consideration without regard to any characteristics protected by applicable law, including race, color, religion, sex (as defined by law), national origin, age, military or veteran status, genetic information, or disability.  
                
    "
2025-12-12T18:28:05.616,Sr Staff Engineer Software (Data Plane Applications),Palo Alto Networks,"Company Description
Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
Who We Are
We believe collaboration thrives in person. That’s why most of our teams work from the office full time, with flexibility when it’s needed. This model supports real-time problem-solving, stronger relationships, and the kind of precision that drives great outcomes.
Job Description
Your Career
Prisma Access™ (formally GlobalProtect Cloud Service) provides protection straight from the cloud to make access to the cloud secure. It combines the connectivity and security you need and delivers it everywhere you need it. Using cutting-edge public and private cloud technologies extending the next-generation security protection to all cloud services, customers on-premise remote networks and mobile users.
We are seeking an experienced Software Engineer to design, develop and deliver next-generation technologies within our Prisma Access team. We want passionate engineers who love to code and build great products. Engineers who bring new ideas in all facets of software development. We are looking for leaders who take ownership of their areas of focus and who are driven to solve problems at every level. Collaboration and teamwork are at the foundation of our culture and we need engineers who can communicate at a high level and work well with others towards achieving a common goal.
Your Impact
Design, develop and implement highly scalable software features and infrastructure on our next-generation security platform ready for cloud native deployment from inception to completion
Work with different development and quality assurance groups to achieve the best quality - You accomplish this by being hands-on, creating tools, processes, and systems that produce transparency, alignment, and direction
Profile, optimize and tune systems software (management/control/dataplane) for efficient cloud operation
Work with DevOps and the Technical Support teams to troubleshoot customer issues
Work with other software development team to apply PanOS features on Prisma Access
Interview, mentor and coach new team members 
Qualifications
Your Experience 
5+ years of experience in developing and troubleshooting dataplane applications
Required hands-on programming experience in Python and Go
Nice to have C/C++ Programming
Strong Data structures/Algorithms
Strong analytical skills, problem solving and debugging skills
Nice to have experience with LLMs and GenAI applications. Or Machine learning/Data science with experience in ETL, curating datasets, running evals. 
Experience with building applications in the cloud
In-depth understanding of Operating System principles and OS like Linux/Unix
In-depth understanding of networking concepts and TCP/IP stack, TLS
Exposure to building Microservices 
Enjoys working with many different teams with strong collaboration and communication skills
Solid foundation in design, data structures, and algorithms, and strong analytical and debugging skills
Education : M.S./B.S. degree in Computer Science or equivalent military experience required
Additional Information
The Team
Our engineering team is at the core of our products – connected directly to the mission of preventing cyberattacks. We are constantly innovating – challenging the way we, and the industry, think about cybersecurity. Our engineers don’t shy away from building products to solve problems no one has pursued before.
We define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment.
Compensation Disclosure
The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $170,000 - $190,000/YR. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.
Our Commitment

We’re problem solvers that take risks and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at [email protected].
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
Is role eligible for Immigration Sponsorship?: Yes"
2025-12-12T18:20:27,Data Engineer,Real Chemistry,"At Real Chemistry, making the world a healthier place isn’t just an aspiration—it’s our everyday reality. Our drive to transform healthcare is informed by our blend of deep scientific expertise, human-centred creativity, and AI-driven insights, fostering a unique environment where innovation thrives and our people are impact-obsessed. As a global agency, we provide a full suite of services across healthcare communications and marketing to our clients, including top players in the pharmaceutical and biotech industries.
Our #LifeatRealChem culture is rooted in our people—we believe we are best together and are committed to excellence for both our clients and colleagues. Whether you're a seasoned professional or just starting your career, if you share our passion for healthcare and connection, we invite you to explore our opportunities.
Discover your purpose. Embrace innovation. Experience #LifeatRealChem.
Job Summary 
We’re looking for a hands-on Data Engineer to help build and maintain the data infrastructure that powers our AI products and solutions. This role sits within our AI organization and focuses on designing, developing, and optimizing scalable data pipelines, data models, and cloud-based data systems. You’ll collaborate closely with data scientists, ML engineers, product teams, and other technical partners to ensure high-quality, reliable, and well-structured data is available across the organization. 
Key Responsibilities 
Data Pipeline Development 
Build, optimize, and maintain scalable ETL/ELT pipelines for structured and unstructured data. 
Implement reliable, fault-tolerant ingestion and transformation workflows. 
Automate routine data processes where possible. 
Data Architecture & Modeling 
Develop well-structured data models that support analytics, ML use cases, and downstream applications. 
Support the design and enhancement of AI-related data architecture across cloud environments. 
Data Quality & Governance 
Implement automated data validation, monitoring, and alerting. 
Ensure high data accuracy, completeness, and integrity across ingestion and transformation layers. 
Cross-Functional Collaboration 
Partner with data scientists, ML engineers, product managers, and IT teams to understand data requirements and translate them into technical solutions. 
Troubleshoot issues and support stakeholders with data access and pipeline improvements. 
Cloud & Infrastructure 
Work with modern cloud platforms (AWS, Azure, or GCP) and associated data storage, compute, and orchestration services. 
Support deployment, scaling, and operational health of data systems. 
Innovation & Continuous Improvement 
Stay current with emerging data engineering tools and best practices. 
Propose opportunities to improve performance, efficiency, or reliability within the data stack. 
Qualifications & Skills 
Education & Experience 
Bachelor’s degree in Computer Science, Data Engineering, or related technical field (or equivalent experience). 
3–7 years of hands-on experience in data engineering or data pipeline development. 
Technical Skills 
Strong SQL skills and proficiency in Python or Scala. 
Experience with data warehousing technologies such as Snowflake, BigQuery, Redshift, or Databricks. 
Hands-on experience with cloud services (AWS, Azure, or GCP). 
Knowledge of data modeling, schema design, and ETL/ELT principles. 
Familiarity with distributed computing frameworks such as Spark or Flink. 
Experience with workflow orchestration tools like Airflow, Prefect, or Dagster is a plus. 
Soft Skills 
Strong problem-solving skills and attention to detail. 
Ability to communicate technical concepts clearly to peers and cross-functional partners. 
Comfortable working in a fast-moving, collaborative environment. 
Preferred Qualifications 
Experience with streaming data tools such as Kafka or Kinesis. 
Experience building CI/CD pipelines for data workflows. 
Experience in healthcare, biotech, life sciences, or commercial/marketing data environments. 
Experience in agency or consulting settings. 
Posting Salary
$140,000—$175,000 USD
Real Chemistry is proud to be Great Place to Work® certified; check out what our people shared about our culture and workplace on our Great Places to Work Profile here.
We believe we can do our best when feeling our best, which is why we’ve put together a benefits program designed to give you the support you and your family need at every stage of life. Real Chemistry offers a comprehensive benefit program and perks, tailored to your region. Globally, this includes offices in our key markets with free snacks to keep you running all day long, generous holiday and paid time off, options for private medical, dental, and vison plans, and support in saving for the future. Other perks include mental wellness coaching and support and access to more than 13,000 online classes with LinkedIn Learning. Learn more about our great benefits and perks and search specific offerings in your region at: www.realchemistrybenefits.com.
Working with Real HART: Since the pandemic, we have adapted to how our people told us they want to work. We have office locations in cities in the US, UK, and Europe with many employees and clients that serve as hubs where and when they need us. For employees who are within an hour of one of our offices, we expect attendance in the office two days per week, either at a Real Chemistry office or onsite with clients. We are also actively opening new office locations, so if one opens near you, our Real HART policy will apply. We are not looking for attendance for the sake of attendance but believe that the opportunity to coordinate in-office team meetings, 1:1 meetings with managers, taking advantage of on-site learning, and connecting with client partners is a critical to delivering on our purpose of making healthcare what it should be. Outside of these offices, we have regions, where people work remotely but come together quarterly for collaboration, culture and learning opportunities. We call this our Real Hybrid and Regional Teams (Real HART) approach. Real Chemistry believes we are best together – and our workplace strategy fosters connection and collaboration in person – but also supports flexibility for our people.
Real Chemistry is an Equal Opportunity employer. We continually strive to build and sustain an inclusive and equitable work environment where our employees feel empowered to leverage all they bring from their personal lived experience and professional expertise, to make our team the best in the industry. We encourage motivated and qualified applicants to apply without regard to race, color, religion, sex (including pregnancy), sexual orientation, gender identity/expression, ethnic or national origin, age, physical or mental disability, genetic information, marital information, or any other characteristic protected by federal, state, or local employment discrimination laws where Real Chemistry operates. Should you require accommodations throughout the interview process please let your recruiter know.
*Notice: Real Chemistry and its affiliates' names are being misused by scammers through messaging services, fake websites, and apps. Do not share personal or financial information or make payments to any unverified sources claiming to be connected to Real Chemistry. We are working to stop these unauthorized activities and protect our community. Read more here."
2025-12-12T17:29:23,Senior Python Data Engineer - (Remote)  ,KBRA,"Position Title: Senior Python Data Engineer - (Remote) 
Entity: KBRA Holdings LLC
Employment Type: Full-Time
Location: Remote (Remote only in CA, CO, DC, FL, IL, MD, NJ, MA, NY, PA, SC, TX, VA)
Summary/Overview:
KBRA (KBRA Holdings, LLC) is seeking an engaged and proactive Senior Python Data Engineer to work on our financial analytical system. We want someone who loves solving difficult problems, digs deeply to understand the domain in which they’re working, and excels at creating high-quality software in a collaborative environment.
About the Team:
We believe that small, empowered teams can do amazing things. Across the engineering organization, we work hard to make the best systems for our customers using modern engineering practices. We are intentional in our investments in time and effort around creating a safe and successful workplace for our team members. We understand software engineering goes beyond the 1’s and 0’s and prioritize concrete value for our customers.
About the Job:

This role involves joining an existing team with a well-defined product vision. This team operates collaboratively, and there is an expectation to get involved in all aspects of design, delivery, and support of our systems.

This role emphasizes collaboration with our technical and non-technical counterparts to learn our domain and its unique challenges, while delivering value to our customers. It also requires collaboration with our other engineering, design, product, and platform teams to develop, build, run, and support the system.
About You:

You will be successful in this role if you:
Develop, test, and maintain scalable Python applications.
Collaborate with product managers, designers, and other engineers to deliver high-quality software.
Write clean, efficient, and reusable code following best practices.
Participate in code reviews to ensure code quality and share knowledge with the team.
Troubleshoot and debug issues in a timely manner.
Contribute to the design and architecture of new features and systems.
Have a sense of ownership and craftsmanship around the code base and your work.
Enjoy helping other developers grow and learn new technologies.
Display a strong track record of mentorship with engineers at various levels.
Are mindful of application security and performance.
Take pride in learning, and want opportunities to learn throughout your day-to-day.
Possess a pragmatic mindset. 
Familiarity with Generative AI tools such as ChatGPT for research, data insights, and general productivity is a plus.
Must have skills:
3–6 years of professional software engineering experience, with a strong portfolio of full stack development work.
Proficiency in Python, including experience with web frameworks such as Flask.
Cloud experience, particularly with AWS (Amazon Web Services).
Experience integrating frontend applications with RESTful APIs and backend services.
Relational and non-relational databases (SQL Server, Snowflake and MongoDB).
Debugging, issue resolution, and troubleshooting.
Nice to have skills:
Familiarity with UX design tools (Figma) and solid understanding of the design-engineering hand-off process
Containerized development and deployment (i.e. Docker, Docker swarm, Kubernetes)
Infrastructure as Code (Terraform)
Familiarity with deployment pipelines, CICD tools.
Exposure to financial systems or credit modeling is strongly preferred.
Salary Range:
The anticipated annual base salary range for this full-time position is $130,000 - $160,000. Offer amounts are determined by factors such as experience, skills, geography, and other job-related factors.
Benefits:
Competitive benefits and paid time off
Paid family and disability leave
401(k) plan, including employer match (100% vested)
Educational and professional development financial assistance
Employee referral bonus program
About Us:
KBRA is a full-service credit rating agency registered in the U.S., the EU and the UK, and is designated to provide structured finance ratings in Canada. KBRA’s ratings can be used by investors for regulatory capital purposes in multiple jurisdictions.
More Info:
KBRA encourages applications from all qualified individuals without regard to race, color, religion, gender, sexual orientation, gender identity or expression, age, national origin, marital status, citizenship, disability, and veteran status or any other basis prohibited by federal, state or local law.
#LI-KS1
#REMOTE"
2025-12-12T17:19:54,Data Platform Engineer,Dragonfli Group,"Dragonfli Group is a cybersecurity and IT consulting firm providing services to federal agencies and Fortune 100 enterprises. Headquartered in Washington, DC, Dragonfli supports clients in securing mission-critical systems across on-site, hybrid, and fully remote environments.

This contract Data Platform Engineer role supports a large federal agency in protecting security data platforms within a large-scale IT environment. The engineer will manage security data platforms such as Splunk and data lakes, ensuring effective data flows, integrations, and platform support. Key technologies include Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS. The role requires seasoned IT security expertise, hands-on technical skills, and strong communication and planning abilities. It's a high-impact opportunity to shape security analytics capabilities within a major federal agency.

This is a multi-year contract position involving a large US federal agency. Candidates with previous federal contracting experience are preferred. U.S. Citizenship or Permanent Residency required. If hired, all work related to this role must be performed within the continental U.S.

Responsibilities:
Manage security data platforms, such as Splunk and data lakes.
Ensure effective data flows, integrations, and platform support.
Support event ingestion, platform maintenance, and technical add-ons.
Troubleshoot to support operational and compliance reporting.
Optimize data use for security monitoring, incident response, and threat analysis.
Collaborate across teams to enhance security analytics capabilities.
Configure and maintain various event ingestion methods.
Create and maintain custom TAs for data parsing into Splunk CIM format.
Monitor and perform routine maintenance of data systems.
Drive process improvements and attention to detail.

Requirements
Four (4)+ years of experience supporting enterprise data platforms.
BS/BA in a cyber-related field or equivalent experience/certifications.
Experience with installing, updating, and maintaining ELM and SIEM.
Proficiency with Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS.
Experience configuring and maintaining event ingestion methods.
Ability to create and maintain custom TAs for Splunk.
Experience in troubleshooting, monitoring, and maintaining data systems.
Familiarity with enterprise security operations.
Strong cross-functional communication skills.

Skill(s)
Hands-on management of security data platforms.
Expertise in data flows and platform integrations.
Proficiency in Splunk and related technologies.
Strong troubleshooting and problem-solving skills.
Ability to optimize security monitoring and incident response.
Excellent cross-functional communication abilities.
Attention to detail and process improvement mindset.
Ability to work collaboratively across teams.
Strong planning and organizational skills.

Benefits
Insurance – health, dental, and vision
Paid Time Off (PTO) and 11 Federal Holidays
401(k) employer match

Travel
null"
2025-12-12T16:50:01,Staff Configuration Data Engineer,Archer,"Archer is an aerospace company based in San Jose, California building an all-electric vertical takeoff and landing aircraft with a mission to advance the benefits of sustainable air mobility. We are designing, manufacturing, and operating an all-electric aircraft that can carry four passengers while producing minimal noise.
Our sights are set high and our problems are hard, and we believe that diversity in the workplace is what makes us smarter, drives better insights, and will ultimately lift us all to success. We are dedicated to cultivating an equitable and inclusive environment that embraces our differences, and supports and celebrates all of our team members.
What you'll do:
As the Configuration Data Engineer, you will combine software development expertise with configuration management practices to safeguard product data integrity, traceability, and compliance. You will design tools, reports, and automations that enable engineering and product teams to make faster, more accurate configuration decisions.
Develop and maintain tools and reports to monitor bills of materials (BOMs), effectivity assignments, and configuration changes
Create automated quality checks to validate workflows and ensure compliance with configuration management standards
Integrate with Teamcenter APIs and background services to access, analyze, and validate engineering data
Build automation scripts to support NX, CATIA, and other CAD-driven workflows (NX Open, CATIA VB, Check-Mate, NX Check-Mate)
Support the definition, maintenance, and auditing of BOM structures, unit effectivity, and date-based effectivity for engineering changes
Develop dashboards and metrics reporting to provide visibility into change requests, change notices, and configuration status accounting
Collaborate with configuration management, engineering, and IT teams to streamline data flow across systems
Investigate data anomalies and provide corrective recommendations to maintain design and change integrity
Partner with project teams to ensure effectivity assignments are properly implemented and reflected in reports
Contribute to the improvement of enterprise configuration management processes through data-driven insights
Serve as a technical resource to CM specialists for reporting, automation, and API usage
What You Need
To be a self starter with a strong desire to learn new technologies
Ability to translate engineering/CM requirements into automated solutions
2+ years of experience developing tools and reports for a Product Lifecycle Management (PLM) tools (e.g., Teamcenter, Windchill, Enovia, 3DX) or equivalent engineering data environments
Experience with relational databases (SQL, PostgreSQL, Oracle) for reporting and automation
Ability to interpret engineering drawings, CAD data, and metadata
Understanding of BOM structures, unit effectivity, and date-based effectivity methods
Familiarity with engineering change processes, including Change Requests (CRs) and Change Notices (CNs)
Experience with scripting or automation in CAD/PLM environments (NX Open, CATIA VB, or similar)
Strong problem-solving skills and ability to analyze complex datasets for process improvements
Effective written communication skills to document procedures and produce clear reports
Ability to work in a collaborative environment across engineering, CM, and IT teams
Bonus Qualifications
Hands-on experience with Siemens Teamcenter APIs or integrations
Experience with Business Intelligence tools such as Power BI, Sigma, or SAP Hana
Experience with ITI CADIQ tools and CAD data validation workflows
Experience with Elysium CAD Translation tools
Familiarity with NX Check-Mate and automations
Familiarity with ASME Y14.5 Dimensioning and Tolerancing
Experience developing Adobe Forms with JavaScript and PDF publishing workflows
Exposure to aerospace, automotive, or other complex product development environments
Knowledge of configuration management standards and compliance practices (CMII, EIA-649, etc.)
This role is ideal for engineers who enjoy bridging software development with product lifecycle control. You will directly impact how engineering data is managed, ensuring accuracy, efficiency, and compliance across the enterprise
Archer is committed to working with and providing reasonable accommodations to job applicants with physical or mental disabilities, and those with sincerely held religious beliefs. Applicants who may require reasonable accommodation for any part of the application or hiring process should provide their name and contact information to Archer’s People Team at people@archer.com. Reasonable accommodations will be determined on a case-by-case basis.
Information collected and processed as part of any job applications you choose to submit is subject to Archer's Candidate Privacy Policy.
Archer is unable to provide work visa sponsorship for this position at the present time.
Archer is proud to be an Equal Opportunity employer committed to diversity and inclusivity in the workplace. All aspects of employment are decided on the basis of merit, qualifications, and business needs. We do not discriminate based upon race, color, religion, sex, sexual orientation, age, national origin, disability status, protected veteran status, gender identity or any other characteristic protected by federal, state or local laws.
Archer Aviation does not engage with external recruiting agencies/individual recruiters with whom it does not have a prior written agreement. Archer reserves the right to make use of any unsolicited resumes that it receives and bears no responsibility for payment of any fees asserted from the use of unsolicited resumes. If you are a recruiting agency or individual recruiter wishing to do business with Archer, please reach out to People@archer.com. All employment processes are managed by the Archer People Team."
2025-12-12T16:14:31,Data Engineer - Integrated Supply Chain,Textron,"Data Engineers build and maintain data systems in support of data analytics and data science activities. The Data Engineer will implement methods to improve data reliability, data quality, and ensure success in data-driven initiatives.
This position within Integrated Supply Chain Analytics is responsible for identifying, developing, and executing solutions that support reliable and efficient extraction of data from source systems and loading of that data into analytic platforms. The Data Engineer will help administer data platforms and consult with data analysts and data scientists on process optimization and data quality improvements.
At Textron Aviation, we are building a community of Data & Analytics professionals with an emphasis on collaboration and cross functional support. You will have the opportunity to work closely with your peers throughout the organization toward a vision of data driven strategy.


JOB RESPONSIBILITIES:
· Gain core business understanding of Textron Aviation and aircraft design, operation, and support
· Query, clean, transform, and stage data (ETL/ELT) across on-prem and cloud environments
· Support data analytics and data science activities by implementing, maintaining, and optimizing production ready data pipelines
· Install and update software to ensure data platform continuity
· Administer a CI/CD compliant code repository during development and update activities
· Research and help implement new technologies to support analytics function
· Interface with other data professionals throughout the organization to embrace cross functional growth in analytics capabilities
· Work to improve data quality by assisting data governance efforts in creating and maintaining data quality standards
· Plan and execute projects according to established milestones and schedules
· Train users in data & analytic tools and processes per best practices and compliance standards
· Contribute to the resolution of service tickets pertaining to data infrastructure
· Serve as an internal consultant to business leaders by advising on system capabilities
EDUCATION/ EXPERIENCE:
· Bachelor’s degree in Computer Science, Software Engineering, Data Science/Analytics, MIS, or other related technical field
· Minimum 2 years relevant technical experience required, focused on data collection, utilization, and analysis.
· Aviation experience preferred
Textron Aviation Inc. must comply with U.S export control laws and regulations. If a position requires access to sensitive information controlled under these laws and regulations, a successful applicant must be eligible to meet any requirements to access controlled information."
2025-12-12T16:07:56,Senior Data Engineer ,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:55,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:54,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T15:01:13.806,"Software Engineer III, Infrastructure, Audience Data Processing",Google,"MINIMUM QUALIFICATIONS:

 * Bachelor’s degree or equivalent practical experience.
   
 * 2 years of experience with software development in C++, SQL, Borg, Flume, or
   1 year of experience with an advanced degree.
 * 2 years of experience with developing large-scale infrastructure, distributed
   systems or networks, or experience with compute technologies, storage or
   hardware architecture.



PREFERRED QUALIFICATIONS:

 * Master's degree or PhD in Computer Science or related technical fields.
   
 * 2 years of experience with data structures and algorithms.
 * Experience with Flume and large scale data processing pipelines.
 * Experience developing accessible technologies.
   


ABOUT THE JOB:

Google's software engineers develop the next-generation technologies that change
how billions of users connect, explore, and interact with information and one
another. Our products need to handle information at massive scale, and extend
well beyond web search. We're looking for engineers who bring fresh ideas from
all areas, including information retrieval, distributed computing, large-scale
system design, networking and data storage, security, artificial intelligence,
natural language processing, UI design and mobile; the list goes on and is
growing every day. As a software engineer, you will work on a specific project
critical to Google’s needs with opportunities to switch teams and projects as
you and our fast-paced business grow and evolve. We need our engineers to be
versatile, display leadership qualities and be enthusiastic to take on new
problems across the full-stack as we continue to push technology forward.

As a Software Engineer on the Audience Data Processing Infrastructure team, you
will innovate and optimize planet-scale data processing flows to support Google
Ads.

While we're an infrastructure team, we operate in a fast-paced environment with
evolving requirements. Our focus is on supporting client data processing needs,
enhancing operational excellence and developer velocity, and significantly
improving resource efficiency.


Google Ads is helping power the open internet with the best technology that
connects and creates value for people, publishers, advertisers, and Google.
We’re made up of multiple teams, building Google’s Advertising products
including search, display, shopping, travel and video advertising, as well as
analytics. Our teams create trusted experiences between people and businesses
with useful ads. We help grow businesses of all sizes from small businesses, to
large brands, to YouTube creators, with effective advertiser tools that deliver
measurable results. We also enable Google to engage with customers at scale.

The US base salary range for this full-time position is $141,000-$202,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Write product or system development code in C++ for infrastructure
   responsible for managing and optimizing processing of planet-scale data
   processing.
 * Investigate data storage and processing use cases, techniques, and
   identifying opportunities for future innovation.
 * Review code developed by other developers and provide feedback to ensure best
   practices (e.g., style guidelines, checking code in, accuracy, testability,
   and efficiency).
 * Contribute to existing documentation or educational content and adapt content
   based on product/program updates and user feedback.
 * Triage product or system issues and debug/track/resolve by analyzing the
   sources of issues and the impact on hardware, network, or service operations
   and quality."
2025-12-12T13:26:27,Cleared On Site Data Engineer (4899),SMX,"SMX is seeking a Senior Data Architect to provide strategic and technical leadership for enterprise data architecture and analytics modernization efforts. This individual will design, optimize, and oversee data solutions that enable advanced analytics, business intelligence, and reporting capabilities across multiple secure environments. This role will focus on designing, developing, optimizing, and maintaining data pipelines and backend data engineering solutions that power critical analytical products used by senior FBI leadership. The ideal candidate brings deep technical expertise in ETL processes, SQL, Python, AWS data services, and enterprise-scale data warehousing, with strong familiarity in BI ecosystems such as MicroStrategy (Strategy), ThoughtSpot, and related tools used within the HR Reports program. The position requires close collaboration with government leads, senior data developers, BI engineers, and cross-functional analytics teams to ensure high reliability, performance, and security of data products supporting mission-critical operations. 
This is a full-time position requiring on-site work five days a week at a client’s office in Washington, D.C. An active Top Secret clearance is mandatory.
Essential Duties and Responsibilities: 
Design, build, and maintain scalable, secure ETL/ELT pipelines supporting HR Reports analytics and dashboard products.
Develop and optimize SQL-based transformations, stored procedures, and data models for high-volume enterprise datasets.
Implement data orchestration workflows using AWS services (e.g., Glue, Lambda, Step Functions, CloudWatch).
Ensure data quality, lineage, and integrity across multiple enterprise data sources.
Support and enhance cloud-based warehouse environments within AWS (e.g., Redshift, S3, IAM).
Collaborate with BI developers to ensure backend data structures meet MicroStrategy/Strategy and ThoughtSpot reporting needs.
Troubleshoot complex data pipeline or performance issues and implement long-term remediation solutions.
Translate government stakeholder requirements into technical specifications for new data sources and pipelines.
Partner with Data Analysts, Data Scientists, and BI Developers to support advanced analytics and ad-hoc data requests.
Apply data governance, security, and compliance best practices in alignment with FBI and SMX standards.
Recommend and implement improvements to automation, data architecture, pipeline reliability, and overall performance.
Maintain documentation for pipelines, logic, data flows, and system dependencies.
Stay current with modern data engineering practices and AWS service enhancements relevant to pipeline automation and warehousing.
Required Skills: 
10+ years of experience in data architecture, data warehousing, or enterprise analytics systems.
Expert-level proficiency in SQL and data modeling
Hands-on experience designing and implementing ETL/ELT frameworks (e.g., Apache Airflow, dbt, AWS Glue, Informatica).
Demonstrated success architecting and optimizing large-scale BI/reporting solutions (MicroStrategy, ThoughtSpot, Power BI, Tableau).
Strong knowledge of AWS data ecosystem (Redshift, Athena, S3, Glue, Lambda) or similar cloud environments.
Experience defining and enforcing data governance, quality, and security standards.
Ability to design and document end-to-end data flows and integrations between transactional and analytical systems.
Excellent communication, analytical, and problem-solving skills.
Desired Skills/Experience:
Bachelor’s or Master’s degree in Computer Science, Information Systems, Data Engineering, or related technical field.
10+ years of experience in data engineering, backend data development, or enterprise-scale ETL development.
Experience supporting federal government IT systems or analytics programs.
Familiarity with Agile methodologies and Jira-based workload management.
Experience supporting or modernizing enterprise BI ecosystems.
**This position requires five days a week on site at customer location in Washington DC.
Application deadline 1-16-2026
#LI-SA
#cjpost
The SMX salary determination process takes into account a number of factors, including but not limited to, geographic location, Federal Government contract labor categories, relevant prior work experience, specific skills, education and certifications. At SMX, one of our Core Values is to Invest in Our People so we offer a competitive mix of compensation, learning & development opportunities, and benefits. Some key components of our robust benefits include health insurance, paid leave, and retirement.
The proposed salary for this position is:
$114,600—$192,500 USD
At SMX®, we are a team of technical and domain experts dedicated to enabling your mission. From priority national security initiatives for the DoD to highly assured and compliant solutions for healthcare, we understand that digital transformation is key to your future success.
We share your vision for the future and strive to accelerate your impact on the world. We bring both cutting edge technology and an expansive view of what’s possible to every engagement. Our delivery model and unique approaches harness our deep technical and domain knowledge, providing forward-looking insights and practical solutions to power secure mission acceleration.
SMX is an Equal Opportunity employer including disabilities and veterans.
Selected applicant may be subject to a background investigation and/or education verification.
SMX does not sponsor a new applicant for employment authorization or immigration related support for this position (i.e. H1B, F-1 OPT, F-1 STEM OPT, F-1 CPT, J-1, TN, E-2, E-3, L-1 and O-1, or any EADs or other forms of work authorization that require immigration support from an employer)."
2025-12-12T12:29:19.508,"Data Center Plant Engineer, Mechanical, Electrical",Google,"MINIMUM QUALIFICATIONS:

 * Associate's degree, trade school certification, or other certified training
   in a related technical field, or equivalent practical experience.
 * 7 years of experience in electrical, mechanical/HVAC, or controls/automation
   experience in an industrial or commercial environment.



PREFERRED QUALIFICATIONS:

 * Experience working in data centers, hospitals, or power plants.
 * Knowledge of electrical and mechanical systems used in a data center
   environment (e.g., Feeders, Transformers, Generators, Switchgear, UPS
   systems, ATS/STS units, PDU/PMM units, Chillers, Air handling units, and CRAC
   units).
   
 * Knowledge of meters, devices, sensors, and troubleshooting utilizing standard
   hand tools, digital metering, or calibration/diagnostic equipment.
   
 * Ability to communicate with contractors who perform maintenance or upgrade
   work on the data center systems.
   


ABOUT THE JOB:

The Data Center team designs and operates some of the most sophisticated
electrical engineering, mechanical engineering and HVAC systems in the world.
Facilities Technicians at Google data centers operate, monitor and support
physical facilities conditions. Some of these duties will include heating and
cooling of air and water, power supply, generators, UPS systems, electrical
distribution and control and monitoring systems. You regularly help inspect,
maintain and repair various data center systems such as piping and non-critical
electrical or mechanical system components). You provide daily assistance to
senior technicians as you read blueprints/schematics, conduct tours of systems
and assess their working order.

As a master of exceptional practices, you develop creative approaches to
reducing operational costs while improving overall data center efficiency. You
ensure that environmental and safety standards are consistently met, identifying
problems and making repairs quickly In emergency situations or abnormal
conditions, you manage data center performance issues and outages to minimize
the recovery time from failures.The AI and Infrastructure team is redefining
what’s possible. We empower Google customers with breakthrough capabilities and
insights by delivering AI and Infrastructure at unparalleled scale, efficiency,
reliability and velocity. Our customers include Googlers, Google Cloud
customers, and billions of Google users worldwide.

We're the driving force behind Google's groundbreaking innovations, empowering
the development of our cutting-edge AI models, delivering unparalleled computing
power to global services, and providing the essential platforms that enable
developers to build the future. From software to hardware our teams are shaping
the future of world-leading hyperscale computing, with key teams working on the
development of our TPUs, Vertex AI for Google Cloud, Google Global Networking,
Data Center operations, systems research, and much more.

The US base salary range for this full-time position is $105,000-$151,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Inspect, maintain, and repair various data center systems such as piping and
   non-critical electrical or mechanical system components.
   
 * Provide daily assistance to technicians as you read blueprints/schematics,
   conduct tours of systems, and assess their working order.
   
 * Manage the uptime and maintenance of water pumps and treatment systems, HVAC,
   UPS, generators, electrical distribution, and control and monitoring systems.
   
 * Operate, monitor, maintain, and respond to abnormal conditions in the data
   center facilities systems and equipment.
   
 * Support startup, commissioning, and integration of new equipment and systems
   into facilities infrastructure.
   "
2025-12-12T09:01:55.769,Data Engineer II,Microsoft,"Overview
With continued growth in digital data and the desire to leverage data to measure in-production quality and address problems that touch all aspects of our lives, Microsoft’s Windows Servicing & Delivery Org is looking for an equally data- and quality-minded engineer to meet these challenges! Join the Update Platform team for the chance to have an impact on billions of customers every day. The Update Platform Team is responsible for ensuring the seamless delivery and integration of software updates and keeping our customers up-to-date and secure at all times.
As a Data Engineer II member of the Update Platform Insights team, you will be at the forefront of leveraging data to assess the quality of the product, detect issues before they reach broad customer application to assure top product quality for partners and customers alike while keeping billions of devices secure and up-2-date.

In this exciting role, you'll work with a diverse group of talented professionals, innovate for greater platform efficiency as well as leveraging the latest technologies and best practices to streamline our update processes with timely in-depth insights and intelligent features.

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.


Responsibilities
Data Management and Transformation: With guidance, you will apply modification techniques to transform raw data into compatible formats for downstream systems. Utilize software and computing tools to ensure data quality and completeness. Implement code to extract and validate raw data from upstream sources, ensuring accuracy and reliability.
Drive Customer Success: Through Data and Business Insight: You will play a pivotal role in building a metrics-driven culture that directly impacts product quality and customer outcomes. This role goes beyond technical execution—you will design and implement measurement frameworks from the ground up while applying a strategic, top-down perspective to ensure the right metrics are in place. Your ability to translate data into actionable insights, aligned with business priorities and rhythm of business, will enable informed decisions that drive high-quality product outcomes and measurable customer success.

Data Requirements and Modeling: Collaborate with stakeholders to document and understand data requirements. Evaluate project plans to assess data costs, access, and availability. Draft design specifications to model data flow and storage, ensuring data is easy to connect and manage.
Compliance: You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams. You’ll also learn about permissions and approvals for data access within a data pipeline.

Validation and Quality Mindset: Apply and use operational fundamentals to validate and ensure quality of the product as well as the underlying data pipeline and assets to secure trustworthiness in your data daily.

Customer Focus: Be driven by a focus on customer happiness and success. We as a team only succeed if our customers are secure and protected via the updates we deliver.


Qualifications
Required Qualifications:
Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 1+ year(s) experience in business analytics, data science, software development, data modeling, or data engineering
OR Bachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 2+ years experience in business analytics, data science, software development, data modeling, or data engineering
OR equivalent experience.
Other Requirements:
Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include but are not limited to the following specialized security screenings:
Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.
Preferred Qualifications:
3+ years with scripting and coding languages with a focus on data engineering, like SQL, KQL, python, Scope, C# (or similar object-oriented languages) and others.
1+ years of experience with building large data processing frameworks using technologies like Azure Data Factory, Azure Data Explorer, PowerBI and/or other public and Microsoft internal tools.
1+ years of experience in analytics to define, monitor, and optimize key performance indicators (KPIs) and connected business metrics that ensure measurable customer success.
1+ years of proven ability to orchestrate and sustain a data-driven rhythm of business, transforming insights into actionable strategies that align with organizational priorities and deliver impactful outcomes.
A solid quality mindset with the ability to deliver end-to-end data solutions that build partner and customer confidence, ensuring alignment with business objectives and measurable outcomes.
Experience with Git, ADO or equivalent Source Control Systems.
Experience with data visualization tools and how to effectively communicate Insights to consumers of varying types of audiences.
Experience leveraging AI to define and evaluate quality standards


Data Engineering IC3 - The typical base pay range for this role across the U.S. is USD $100,600 - $199,000 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $131,400 - $215,400 per year. 
Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:
https://careers.microsoft.com/us/en/us-corporate-pay

This position will be open for a minimum of 5 days, with applications accepted on an ongoing basis until the position is filled.


Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance with religious accommodations and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations."
2025-12-12T01:54:02.588,"Data Science Engineer, New College Grad- Master's/PhD (Santa Clara, CA)",Applied Materials,"Assist in developing data science software prototypes and interfaces for monitoring semiconductor process tools Develop Python scripts to implement key concepts Collaborate closely with algorithm developers to characterize the algorithms and benchmark their performance, collecting quantitative data assessing effectiveness Evaluate the effectiveness and accuracy of the algorithms by working closely with process and equipment experts, providing feedback to algorithm developers Provide solutions which can be implemented by engineers without a deep statistical or mathematical background Deploy and maintain solutions at service sites Troubleshoot solutions, provide workarounds, and assist users in using solutions Assess effectiveness of solutions and provide data science insight Communicate well with algorithm developers and process experts Train field engineers to use solutions Present work and conclusions clearly and succinctly to peers Work well in team, providing and receiving constructive input with team members Monitor and quantify the results of complex algorithms in a production environment. Train a variety of individuals on the operation of these algorithms. Experience with various Artificial Intelligence Solutions, including Large Language Models, Computer Vision and Generative AI applications. Python, MATLAB Familiarity with common data science techniques, including regression, decision trees, Principle components, PLS, various Neural networks, time-series techniques, Bayesian techniques, etc. Ability to troubleshoot software applications and perform basic DevOps for deployment Ability to interact with Process and Customer Engineers Semiconductor process or equipment experience preferred. Demonstrates depth and/or breadth of expertise in own specialized discipline or field May lead small functional teams or projects with moderate resource requirements, risk, and/or complexity Communicates difficult concepts and negotiates with others to adopt a different point of view Master's or PhD in Computer Science, Data Science, Software Engineering, Mechanical Engineering, or related field. Preferred GPA of 3.0 or above"
2025-12-12T01:52:09.253,"Vice President, Data Engineer",BNY,"Bachelor's or master's degree in computer science or a related discipline, or equivalent work experience is required. 10+ years of data modeling, database design and development or related experience is required. Prior experience in managing DB development team Experience modeling Financial data Prior experience modeling Client and Entitlement Data Good knowledge of Financial Accounts, Transactions and Positions data Hands-on experience with any RDBMS, preferably MS SQL Server or Oracle Good SQL knowledge Excellent communication skills Good Problem Solving & Analytical Skills Work experience in Financial Services Work experience on any data modeling tool, viz. Erwin, DBArtisan etc. Experience with writing ANSI SQL code Prior Experience with a scripting language, preferably Python Experience working with Cloud native databases Bachelor's or Master's degree in Computer Science or a related discipline, or equivalent work experience is required. Advanced degree is preferred. Experience in the Securities or Financial Services industry."
2025-12-12T01:08:33,Data Analytics Engineer,Masimo,"The Data Analytics Engineer will support Masimo’s Quality organization by developing dashboards, performing data analysis, and transforming large datasets into meaningful insights. This role partners closely with Quality Compliance, Product Assurance, Engineering, Operations and cross-functional stakeholders to enhance data visibility, drive data-informed decisions, and support continuous improvement across the organization. The ideal candidate is technically strong in analytics tools, comfortable working with structured and unstructured data, and eager to grow in a fast-paced and evolving environment.
Duties & Responsibilities
Develop and maintain Power BI dashboards and reports that translate complex data sets into clear, actionable information.
Perform data transformation and modeling using SQL, Power Query (M), and DAX to support quality metrics, KPIs, and trend analysis.
Support routine and ad-hoc data analytics requests related to customer feedback, failure analysis, operations, and compliance activities.
Analyze large datasets to identify trends and process improvement opportunities.
Collaborate with Quality Compliance, Product Assurance, and cross-functional engineering teams to ensure data accuracy, consistency, and alignment with business needs.
Communicate findings through effective data storytelling, written summaries, and monthly presentations to cross functional leaders across the organization.
Contribute to continuous improvement efforts in reporting automation, dashboard optimization, and analytics best practices.
Minimum & Preferred Qualifications and Experience
Experience
0–2+ years of experience in data analytics, business intelligence, or engineering analytics; internship or project experience considered.
Hands-on experience with SQL and Power BI (including Power Query/M and DAX).
Experience using Python or R for data manipulation, modeling, or visualization preferred.
Familiarity with data visualization tools (Power BI highly preferred; Tableau or Looker a plus).
Understanding of statistics, data modeling, or quantitative analysis techniques.
Skills & Competencies
Strong analytical and problem-solving skills with high attention to detail.
Ability to translate data into clear insights for technical and non-technical partners.
Strong verbal, written, and visual communication skills, with the ability to present confidently and engage diverse audiences.
Ability to work independently and in a team environment.
Curiosity and willingness to learn new tools, systems, and techniques.
Education
Bachelor’s degree in Data Analytics, Data Science, Business Intelligence, Computer Science, Engineering, or a related field required.
Master’s degree in a relevant field is a plus but not required.
Compensation:
The anticipated salary range for this position is $90,000 - $110,000 plus benefits. Actual placement within the range is dependent on multiple factors, including but not limited to skills, education, and experience. 
This position also qualifies for up to 10% annual bonus based on Company, department, and individual performance. 
Masimo offers benefits such as Medical, Dental, Vision, Life/AD&D, Disability Insurance, 401(k), Vacation, Sick, Holiday, Paid Maternity Leave, Flexible Spending Accounts, Voluntary Accident, Critical Illness, Hospital, Long-Term Care, Employee Assistance Program, Pet Insurance, On-site wellness clinic, fitness center, and cafe. All benefits are subject to eligibility requirements."
2025-12-12T00:39:10,Data Engineer,HealthPartners/GHI,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:39:10,Data Engineer,HealthPartners,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:14:05.56,Sr. Data Engineer,Apple,"As a Data Engineer on the Capacity Engineering team, you will help design,
build, and operate the data foundation that drives capacity, cost, and
power-related decisions across Apple’s infrastructure footprint. In this role,
you will: Architect, implement, and maintain large-scale batch and streaming
pipelines that ingest, process, and model infrastructure telemetry, cost,
metering, utilization, forecasting, and power metrics from multiple clouds and
bare metal environments. Design and evolve robust data models (with a strong
focus on dimensional modeling) and storage patterns that support analytics,
internal billing, and efficiency use-cases. Treat data as a product: define
quality checks, SLAs, and observability to ensure data is accurate, timely, and
trusted by stakeholders across Apple. Integrate and enrich raw signals with
metadata and attribution to power use cases such as internal billing/showback,
usage understanding, efficiency and optimization, clawbacks, planning, and
procurement. Collaborate closely with data scientists, software engineers,
platform teams, finance partners, program managers, and leadership to translate
requirements into scalable, reliable data solutions and services. Implement
standard methodologies for data governance, lineage, metadata management, and
security, in alignment with Apple’s standards for data protection and privacy.
Build end-to-end data solutions that include logging, anomaly detection, data
validation, cleaning, and transformation, with strong emphasis on monitoring,
debuggability, and continuous improvement. Contribute to the evolution of our
data and platform stack, including tooling, frameworks, and standards for
development, testing, deployment, and operations (CI/CD, infrastructure as code,
etc.).


DESCRIPTION


Apple’s Capacity data engineering team, within the Apple Services Engineering
organization, is building the centralized data backbone that powers how Apple
understands, plans, and optimizes its cloud and data center infrastructure. We
engineer a unified, trusted data lake that consolidates cost, metering,
utilization, forecasting, and power metrics produced by Apple platforms and
systems (including bare metal) across both third-party and Apple internal
clouds. Enriched with metadata and attribution, this becomes the single source
of truth for internal billing, understanding usage and utilization, clawbacks,
planning, procurement, and efficiency initiatives. We collaborate with platform
engineering, finance, capacity engineering, and leadership teams to build
large-scale data pipelines, enable descriptive and predictive analytics, and
power dashboards and products that support critical business decisions. This is
your opportunity to help design and operate highly visible, global-scale systems
processing petabytes of data and supporting hundreds of users across Apple. Come
join us to help deliver the next generation of infrastructure insights at Apple.


MINIMUM QUALIFICATIONS


Bachelors degree or equivalent experience in Computer Science, Information
systems, Software Engineering, Data Science or related field. Advanced degree in
a related field a plus. 5+ years of experience in data engineering (or
equivalent practical experience), including: Building and maintaining
large-scale ETL/ELT data pipelines Distributed computing (e.g., Spark / PySpark)
for data processing and automation Query performance optimization and tuning at
scale Hands-on experience with: Apache Spark and Airflow (or similar
workflow/orchestration tools) for efficient large-scale data pipelines Data
modeling, especially dimensional modeling, and designing schemas optimized for
analytics and reporting Big data platforms and/or data lake architectures


PREFERRED QUALIFICATIONS


Experience with cloud technologies, specifically AWS (e.g., S3, EMR, Lambda,
Glue, RDS/Redshift, or similar services) Tooling & ecosystem: Experience with
CI/CD tooling such as Jenkins (or similar tools) Experience with data
visualization / BI tools, such as Superset or Tableau (other tools like
QuickSight, QlikView, Cognos, or Business Objects are a plus) Experience with
containerization and orchestration, such as Docker and Kubernetes/EKS is a plus
Understanding of authentication and authorization (AuthN/AuthZ) patterns
Knowledge of data governance principles, data security best practices, and data
privacy regulations"
2025-12-12T00:00:00,Lead Data Engineer,Nuna,"At Nuna, our mission is to make high-quality healthcare affordable for everyone. We are dedicated to tackling one of our nation’s biggest problems with ingenuity, creativity, and a keen moral compass.
Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why.
Nuna has established its brand in the B2B space over the last decade by shifting the US healthcare system towards an incentive model that rewards healthcare providers for positive outcomes. Marshalling our collective backgrounds and insights, we are now crafting an innovative, consumer app - a clinically driven healthcare companion experience that leverages AI, gamification and social support techniques to improve outcomes for people with chronic conditions.
As a sign of the impact Nuna has already made in this space, Nuna was recently selected to join the Centers for Medicare & Medicaid Services (CMS) Health Tech Ecosystem, a landmark public-private initiative designed to transform healthcare for Americans.
YOUR TEAM
The Data org at Nuna is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research.
The Data Engineer team is a core part of the broader Data organization, which is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research. The Data Engineer team acts as the technical backbone for data architecture, platform development, and data operations, empowering the organization to deliver impactful data-driven solutions in healthcare.
YOUR OPPORTUNITIES
We are looking for someone who is excited to use their creativity and engineering skills to make a difference in healthcare. You will have a foundational role on a team building a consumer product that incentivizes healthy behavior. You will be responsible for the data architecture and direction of the data platform that powers our data operations and data science initiatives.
Own the architecture and evolution of the data platform, based on business needs and considering trade-offs in timelines, cost, and resources
Define and enforce standards for code development, contribution, and deployment for data engineering workflows.
Oversee integrations with external services, including data ingestion, distribution, and service-to-service data flows.
Contribute hands-on to data transformations and optimizations
Establish security, governance, and operational best practices for the data platform in collaboration with security and enterprise data engineering teams.
Curate and develop datasets needed to support Data org project deliverables
Collaborate with cross-functional partners in engineering, design, and product to develop solutions
Generate and prioritize new opportunities for improvements
Provide build vs buy assessments and recommendations as the platform expands
QUALIFICATIONS
Required Qualifications
Deep hands-on expertise in designing, coding, developing, and maintaining data platforms that support data analytics and data science use cases
Proven ability to design, develop and implement robust data ingestion pipelines (ETL) from external sources into a data platform.
Experience establishing standards for code development, deployment, and contributions in a data engineering environment.
Ability to solicit and translate customer and business needs into requirements and an evaluation framework
Interest in improving healthcare and working with interdisciplinary project teams
Clear communication and presentation skills
Experience with Databricks
Expertise in data platform languages such as python, pyspark and SQL
+ 5-10 years of industry experience with technical lead experience of running a data platform for business operations
Preferred Qualifications
MS in quantitative field (e.g. Data Science, Economics, Statistics, Engineering)
Experience building a data platform from zero to one
Experience working with healthcare data
Experience with SDLC and management of machine learning models (MLOps)
Bonus points if experience with MLOps on LLM/GenAi features (evals, context building, …)
We take into account an individual’s qualifications, skillset, and experience in determining final salary. This role is eligible for health insurance, life insurance, retirement benefits, participation in the company’s equity program, paid time off, including vacation and sick leave. The expected salary range for this position is $208,000 - $260,000. The actual offer will be at the company’s sole discretion and determined by relevant business considerations, including the final candidate’s qualifications, years of experience, and skillset.
Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status.
#LI-FK1"
2025-12-12T00:00:00,Development Project Engineer (Data Center Construction),QTS Data Centers,"Who we are: It's pretty exciting to find yourself standing in a pivotal moment in time. It’s even more exciting to be out front leading it. At QTS, our world-class data centers are supporting our customers’ most strategic growth initiatives, positioning us at the forefront of today’s dynamic digital transformation. As AI and cloud drive the demand for increased speed, capacity and capability, QTS has emerged as the global digital infrastructure leader, committed to connecting the world for good. Driven by purpose and fueled by a spirit of innovation, QTS designs, builds and operates some of the world’s most advanced, forward-thinking data centers. QTS is a portfolio company of Blackstone. QTS is Powered by People. People who play a vital role in our company’s culture, innovation and growth. People who are committed to contributing to the communities where we operate and work. People who are knowledgeable, resourceful and mission driven. Together, we do great things. Who You Are: The Development Project Engineer (Data Center Construction) is primarily responsible for assisting with the design, preconstruction and construction activities on a given project(s). The Development Project Engineer will interact on a daily basis with Facilities, Contractors, Designers, Engineers, Commissioning Agents, Vendors, and Data Center Operations & Corporate real estate staff and should have both written and oral communication skills commensurate with this level of regular communication. What You Will Do: Assist Development leadership and Project Manager with day to day activities and responsibilities Assist with multiple projects on a campus(es) and maintain updated budgets, schedules, and status reports for each Assist with updates on development program & project status on a monthly basis suitable for executive level reviews. Work with QTS stakeholders, design, and construction teams to help with master development program for site(s), including a complete campus design solution and capital budget. Assist with entitlement and permitting needs for each assigned site project(s) Assist with scopes of work for design, construction, commissioning services & participate in procurement and project cost estimates Evaluate and level pricing proposals for design, construction, and commissioning services Work closely with strategic procurement team on equipment procurement and delivery process Ensure appropriate submittals are coordinated with site stakeholders Assist with monitoring project budget / cost-to-date against overall project budget. Review project schedules and manage teams to on-time completion Review change order requests from contractors and negotiate pricing Assist with establishing site construction security procedures in conjunction with site security team Establish and maintain relationships serving as liaison with key QTS stakeholders Represent QTS Interests in OAC meetings Create & build relationships that enhance QTS’s ability to be a leader in creating the World’s Most Valuable Data Center Real Estate Aid in due diligence efforts on an as-needed basis by participating with real estate efforts on potential or new land banks and properties, including: Evaluate opportunities to design & build new data centers by working with key stakeholders: Corporate Real Estate, Connectivity, Power & Construction teams. Assist with establishing and monitoring entitlement and permit processes for individual projects as needed Work with the internal development team to enhance project management processes and protocols What You Will Need to be Successful (basic qualifications): Bachelor’s degree in Engineering or Construction Management field or equivalent professional experience Experience with Microsoft Office suite, specifically PowerPoint for use in communicating program updates to executive level, and Excel to create and maintain site program & individual project budgets Excellent interpersonal skills with the ability to interface with all levels of the organization Must be a capable, proven team player that both fosters and operates well within internal and external team environments. Able to solve problems at a tactical and functional level Strong Verbal and Written Communication Skills Ability to manage multiple projects simultaneously Other Key Skills: One or more years of professional experience in commercial construction practices and procedures, including management of Lump Sum, Construction Management @ Risk, and Design Build project delivery methods from conceptual development through procurement to close out Documented experience using AutoCAD, BlueBeam, P6, and CxAlloy Experience or exposure in mission critical data center facilities Experience with management of MEP trades Experience managing document control for active data center build sites The Perks (and these are just a few!): Q-Rest Sabbatical Employee Stock Purchase Plan QTS scholarship for dependents Eagle Club Award Trip Eligibility Paid Volunteer and Floating days Tuition Assistance, Parental Leave and Military Leave Assistance We conform to all the laws, statutes, and regulations concerning equal employment opportunities and affirmative action. We strongly encourage women, minorities, individuals with disabilities and veterans to apply to all of our job openings. We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, gender identity, or national origin, age, disability status, Genetic Information & Testing, Family & Medical Leave, protected veteran status, or any other characteristic protected by law. We prohibit retaliation against individuals who bring forth any complaint, orally or in writing, to the employer or the government, or against any individuals who assist or participate in the investigation of any complaint or discrimination claim. The ""Know Your Rights"" Poster is included here: Know Your Rights (English) Know Your Rights (Spanish) The pay transparency policy is available here: Pay Transparency Nondiscrimination Poster-Formatted QTS is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please send an e-mail to talentacquisition@qtsdatacenters.com and let us know the nature of your request and your contact information. It’s exhilarating to find yourself at a pivotal moment in history— and even more so to be leading the way. At QTS Data Centers, we are proud to stand at the forefront of today’s dynamic digital transformation. Our world-class data centers empower our customers’ most strategic growth initiatives, positioning us as a global leader in digital infrastructure. As AI and cloud technologies fuel the demand for increased speed, capacity, and innovation, QTS has emerged as the global digital infrastructure leader. We are committed to connecting the globe for good. Driven by purpose and a spirit of innovation, we design, build, and operate some of the most advanced data centers worldwide. In addition to our cutting-edge technology, we are dedicated to sustainability, incorporating renewable energy solutions to minimize our environmental footprint and drive meaningful impact. As a proud portfolio company of Blackstone, QTS is uniquely positioned to achieve ambitious growth and innovation goals. At QTS, we are Powered by People. Our team members are the cornerstone of our culture, innovation, and growth. They are mission-driven, resourceful, and committed to making a positive impact in the communities where we live and work. Together, we’re achieving remarkable things and shaping the future of digital infrastructure. And we’d like to invite you to join us. In addition to a variety of benefit packages, QTS goes above and beyond for our employees: Roth and Traditional 401(k) matching contributions with immediate vesting Every employee is bonus or commission eligible Generous PTO, Paid Volunteer Days Plus Floating Holidays Stock Purchase Plan (SPP) 11 paid Holidays Annually/Holiday compensation when worked Pet and Legal Insurance Q-Rest Sabbatical Program Q-Anniversary Service Award Program Parental Leave for primary and secondary caregivers Military Benefits Package QTS Charitable Matching Gift Program QTS Scholarship for Employee Dependents QTS Crisis Fund Wellness Program Tuition Reimbursement Program"
2025-12-12T00:00:00,"Data Engineer I, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $109,300.00 - $180,200.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data across the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape by designing, building, and deploying data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning, and business intelligence initiatives. You will work closely with Data Science and Decision Science teams to build, test, and maintain data pipelines and model workflows that support both analytical research and production use cases in our Databricks/AWS/Snowflake environment. In addition to your strong analytical mind, you will bring an inquisitive attitude and the ability to translate the stories found in data into actionable insights while contributing to technical discussions and process improvements. Applicants must be authorized to work for ANY employer in the U.S. The company does not sponsor/support H-1B petitions, TN, or Forms I-983/STEM OPT, for this role. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions. Design data solutions. Analyze sources to determine value and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Collaborate within and across teams to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate. Test data movement, transformation code, and data components. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent. Six years of related experience. Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions. Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on. Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems. Strong verbal and written communication skills with the ability to interact with team members and business partners. Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Four years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,"Senior Data Engineer, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $139,400.00 - $230,000.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions. Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies. Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate. Collaborate across team to support delivery and educate end users on complex data products/analytic environment. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent Ten years of related experience Primary Job Requirements: Architect and design scalable, secure data solutions using AWS, Databricks, and Ab Initio. Lead technical direction for data engineering initiatives across cloud and on-premises infrastructure. Hands-on development: build ETL pipelines, optimize Spark jobs, and create Ab Initio graphs. Troubleshoot production issues and provide technical guidance to junior engineers. Conduct mentoring sessions and offer technical guidance to the 20-person admin team. Collaborate with DBA teams, business analysts, and QA teams to ensure data governance and quality. Manage infrastructure deployment and optimize cloud resources. Lead technical design reviews and architecture discussions. Implement data integration solutions and ensure compliance with data protection regulations. Establish and enforce coding standards, best practices, and data governance policies. Technical Skills: AbInitio: Expert proficiency with GDE, Co>Operating System, EME, BRE, Express>It, metaprogramming (PDL) Programming: Python, PySpark, SQL Cloud: AWS architecture and services Databricks: Workspace management, cluster configuration, Delta Lake, Unity Catalog Data Warehousing: Strong understanding of data modeling, dimensional modeling (star/snowflake schemas) ETL/ELT: End-to-end ETL development lifecycle Version Control: Git, CI/CD pipelines Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices. Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems. Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers. Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize. Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas. Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Five years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,Data Flow Engineer,Scientific Research Corporation,"Description
The Data Flow Engineer will be a member of a Cryptologic Carry-On Program (CCOP) and Ship’s Signals Exploitation Equipment (SSEE) Systems Engineering team primarily responsible for ensuring the processing and distribution of data to and from intelligence community networks. The ideal candidate will have a history of direct involvement with successful NiFi data flow engineering and resolving Navy hardware and software functionality problems by providing a high degree of timely customer service and technical expertise in support of the US Navy information warfare community.
Installing, configuring, integrating, and maintaining NiFi servers and processors into new or existing system architectures
Verifying and maintaining all NiFi processors and flows to and from deployed (and test) systems, from the field system through customer back-end repositories
Assisting end users with the operational readiness and configuration of deployed systems for optimal data flow to satisfy customer requirements
Designing and developing NiFi processors and flows for deployed systems, containing multiple subsystems and requiring integration with external networks
Implementing expression language in NiFi processors in response to emerging customer requirements
Exhibiting developed verbal and written communication skills and the ability to express concepts and ideas in a clear and concise manner; employing technical writing techniques
Performing as a team player, dedicated to the endeavors of the mission, the customer, and the team itself
Being a self-starter who is accountable and requires minimal direction and supervision; capable of multitasking and working several complex and diverse tasks with simultaneous or near simultaneous deadlines
#LI-LL1
Requirements
Must possess an active TS/SCI clearance and be able to obtain a CI Polygraph
Requires a bachelor’s degree in related technical field or equivalent work experience
Intermediate Linux Command Line Interface (CLI) experience
1-3 years of Apache Niagara Files (NiFi) experience (negotiable with other qualifications)
Strong background in using and troubleshooting Software Defined Radio (SDR) systems
Fundamental knowledge of wireless protocols in common use
Experience providing technical support to customers over Internet Relay Chat (IRC) or similar applications
Familiarity with back-end databases and repositories
Must be willing to travel up to 10% of the year
Must currently be DoD 8570-compliant with the equivalent of an IAT II certification or have the ability to do so within 6 months of employment
Desired Skills
Current Linux+/LPIC 1 and/or Network+ certification
Familiarity with Regular Expression (REGEX), Cisco Networking, and Amazon Web Services (AWS)
Expert-level SDR knowledge and experience
Experience with strategic-level intelligence processes
Basic computer programing experience (i.e. Python, JavaScript, bash)
Prior Navy CTR/CTM/CTN with shipborne, expeditionary, or other comparable experience 
Clearance Information
SRC IS A CONTRACTOR FOR THE U.S. GOVERNMENT. THIS POSITION WILL REQUIRE U.S. CITIZENSHIP AS WELL AS A U.S. GOVERNMENT SECURITY CLEARANCE AT THE TOP SECRET / SCI LEVEL with CI POLY ELIGIBILITY
Travel Requirements
up to 10% travel may be required
About Us
Scientific Research Corporation is an advanced information technology and engineering company that provides innovative products and services to government and private industry, as well as independent institutions. At the core of our capabilities is a seasoned team of highly skilled engineers and scientists with multidisciplinary backgrounds. This team is challenged daily to provide cutting edge technology solutions to our clients.
SRC offers a generous benefit package, including medical, dental, and vision plans, 401(k) with a company match, life insurance, vacation and sick paid time off accruals starting at 10 days of vacation and 5 days of sick leave annually, 11 paid holidays, tuition reimbursement, and a work environment that encourages excellence and more. For positions requiring a security clearance, selected applicants will be subject to a government security investigation and must meet eligibility requirements for access to classified information.
EEO
Scientific Research Corporation is an equal opportunity employer that does not discriminate in employment.
All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other protected characteristic under federal, state or local law.
Scientific Research Corporation endeavors to make www.scires.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact jobs@scires.com for assistance. This contact information is for accommodation requests only and cannot be used to inquire about the status of applications."
2025-12-12T00:00:00,"Research Data Engineer II, CHeT Analytics",University of Rochester,"As a community, the University of Rochester is defined by a deep commitment to Meliora - Ever Better. Embedded in that ideal are the values we share: equity, leadership, integrity, openness, respect, and accountability. Together, we will set the highest standards for how we treat each other to ensure our community is welcoming to all and is a place where all can thrive. Job Location (Full Address): 265 Crittenden Blvd, Rochester, New York, United States of America, 14642 Opening: Worker Subtype: Regular Time Type: Full time Scheduled Weekly Hours: 40 Department: 400980 Neuro-Ctr Health & Tech/Admin Work Shift: UR - Day (United States of America) Range: UR URG 113 Compensation Range: $77,216.00 - $115,824.00 The referenced pay range represents the minimum and maximum compensation for this job. Individual annual salaries/hourly rates will be set within the job's compensation range, and will be determined by considering factors including, but not limited to, market data, education, experience, qualifications, expertise of the individual, and internal equity considerations. Responsibilities: GENERAL PURPOSE Participates in the design, implementation and maintenance of analytical and data science-based software and data pipelines to support scientific workflows. Focuses on developing and supporting data collection frameworks that integrate structured and unstructured data from multiple sources and systems to support specific research study teams. Supports the development and maintenance of infrastructure systems (e.g., data warehouses, data lakes), including data access Application Programming Interface(s) (APIs). Works in partnership with team members to provide robust, scalable software solutions to the research enterprise. ESSENTIAL FUNCTIONS Builds, maintains and evolves general Extract, Transform and Load (ETL) data pipelines and overall data architecture to accommodate a growing amount of data from a variety of large research data sources. Works with research team members to convert business and technical requirements into professional software solutions. Ensures timely completion of tasks while managing multiple assignments, project timelines and business user expectations. Designs and implements custom research project-specific data workflow solutions for data collection, management, reporting and analytics. Contributes to the scientific research. Adheres to defined application development life-cycle practices, including but not limited to, requirements gathering, writing test plans, source code management, peer code review and quality assurance through unit/system/user acceptance testing. Participates in specification, implementation and execution of testing procedures to ensure quality of deliverables, system and data workflow reliability. Produces and maintains comprehensive technical documentation for all systems under the Engineer's responsibilities. Keeps abreast of current application developments through continuing education, professional reading, online forums, conferences, workshops and professional groups. Other duties as assigned. MINIMUM EDUCATION & EXPERIENCE Bachelor's degree in Data Science, Biomedical Science, Computer Science, Mathematics, Statistics or similar discipline and 2 years of experience in technology and data intensive roles and environments required Or equivalent combination of education and experience Programming experience in Structured Query Language (SQL) and one other applicable language (Java, Python, and/or R) required Experience with Change Management solutions required Experience with Version Control solutions (e.g. Git) required Experience implementing and supporting data management systems in a scientific, research context (e.g. biospecimen software, electronic laboratory notebooks, REDCap) preferred Experience with Linux, container and cloud technologies (e.g. HPC, IaaS and PaaS) preferred KNOWLEDGE, SKILLS AND ABILITIES Understanding of data analytics and statistical methods required Expertise of software engineering best practices such as version control and software release management required Strong analytical and problem-solving skills required Strong organizational skills required Ability to work with others in a matrix management environment required Excellent communication skills for describing progress and challenges to stakeholders required Attention to detail, patience and a positive, customer-centric attitude required Strong technical presentation skills required Demonstrated ability to develop proficiency with unfamiliar toolsets preferred Familiarity with file formats, metadata, and data exchange and storage standards applicable in management of scientific and clinical research required The University of Rochester is committed to fostering, cultivating, and preserving an inclusive and welcoming culture to advance the University’s Mission to Learn, Discover, Heal, Create – and Make the World Ever Better. In support of our values and those of our society, the University is committed to not discriminating on the basis of age, color, disability, ethnicity, gender identity or expression, genetic information, marital status, military/veteran status, national origin, race, religion, creed, sex, sexual orientation, citizenship status, or any other characteristic protected by federal, state, or local law (Protected Characteristics). This commitment extends to non-discrimination in the administration of our policies, admissions, employment, access, and recruitment of candidates, for all persons consistent with our values and based on applicable law. Notice: If you are a Current Employee, please log into myURHR to search for and apply to jobs using the Jobs Hub. Your application, if submitted using this portal, cannot be moved forward. Learn. Discover. Heal. Create. Located in western New York, Rochester is our namesake and our home. One of the world’s leading research universities, Rochester has a long tradition of breaking boundaries—always pushing and questioning, learning and unlearning. We transform ideas into enterprises that create value and make the world ever better. If you’re looking for a career in higher education or health care, the University of Rochester may offer the perfect opportunity for your background and goals. At the University of Rochester, we are committed to fostering, cultivating, and preserving an inclusive and welcoming culture and are united by a strong commitment to be ever better—Meliora. It is an ideal that informs our shared mission to ensure all members of our community feel safe, respected, included, and valued."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,Data Engineer II (Onsite),RTX,"Date Posted: 2025-12-12 Country: United States of America Location: PW147: PW OKC Campus 8120 S. Air Depot Blvd , Oklahoma City, OK, 73135 USA Position Role Type: Onsite U.S. Citizen, U.S. Person, or Immigration Status Requirements: U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Security Clearance: None/Not Required Pratt & Whitney is working to once again transform the future of flight—designing, building and servicing engines unlike any the world has ever seen. And because transformation begins from within, we’re seeking the people to drive it. So, calling all curious. Come ready to explore and you’ll find a place where your talent takes flight—beyond the borders of title, a country or your comfort zone. Bring your passion and commitment and we’ll welcome you into a tight-knit team that takes our mission personally. Channel your drive to make a difference into shaping an organization and an industry that’s evolving fast to the future. At Pratt & Whitney, the difference you make is on display every day. Just look up. Are you ready to go beyond? You will be an integral part of Pratt & Whitney’s Sustainment Operational Excellence Data Engineering & Analytics team. This team supports the global aftermarket maintenance and overhaul of engines for the F117, F119, and F135 programs. We are looking for a Data Engineer II to advance the digital and data capability of the Military Engines Global Depot Network organization. You will be working on exciting new technologies like cloud and open-source tools among others, and be responsible for cleaning, standardizing, transforming, and configuring data products within our emerging data mesh. What You Will Do: Create and maintain scripts written in Spark SQL or Pyspark in Databricks Notebooks. Also, work with SMEs to understand complex datasets for next generation data products and data visualizations to create data mesh tables. Develop scalable and sustainable data product transformations that curate, clean and store data efficiently; perform statistical analysis to quantify completeness and validity; perform bug fixes and apply enhancements to the models when the need arises. Ensure high performance and reliability of data transformation processes and pipelines. Collaborate cross-functionally to gather insights, refine requirements, and ensure alignment between product goals and team efforts. Document data processes, logic, and data sources to ensure transparency and knowledge sharing as well as support the overall team with any ad-hoc data related tasks. Work to convert our existing data visualizations in Power BI to use Databricks instead of Azure Synapse. Keep up to date with technologies and use advanced cloud data warehouse and data transformation techniques to build innovative solutions. Qualifications You Must Have: A degree in Science, Technology, Engineering or Mathematics (STEM) with 2+ years of experience in the use of SQL and/or Python to transform, clean, and integrate data from a variety of source pipelines. U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Qualifications We Prefer: Experience with transformation tools such as dbt, Databricks pipelines, or relevant tools such as SSIS, ADF, or Matillion. Demonstrated experience with Git/GitHub; experience working in cloud data warehouses like Databricks. Familiarity with agile methodologies and Kanban boards. Self-motivated, team player with good communication skills. Ability to focus on results and successfully manage multiple tasks/projects. An astute individual, with the ability to build strong cross-functional relationships; excited at the prospect of developing and implementing new data products that add organizational value & improve decision making capabilities. Business experience with Aerospace or other heavy manufacturing industry. An understanding of ER Diagrams for data modeling. Demonstrated understanding of data mesh design principles and data engineering best practices. Learn More & Apply Now! What is my role type? In addition to transforming the future of flight, we are also transforming how and where we work. We’ve introduced role types to help you understand how you will operate in our blended work environment. This role is: Onsite: Employees who are working in Onsite roles will work primarily onsite. This includes all production and maintenance workers, as they are essential to the development of our engines. Candidates will learn more about role type and current site status throughout the recruiting process. For onsite and hybrid roles, commuting to and from the assigned site is the employee’s personal responsibility. As part of our commitment to maintaining a secure hiring process, candidates may be asked to attend select steps of the interview process in-person at one of our office locations, regardless of whether the role is designated as on-site, hybrid or remote. The salary range for this role is 66,000 USD - 130,000 USD. The salary range provided is a good faith estimate representative of all experience levels. RTX considers several factors when extending an offer, including but not limited to, the role, function and associated responsibilities, a candidate’s work experience, location, education/training, and key skills. Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement. Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company’s performance. This role is a U.S.-based role. If the successful candidate resides in a U.S. territory, the appropriate pay structure and benefits will apply. RTX anticipates the application window closing approximately 40 days from the date the notice was posted. However, factors such as candidate flow and business necessity may require RTX to shorten or extend the application window. RTX is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or veteran status, or any other applicable state or federal protected class. RTX provides affirmative action in employment for qualified Individuals with a Disability and Protected Veterans in compliance with Section 503 of the Rehabilitation Act and the Vietnam Era Veterans’ Readjustment Assistance Act. Privacy Policy and Terms: Click on this link to read the Policy and Terms RTX is an aerospace and defense company that provides advanced systems and services for commercial, military and government customers worldwide. It comprises three industry-leading businesses – Collins Aerospace, Pratt & Whitney, and Raytheon. Its 195,000 employees enable the company to operate at the edge of known science as they imagine and deliver solutions that push the boundaries in quantum physics, electric propulsion, directed energy, hypersonics, avionics and cybersecurity. The company, formed in 2020 through the combination of Raytheon Company and the United Technologies Corporation aerospace businesses, is headquartered in Arlington, Virginia."
2025-12-12T00:00:00,"Senior Engineer, BAW R&D Trimming and Data Infrastructure",Qorvo,"
                Qorvo (Nasdaq: QRVO) supplies innovative semiconductor solutions that make a better world possible. We combine product and technology leadership, systems-level expertise and global manufacturing scale to quickly solve our customers' most complex technical challenges. Qorvo serves multiple high-growth segments of large global markets, including consumer electronics, smart home/IoT, automotive, EVs, battery-powered appliances, network infrastructure, healthcare and aerospace/defense. Visit www.qorvo.com to learn how our innovative team is helping connect, protect and power our planet.

 
Summary:
 Qorvo’s BAW R&D Data Infrastructure team is seeking a talented engineer for semiconductor data infrastructure, frequency trimming and process automation. The candidate chosen for this role will develop data infrastructure and software tools to support efficient development and production of new Bulk Acoustic Wave (BAW) filter technologies. The candidate will use MATLAB, data analysis tools (SpotFire), databases and other software tools for process control improvements, faster design cycles, and general automation to efficiently develop and produce new technologies.
 
Key Roles and responsibilities:

Research, implement, deploy, and maintain internal software applications used by Manufacturing and R&D Engineering teams to process and trim BAW filters wafers.
Work closely with Process Integration and Process Engineering teams to understand new BAW technology needs to define requirements and implement.
Provide comprehensive support to internal customers: resolve outstanding issues for R&D engineers, designers, and production at Qorvo’s fabrication facility.
Own critical data infrastructure projects and successfully deliver results in a timely manner

 
Technical Knowledge/Skills/Abilities Required:

Excellent MATLAB or Python programming capabilities
Knowledge of semiconductor processing
Practical knowledge of software development and object-oriented programming
Excellent debugging and problem-solving skills


Strong data analysis and mathematical skills


Experience with version control utilizing Git and GitLab
Good knowledge of SQL database (Oracle is a plus)
Experience in the full life cycle of the software design process including requirement analysis, design, prototyping, coding, documentation, implementation, and maintenance

 
Personal Skills:

Self-motivated, independent, proactive, detail oriented, and responsible team-player
Excellent analytical skills
Comfortable working in a dynamic and fast paced environment
Passion for innovation and emerging technologies
Excellent communication and interpersonal skills
Able to handle multiple priorities
Proficient in English

 
Desired experiences:

Experience with software development for semiconductor processing 
Expertise in electromagnetics, physics, or material science
Expertise in Oracle PL/SQL databases
Experience with data analysis tools such as Spotfire or similar application
Experience with GitLab workflows and pipeline automation 
Experience with Visual Studio Code and GitHub Copilot
Experience with unit testing in past development projects

 
Qualifications:
Education & Experience:

BS or MS in Computer Science, Electrical Engineering, Physics or Material Science
5+ years of code development experience.(or if Master's degree 2+ years experience)

 
This position is not eligible for visa sponsorship by the Company.
 
#LI-KR1
 MAKE A DIFFERENCE AT QORVO   

 We are Qorvo. We do more than create innovative RF and Power solutions for the mobile, defense and infrastructure markets – we are a place to innovate and shape the future of wireless communications. It starts with our employees. As a unified global team, we bring a commitment to excellence, growth and a passion for creating what's next. Explore the possibilities with us.

We are an Equal Employment Opportunity (EEO) employer and welcome all qualified applicants. Applicants will receive fair and impartial consideration without regard to any characteristics protected by applicable law, including race, color, religion, sex (as defined by law), national origin, age, military or veteran status, genetic information, or disability.  
                
    "
2025-12-12T18:28:05.616,Sr Staff Engineer Software (Data Plane Applications),Palo Alto Networks,"Company Description
Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
Who We Are
We believe collaboration thrives in person. That’s why most of our teams work from the office full time, with flexibility when it’s needed. This model supports real-time problem-solving, stronger relationships, and the kind of precision that drives great outcomes.
Job Description
Your Career
Prisma Access™ (formally GlobalProtect Cloud Service) provides protection straight from the cloud to make access to the cloud secure. It combines the connectivity and security you need and delivers it everywhere you need it. Using cutting-edge public and private cloud technologies extending the next-generation security protection to all cloud services, customers on-premise remote networks and mobile users.
We are seeking an experienced Software Engineer to design, develop and deliver next-generation technologies within our Prisma Access team. We want passionate engineers who love to code and build great products. Engineers who bring new ideas in all facets of software development. We are looking for leaders who take ownership of their areas of focus and who are driven to solve problems at every level. Collaboration and teamwork are at the foundation of our culture and we need engineers who can communicate at a high level and work well with others towards achieving a common goal.
Your Impact
Design, develop and implement highly scalable software features and infrastructure on our next-generation security platform ready for cloud native deployment from inception to completion
Work with different development and quality assurance groups to achieve the best quality - You accomplish this by being hands-on, creating tools, processes, and systems that produce transparency, alignment, and direction
Profile, optimize and tune systems software (management/control/dataplane) for efficient cloud operation
Work with DevOps and the Technical Support teams to troubleshoot customer issues
Work with other software development team to apply PanOS features on Prisma Access
Interview, mentor and coach new team members 
Qualifications
Your Experience 
5+ years of experience in developing and troubleshooting dataplane applications
Required hands-on programming experience in Python and Go
Nice to have C/C++ Programming
Strong Data structures/Algorithms
Strong analytical skills, problem solving and debugging skills
Nice to have experience with LLMs and GenAI applications. Or Machine learning/Data science with experience in ETL, curating datasets, running evals. 
Experience with building applications in the cloud
In-depth understanding of Operating System principles and OS like Linux/Unix
In-depth understanding of networking concepts and TCP/IP stack, TLS
Exposure to building Microservices 
Enjoys working with many different teams with strong collaboration and communication skills
Solid foundation in design, data structures, and algorithms, and strong analytical and debugging skills
Education : M.S./B.S. degree in Computer Science or equivalent military experience required
Additional Information
The Team
Our engineering team is at the core of our products – connected directly to the mission of preventing cyberattacks. We are constantly innovating – challenging the way we, and the industry, think about cybersecurity. Our engineers don’t shy away from building products to solve problems no one has pursued before.
We define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment.
Compensation Disclosure
The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $170,000 - $190,000/YR. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.
Our Commitment

We’re problem solvers that take risks and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at [email protected].
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
Is role eligible for Immigration Sponsorship?: Yes"
2025-12-12T18:20:27,Data Engineer,Real Chemistry,"At Real Chemistry, making the world a healthier place isn’t just an aspiration—it’s our everyday reality. Our drive to transform healthcare is informed by our blend of deep scientific expertise, human-centred creativity, and AI-driven insights, fostering a unique environment where innovation thrives and our people are impact-obsessed. As a global agency, we provide a full suite of services across healthcare communications and marketing to our clients, including top players in the pharmaceutical and biotech industries.
Our #LifeatRealChem culture is rooted in our people—we believe we are best together and are committed to excellence for both our clients and colleagues. Whether you're a seasoned professional or just starting your career, if you share our passion for healthcare and connection, we invite you to explore our opportunities.
Discover your purpose. Embrace innovation. Experience #LifeatRealChem.
Job Summary 
We’re looking for a hands-on Data Engineer to help build and maintain the data infrastructure that powers our AI products and solutions. This role sits within our AI organization and focuses on designing, developing, and optimizing scalable data pipelines, data models, and cloud-based data systems. You’ll collaborate closely with data scientists, ML engineers, product teams, and other technical partners to ensure high-quality, reliable, and well-structured data is available across the organization. 
Key Responsibilities 
Data Pipeline Development 
Build, optimize, and maintain scalable ETL/ELT pipelines for structured and unstructured data. 
Implement reliable, fault-tolerant ingestion and transformation workflows. 
Automate routine data processes where possible. 
Data Architecture & Modeling 
Develop well-structured data models that support analytics, ML use cases, and downstream applications. 
Support the design and enhancement of AI-related data architecture across cloud environments. 
Data Quality & Governance 
Implement automated data validation, monitoring, and alerting. 
Ensure high data accuracy, completeness, and integrity across ingestion and transformation layers. 
Cross-Functional Collaboration 
Partner with data scientists, ML engineers, product managers, and IT teams to understand data requirements and translate them into technical solutions. 
Troubleshoot issues and support stakeholders with data access and pipeline improvements. 
Cloud & Infrastructure 
Work with modern cloud platforms (AWS, Azure, or GCP) and associated data storage, compute, and orchestration services. 
Support deployment, scaling, and operational health of data systems. 
Innovation & Continuous Improvement 
Stay current with emerging data engineering tools and best practices. 
Propose opportunities to improve performance, efficiency, or reliability within the data stack. 
Qualifications & Skills 
Education & Experience 
Bachelor’s degree in Computer Science, Data Engineering, or related technical field (or equivalent experience). 
3–7 years of hands-on experience in data engineering or data pipeline development. 
Technical Skills 
Strong SQL skills and proficiency in Python or Scala. 
Experience with data warehousing technologies such as Snowflake, BigQuery, Redshift, or Databricks. 
Hands-on experience with cloud services (AWS, Azure, or GCP). 
Knowledge of data modeling, schema design, and ETL/ELT principles. 
Familiarity with distributed computing frameworks such as Spark or Flink. 
Experience with workflow orchestration tools like Airflow, Prefect, or Dagster is a plus. 
Soft Skills 
Strong problem-solving skills and attention to detail. 
Ability to communicate technical concepts clearly to peers and cross-functional partners. 
Comfortable working in a fast-moving, collaborative environment. 
Preferred Qualifications 
Experience with streaming data tools such as Kafka or Kinesis. 
Experience building CI/CD pipelines for data workflows. 
Experience in healthcare, biotech, life sciences, or commercial/marketing data environments. 
Experience in agency or consulting settings. 
Posting Salary
$140,000—$175,000 USD
Real Chemistry is proud to be Great Place to Work® certified; check out what our people shared about our culture and workplace on our Great Places to Work Profile here.
We believe we can do our best when feeling our best, which is why we’ve put together a benefits program designed to give you the support you and your family need at every stage of life. Real Chemistry offers a comprehensive benefit program and perks, tailored to your region. Globally, this includes offices in our key markets with free snacks to keep you running all day long, generous holiday and paid time off, options for private medical, dental, and vison plans, and support in saving for the future. Other perks include mental wellness coaching and support and access to more than 13,000 online classes with LinkedIn Learning. Learn more about our great benefits and perks and search specific offerings in your region at: www.realchemistrybenefits.com.
Working with Real HART: Since the pandemic, we have adapted to how our people told us they want to work. We have office locations in cities in the US, UK, and Europe with many employees and clients that serve as hubs where and when they need us. For employees who are within an hour of one of our offices, we expect attendance in the office two days per week, either at a Real Chemistry office or onsite with clients. We are also actively opening new office locations, so if one opens near you, our Real HART policy will apply. We are not looking for attendance for the sake of attendance but believe that the opportunity to coordinate in-office team meetings, 1:1 meetings with managers, taking advantage of on-site learning, and connecting with client partners is a critical to delivering on our purpose of making healthcare what it should be. Outside of these offices, we have regions, where people work remotely but come together quarterly for collaboration, culture and learning opportunities. We call this our Real Hybrid and Regional Teams (Real HART) approach. Real Chemistry believes we are best together – and our workplace strategy fosters connection and collaboration in person – but also supports flexibility for our people.
Real Chemistry is an Equal Opportunity employer. We continually strive to build and sustain an inclusive and equitable work environment where our employees feel empowered to leverage all they bring from their personal lived experience and professional expertise, to make our team the best in the industry. We encourage motivated and qualified applicants to apply without regard to race, color, religion, sex (including pregnancy), sexual orientation, gender identity/expression, ethnic or national origin, age, physical or mental disability, genetic information, marital information, or any other characteristic protected by federal, state, or local employment discrimination laws where Real Chemistry operates. Should you require accommodations throughout the interview process please let your recruiter know.
*Notice: Real Chemistry and its affiliates' names are being misused by scammers through messaging services, fake websites, and apps. Do not share personal or financial information or make payments to any unverified sources claiming to be connected to Real Chemistry. We are working to stop these unauthorized activities and protect our community. Read more here."
2025-12-12T17:29:23,Senior Python Data Engineer - (Remote)  ,KBRA,"Position Title: Senior Python Data Engineer - (Remote) 
Entity: KBRA Holdings LLC
Employment Type: Full-Time
Location: Remote (Remote only in CA, CO, DC, FL, IL, MD, NJ, MA, NY, PA, SC, TX, VA)
Summary/Overview:
KBRA (KBRA Holdings, LLC) is seeking an engaged and proactive Senior Python Data Engineer to work on our financial analytical system. We want someone who loves solving difficult problems, digs deeply to understand the domain in which they’re working, and excels at creating high-quality software in a collaborative environment.
About the Team:
We believe that small, empowered teams can do amazing things. Across the engineering organization, we work hard to make the best systems for our customers using modern engineering practices. We are intentional in our investments in time and effort around creating a safe and successful workplace for our team members. We understand software engineering goes beyond the 1’s and 0’s and prioritize concrete value for our customers.
About the Job:

This role involves joining an existing team with a well-defined product vision. This team operates collaboratively, and there is an expectation to get involved in all aspects of design, delivery, and support of our systems.

This role emphasizes collaboration with our technical and non-technical counterparts to learn our domain and its unique challenges, while delivering value to our customers. It also requires collaboration with our other engineering, design, product, and platform teams to develop, build, run, and support the system.
About You:

You will be successful in this role if you:
Develop, test, and maintain scalable Python applications.
Collaborate with product managers, designers, and other engineers to deliver high-quality software.
Write clean, efficient, and reusable code following best practices.
Participate in code reviews to ensure code quality and share knowledge with the team.
Troubleshoot and debug issues in a timely manner.
Contribute to the design and architecture of new features and systems.
Have a sense of ownership and craftsmanship around the code base and your work.
Enjoy helping other developers grow and learn new technologies.
Display a strong track record of mentorship with engineers at various levels.
Are mindful of application security and performance.
Take pride in learning, and want opportunities to learn throughout your day-to-day.
Possess a pragmatic mindset. 
Familiarity with Generative AI tools such as ChatGPT for research, data insights, and general productivity is a plus.
Must have skills:
3–6 years of professional software engineering experience, with a strong portfolio of full stack development work.
Proficiency in Python, including experience with web frameworks such as Flask.
Cloud experience, particularly with AWS (Amazon Web Services).
Experience integrating frontend applications with RESTful APIs and backend services.
Relational and non-relational databases (SQL Server, Snowflake and MongoDB).
Debugging, issue resolution, and troubleshooting.
Nice to have skills:
Familiarity with UX design tools (Figma) and solid understanding of the design-engineering hand-off process
Containerized development and deployment (i.e. Docker, Docker swarm, Kubernetes)
Infrastructure as Code (Terraform)
Familiarity with deployment pipelines, CICD tools.
Exposure to financial systems or credit modeling is strongly preferred.
Salary Range:
The anticipated annual base salary range for this full-time position is $130,000 - $160,000. Offer amounts are determined by factors such as experience, skills, geography, and other job-related factors.
Benefits:
Competitive benefits and paid time off
Paid family and disability leave
401(k) plan, including employer match (100% vested)
Educational and professional development financial assistance
Employee referral bonus program
About Us:
KBRA is a full-service credit rating agency registered in the U.S., the EU and the UK, and is designated to provide structured finance ratings in Canada. KBRA’s ratings can be used by investors for regulatory capital purposes in multiple jurisdictions.
More Info:
KBRA encourages applications from all qualified individuals without regard to race, color, religion, gender, sexual orientation, gender identity or expression, age, national origin, marital status, citizenship, disability, and veteran status or any other basis prohibited by federal, state or local law.
#LI-KS1
#REMOTE"
2025-12-12T17:19:54,Data Platform Engineer,Dragonfli Group,"Dragonfli Group is a cybersecurity and IT consulting firm providing services to federal agencies and Fortune 100 enterprises. Headquartered in Washington, DC, Dragonfli supports clients in securing mission-critical systems across on-site, hybrid, and fully remote environments.

This contract Data Platform Engineer role supports a large federal agency in protecting security data platforms within a large-scale IT environment. The engineer will manage security data platforms such as Splunk and data lakes, ensuring effective data flows, integrations, and platform support. Key technologies include Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS. The role requires seasoned IT security expertise, hands-on technical skills, and strong communication and planning abilities. It's a high-impact opportunity to shape security analytics capabilities within a major federal agency.

This is a multi-year contract position involving a large US federal agency. Candidates with previous federal contracting experience are preferred. U.S. Citizenship or Permanent Residency required. If hired, all work related to this role must be performed within the continental U.S.

Responsibilities:
Manage security data platforms, such as Splunk and data lakes.
Ensure effective data flows, integrations, and platform support.
Support event ingestion, platform maintenance, and technical add-ons.
Troubleshoot to support operational and compliance reporting.
Optimize data use for security monitoring, incident response, and threat analysis.
Collaborate across teams to enhance security analytics capabilities.
Configure and maintain various event ingestion methods.
Create and maintain custom TAs for data parsing into Splunk CIM format.
Monitor and perform routine maintenance of data systems.
Drive process improvements and attention to detail.

Requirements
Four (4)+ years of experience supporting enterprise data platforms.
BS/BA in a cyber-related field or equivalent experience/certifications.
Experience with installing, updating, and maintaining ELM and SIEM.
Proficiency with Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS.
Experience configuring and maintaining event ingestion methods.
Ability to create and maintain custom TAs for Splunk.
Experience in troubleshooting, monitoring, and maintaining data systems.
Familiarity with enterprise security operations.
Strong cross-functional communication skills.

Skill(s)
Hands-on management of security data platforms.
Expertise in data flows and platform integrations.
Proficiency in Splunk and related technologies.
Strong troubleshooting and problem-solving skills.
Ability to optimize security monitoring and incident response.
Excellent cross-functional communication abilities.
Attention to detail and process improvement mindset.
Ability to work collaboratively across teams.
Strong planning and organizational skills.

Benefits
Insurance – health, dental, and vision
Paid Time Off (PTO) and 11 Federal Holidays
401(k) employer match

Travel
null"
2025-12-12T16:50:01,Staff Configuration Data Engineer,Archer,"Archer is an aerospace company based in San Jose, California building an all-electric vertical takeoff and landing aircraft with a mission to advance the benefits of sustainable air mobility. We are designing, manufacturing, and operating an all-electric aircraft that can carry four passengers while producing minimal noise.
Our sights are set high and our problems are hard, and we believe that diversity in the workplace is what makes us smarter, drives better insights, and will ultimately lift us all to success. We are dedicated to cultivating an equitable and inclusive environment that embraces our differences, and supports and celebrates all of our team members.
What you'll do:
As the Configuration Data Engineer, you will combine software development expertise with configuration management practices to safeguard product data integrity, traceability, and compliance. You will design tools, reports, and automations that enable engineering and product teams to make faster, more accurate configuration decisions.
Develop and maintain tools and reports to monitor bills of materials (BOMs), effectivity assignments, and configuration changes
Create automated quality checks to validate workflows and ensure compliance with configuration management standards
Integrate with Teamcenter APIs and background services to access, analyze, and validate engineering data
Build automation scripts to support NX, CATIA, and other CAD-driven workflows (NX Open, CATIA VB, Check-Mate, NX Check-Mate)
Support the definition, maintenance, and auditing of BOM structures, unit effectivity, and date-based effectivity for engineering changes
Develop dashboards and metrics reporting to provide visibility into change requests, change notices, and configuration status accounting
Collaborate with configuration management, engineering, and IT teams to streamline data flow across systems
Investigate data anomalies and provide corrective recommendations to maintain design and change integrity
Partner with project teams to ensure effectivity assignments are properly implemented and reflected in reports
Contribute to the improvement of enterprise configuration management processes through data-driven insights
Serve as a technical resource to CM specialists for reporting, automation, and API usage
What You Need
To be a self starter with a strong desire to learn new technologies
Ability to translate engineering/CM requirements into automated solutions
2+ years of experience developing tools and reports for a Product Lifecycle Management (PLM) tools (e.g., Teamcenter, Windchill, Enovia, 3DX) or equivalent engineering data environments
Experience with relational databases (SQL, PostgreSQL, Oracle) for reporting and automation
Ability to interpret engineering drawings, CAD data, and metadata
Understanding of BOM structures, unit effectivity, and date-based effectivity methods
Familiarity with engineering change processes, including Change Requests (CRs) and Change Notices (CNs)
Experience with scripting or automation in CAD/PLM environments (NX Open, CATIA VB, or similar)
Strong problem-solving skills and ability to analyze complex datasets for process improvements
Effective written communication skills to document procedures and produce clear reports
Ability to work in a collaborative environment across engineering, CM, and IT teams
Bonus Qualifications
Hands-on experience with Siemens Teamcenter APIs or integrations
Experience with Business Intelligence tools such as Power BI, Sigma, or SAP Hana
Experience with ITI CADIQ tools and CAD data validation workflows
Experience with Elysium CAD Translation tools
Familiarity with NX Check-Mate and automations
Familiarity with ASME Y14.5 Dimensioning and Tolerancing
Experience developing Adobe Forms with JavaScript and PDF publishing workflows
Exposure to aerospace, automotive, or other complex product development environments
Knowledge of configuration management standards and compliance practices (CMII, EIA-649, etc.)
This role is ideal for engineers who enjoy bridging software development with product lifecycle control. You will directly impact how engineering data is managed, ensuring accuracy, efficiency, and compliance across the enterprise
Archer is committed to working with and providing reasonable accommodations to job applicants with physical or mental disabilities, and those with sincerely held religious beliefs. Applicants who may require reasonable accommodation for any part of the application or hiring process should provide their name and contact information to Archer’s People Team at people@archer.com. Reasonable accommodations will be determined on a case-by-case basis.
Information collected and processed as part of any job applications you choose to submit is subject to Archer's Candidate Privacy Policy.
Archer is unable to provide work visa sponsorship for this position at the present time.
Archer is proud to be an Equal Opportunity employer committed to diversity and inclusivity in the workplace. All aspects of employment are decided on the basis of merit, qualifications, and business needs. We do not discriminate based upon race, color, religion, sex, sexual orientation, age, national origin, disability status, protected veteran status, gender identity or any other characteristic protected by federal, state or local laws.
Archer Aviation does not engage with external recruiting agencies/individual recruiters with whom it does not have a prior written agreement. Archer reserves the right to make use of any unsolicited resumes that it receives and bears no responsibility for payment of any fees asserted from the use of unsolicited resumes. If you are a recruiting agency or individual recruiter wishing to do business with Archer, please reach out to People@archer.com. All employment processes are managed by the Archer People Team."
2025-12-12T16:14:31,Data Engineer - Integrated Supply Chain,Textron,"Data Engineers build and maintain data systems in support of data analytics and data science activities. The Data Engineer will implement methods to improve data reliability, data quality, and ensure success in data-driven initiatives.
This position within Integrated Supply Chain Analytics is responsible for identifying, developing, and executing solutions that support reliable and efficient extraction of data from source systems and loading of that data into analytic platforms. The Data Engineer will help administer data platforms and consult with data analysts and data scientists on process optimization and data quality improvements.
At Textron Aviation, we are building a community of Data & Analytics professionals with an emphasis on collaboration and cross functional support. You will have the opportunity to work closely with your peers throughout the organization toward a vision of data driven strategy.


JOB RESPONSIBILITIES:
· Gain core business understanding of Textron Aviation and aircraft design, operation, and support
· Query, clean, transform, and stage data (ETL/ELT) across on-prem and cloud environments
· Support data analytics and data science activities by implementing, maintaining, and optimizing production ready data pipelines
· Install and update software to ensure data platform continuity
· Administer a CI/CD compliant code repository during development and update activities
· Research and help implement new technologies to support analytics function
· Interface with other data professionals throughout the organization to embrace cross functional growth in analytics capabilities
· Work to improve data quality by assisting data governance efforts in creating and maintaining data quality standards
· Plan and execute projects according to established milestones and schedules
· Train users in data & analytic tools and processes per best practices and compliance standards
· Contribute to the resolution of service tickets pertaining to data infrastructure
· Serve as an internal consultant to business leaders by advising on system capabilities
EDUCATION/ EXPERIENCE:
· Bachelor’s degree in Computer Science, Software Engineering, Data Science/Analytics, MIS, or other related technical field
· Minimum 2 years relevant technical experience required, focused on data collection, utilization, and analysis.
· Aviation experience preferred
Textron Aviation Inc. must comply with U.S export control laws and regulations. If a position requires access to sensitive information controlled under these laws and regulations, a successful applicant must be eligible to meet any requirements to access controlled information."
2025-12-12T16:07:56,Senior Data Engineer ,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:55,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:54,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T15:01:13.806,"Software Engineer III, Infrastructure, Audience Data Processing",Google,"MINIMUM QUALIFICATIONS:

 * Bachelor’s degree or equivalent practical experience.
   
 * 2 years of experience with software development in C++, SQL, Borg, Flume, or
   1 year of experience with an advanced degree.
 * 2 years of experience with developing large-scale infrastructure, distributed
   systems or networks, or experience with compute technologies, storage or
   hardware architecture.



PREFERRED QUALIFICATIONS:

 * Master's degree or PhD in Computer Science or related technical fields.
   
 * 2 years of experience with data structures and algorithms.
 * Experience with Flume and large scale data processing pipelines.
 * Experience developing accessible technologies.
   


ABOUT THE JOB:

Google's software engineers develop the next-generation technologies that change
how billions of users connect, explore, and interact with information and one
another. Our products need to handle information at massive scale, and extend
well beyond web search. We're looking for engineers who bring fresh ideas from
all areas, including information retrieval, distributed computing, large-scale
system design, networking and data storage, security, artificial intelligence,
natural language processing, UI design and mobile; the list goes on and is
growing every day. As a software engineer, you will work on a specific project
critical to Google’s needs with opportunities to switch teams and projects as
you and our fast-paced business grow and evolve. We need our engineers to be
versatile, display leadership qualities and be enthusiastic to take on new
problems across the full-stack as we continue to push technology forward.

As a Software Engineer on the Audience Data Processing Infrastructure team, you
will innovate and optimize planet-scale data processing flows to support Google
Ads.

While we're an infrastructure team, we operate in a fast-paced environment with
evolving requirements. Our focus is on supporting client data processing needs,
enhancing operational excellence and developer velocity, and significantly
improving resource efficiency.


Google Ads is helping power the open internet with the best technology that
connects and creates value for people, publishers, advertisers, and Google.
We’re made up of multiple teams, building Google’s Advertising products
including search, display, shopping, travel and video advertising, as well as
analytics. Our teams create trusted experiences between people and businesses
with useful ads. We help grow businesses of all sizes from small businesses, to
large brands, to YouTube creators, with effective advertiser tools that deliver
measurable results. We also enable Google to engage with customers at scale.

The US base salary range for this full-time position is $141,000-$202,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Write product or system development code in C++ for infrastructure
   responsible for managing and optimizing processing of planet-scale data
   processing.
 * Investigate data storage and processing use cases, techniques, and
   identifying opportunities for future innovation.
 * Review code developed by other developers and provide feedback to ensure best
   practices (e.g., style guidelines, checking code in, accuracy, testability,
   and efficiency).
 * Contribute to existing documentation or educational content and adapt content
   based on product/program updates and user feedback.
 * Triage product or system issues and debug/track/resolve by analyzing the
   sources of issues and the impact on hardware, network, or service operations
   and quality."
2025-12-12T13:26:27,Cleared On Site Data Engineer (4899),SMX,"SMX is seeking a Senior Data Architect to provide strategic and technical leadership for enterprise data architecture and analytics modernization efforts. This individual will design, optimize, and oversee data solutions that enable advanced analytics, business intelligence, and reporting capabilities across multiple secure environments. This role will focus on designing, developing, optimizing, and maintaining data pipelines and backend data engineering solutions that power critical analytical products used by senior FBI leadership. The ideal candidate brings deep technical expertise in ETL processes, SQL, Python, AWS data services, and enterprise-scale data warehousing, with strong familiarity in BI ecosystems such as MicroStrategy (Strategy), ThoughtSpot, and related tools used within the HR Reports program. The position requires close collaboration with government leads, senior data developers, BI engineers, and cross-functional analytics teams to ensure high reliability, performance, and security of data products supporting mission-critical operations. 
This is a full-time position requiring on-site work five days a week at a client’s office in Washington, D.C. An active Top Secret clearance is mandatory.
Essential Duties and Responsibilities: 
Design, build, and maintain scalable, secure ETL/ELT pipelines supporting HR Reports analytics and dashboard products.
Develop and optimize SQL-based transformations, stored procedures, and data models for high-volume enterprise datasets.
Implement data orchestration workflows using AWS services (e.g., Glue, Lambda, Step Functions, CloudWatch).
Ensure data quality, lineage, and integrity across multiple enterprise data sources.
Support and enhance cloud-based warehouse environments within AWS (e.g., Redshift, S3, IAM).
Collaborate with BI developers to ensure backend data structures meet MicroStrategy/Strategy and ThoughtSpot reporting needs.
Troubleshoot complex data pipeline or performance issues and implement long-term remediation solutions.
Translate government stakeholder requirements into technical specifications for new data sources and pipelines.
Partner with Data Analysts, Data Scientists, and BI Developers to support advanced analytics and ad-hoc data requests.
Apply data governance, security, and compliance best practices in alignment with FBI and SMX standards.
Recommend and implement improvements to automation, data architecture, pipeline reliability, and overall performance.
Maintain documentation for pipelines, logic, data flows, and system dependencies.
Stay current with modern data engineering practices and AWS service enhancements relevant to pipeline automation and warehousing.
Required Skills: 
10+ years of experience in data architecture, data warehousing, or enterprise analytics systems.
Expert-level proficiency in SQL and data modeling
Hands-on experience designing and implementing ETL/ELT frameworks (e.g., Apache Airflow, dbt, AWS Glue, Informatica).
Demonstrated success architecting and optimizing large-scale BI/reporting solutions (MicroStrategy, ThoughtSpot, Power BI, Tableau).
Strong knowledge of AWS data ecosystem (Redshift, Athena, S3, Glue, Lambda) or similar cloud environments.
Experience defining and enforcing data governance, quality, and security standards.
Ability to design and document end-to-end data flows and integrations between transactional and analytical systems.
Excellent communication, analytical, and problem-solving skills.
Desired Skills/Experience:
Bachelor’s or Master’s degree in Computer Science, Information Systems, Data Engineering, or related technical field.
10+ years of experience in data engineering, backend data development, or enterprise-scale ETL development.
Experience supporting federal government IT systems or analytics programs.
Familiarity with Agile methodologies and Jira-based workload management.
Experience supporting or modernizing enterprise BI ecosystems.
**This position requires five days a week on site at customer location in Washington DC.
Application deadline 1-16-2026
#LI-SA
#cjpost
The SMX salary determination process takes into account a number of factors, including but not limited to, geographic location, Federal Government contract labor categories, relevant prior work experience, specific skills, education and certifications. At SMX, one of our Core Values is to Invest in Our People so we offer a competitive mix of compensation, learning & development opportunities, and benefits. Some key components of our robust benefits include health insurance, paid leave, and retirement.
The proposed salary for this position is:
$114,600—$192,500 USD
At SMX®, we are a team of technical and domain experts dedicated to enabling your mission. From priority national security initiatives for the DoD to highly assured and compliant solutions for healthcare, we understand that digital transformation is key to your future success.
We share your vision for the future and strive to accelerate your impact on the world. We bring both cutting edge technology and an expansive view of what’s possible to every engagement. Our delivery model and unique approaches harness our deep technical and domain knowledge, providing forward-looking insights and practical solutions to power secure mission acceleration.
SMX is an Equal Opportunity employer including disabilities and veterans.
Selected applicant may be subject to a background investigation and/or education verification.
SMX does not sponsor a new applicant for employment authorization or immigration related support for this position (i.e. H1B, F-1 OPT, F-1 STEM OPT, F-1 CPT, J-1, TN, E-2, E-3, L-1 and O-1, or any EADs or other forms of work authorization that require immigration support from an employer)."
2025-12-12T12:29:19.508,"Data Center Plant Engineer, Mechanical, Electrical",Google,"MINIMUM QUALIFICATIONS:

 * Associate's degree, trade school certification, or other certified training
   in a related technical field, or equivalent practical experience.
 * 7 years of experience in electrical, mechanical/HVAC, or controls/automation
   experience in an industrial or commercial environment.



PREFERRED QUALIFICATIONS:

 * Experience working in data centers, hospitals, or power plants.
 * Knowledge of electrical and mechanical systems used in a data center
   environment (e.g., Feeders, Transformers, Generators, Switchgear, UPS
   systems, ATS/STS units, PDU/PMM units, Chillers, Air handling units, and CRAC
   units).
   
 * Knowledge of meters, devices, sensors, and troubleshooting utilizing standard
   hand tools, digital metering, or calibration/diagnostic equipment.
   
 * Ability to communicate with contractors who perform maintenance or upgrade
   work on the data center systems.
   


ABOUT THE JOB:

The Data Center team designs and operates some of the most sophisticated
electrical engineering, mechanical engineering and HVAC systems in the world.
Facilities Technicians at Google data centers operate, monitor and support
physical facilities conditions. Some of these duties will include heating and
cooling of air and water, power supply, generators, UPS systems, electrical
distribution and control and monitoring systems. You regularly help inspect,
maintain and repair various data center systems such as piping and non-critical
electrical or mechanical system components). You provide daily assistance to
senior technicians as you read blueprints/schematics, conduct tours of systems
and assess their working order.

As a master of exceptional practices, you develop creative approaches to
reducing operational costs while improving overall data center efficiency. You
ensure that environmental and safety standards are consistently met, identifying
problems and making repairs quickly In emergency situations or abnormal
conditions, you manage data center performance issues and outages to minimize
the recovery time from failures.The AI and Infrastructure team is redefining
what’s possible. We empower Google customers with breakthrough capabilities and
insights by delivering AI and Infrastructure at unparalleled scale, efficiency,
reliability and velocity. Our customers include Googlers, Google Cloud
customers, and billions of Google users worldwide.

We're the driving force behind Google's groundbreaking innovations, empowering
the development of our cutting-edge AI models, delivering unparalleled computing
power to global services, and providing the essential platforms that enable
developers to build the future. From software to hardware our teams are shaping
the future of world-leading hyperscale computing, with key teams working on the
development of our TPUs, Vertex AI for Google Cloud, Google Global Networking,
Data Center operations, systems research, and much more.

The US base salary range for this full-time position is $105,000-$151,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Inspect, maintain, and repair various data center systems such as piping and
   non-critical electrical or mechanical system components.
   
 * Provide daily assistance to technicians as you read blueprints/schematics,
   conduct tours of systems, and assess their working order.
   
 * Manage the uptime and maintenance of water pumps and treatment systems, HVAC,
   UPS, generators, electrical distribution, and control and monitoring systems.
   
 * Operate, monitor, maintain, and respond to abnormal conditions in the data
   center facilities systems and equipment.
   
 * Support startup, commissioning, and integration of new equipment and systems
   into facilities infrastructure.
   "
2025-12-12T09:01:55.769,Data Engineer II,Microsoft,"Overview
With continued growth in digital data and the desire to leverage data to measure in-production quality and address problems that touch all aspects of our lives, Microsoft’s Windows Servicing & Delivery Org is looking for an equally data- and quality-minded engineer to meet these challenges! Join the Update Platform team for the chance to have an impact on billions of customers every day. The Update Platform Team is responsible for ensuring the seamless delivery and integration of software updates and keeping our customers up-to-date and secure at all times.
As a Data Engineer II member of the Update Platform Insights team, you will be at the forefront of leveraging data to assess the quality of the product, detect issues before they reach broad customer application to assure top product quality for partners and customers alike while keeping billions of devices secure and up-2-date.

In this exciting role, you'll work with a diverse group of talented professionals, innovate for greater platform efficiency as well as leveraging the latest technologies and best practices to streamline our update processes with timely in-depth insights and intelligent features.

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.


Responsibilities
Data Management and Transformation: With guidance, you will apply modification techniques to transform raw data into compatible formats for downstream systems. Utilize software and computing tools to ensure data quality and completeness. Implement code to extract and validate raw data from upstream sources, ensuring accuracy and reliability.
Drive Customer Success: Through Data and Business Insight: You will play a pivotal role in building a metrics-driven culture that directly impacts product quality and customer outcomes. This role goes beyond technical execution—you will design and implement measurement frameworks from the ground up while applying a strategic, top-down perspective to ensure the right metrics are in place. Your ability to translate data into actionable insights, aligned with business priorities and rhythm of business, will enable informed decisions that drive high-quality product outcomes and measurable customer success.

Data Requirements and Modeling: Collaborate with stakeholders to document and understand data requirements. Evaluate project plans to assess data costs, access, and availability. Draft design specifications to model data flow and storage, ensuring data is easy to connect and manage.
Compliance: You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams. You’ll also learn about permissions and approvals for data access within a data pipeline.

Validation and Quality Mindset: Apply and use operational fundamentals to validate and ensure quality of the product as well as the underlying data pipeline and assets to secure trustworthiness in your data daily.

Customer Focus: Be driven by a focus on customer happiness and success. We as a team only succeed if our customers are secure and protected via the updates we deliver.


Qualifications
Required Qualifications:
Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 1+ year(s) experience in business analytics, data science, software development, data modeling, or data engineering
OR Bachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 2+ years experience in business analytics, data science, software development, data modeling, or data engineering
OR equivalent experience.
Other Requirements:
Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include but are not limited to the following specialized security screenings:
Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.
Preferred Qualifications:
3+ years with scripting and coding languages with a focus on data engineering, like SQL, KQL, python, Scope, C# (or similar object-oriented languages) and others.
1+ years of experience with building large data processing frameworks using technologies like Azure Data Factory, Azure Data Explorer, PowerBI and/or other public and Microsoft internal tools.
1+ years of experience in analytics to define, monitor, and optimize key performance indicators (KPIs) and connected business metrics that ensure measurable customer success.
1+ years of proven ability to orchestrate and sustain a data-driven rhythm of business, transforming insights into actionable strategies that align with organizational priorities and deliver impactful outcomes.
A solid quality mindset with the ability to deliver end-to-end data solutions that build partner and customer confidence, ensuring alignment with business objectives and measurable outcomes.
Experience with Git, ADO or equivalent Source Control Systems.
Experience with data visualization tools and how to effectively communicate Insights to consumers of varying types of audiences.
Experience leveraging AI to define and evaluate quality standards


Data Engineering IC3 - The typical base pay range for this role across the U.S. is USD $100,600 - $199,000 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $131,400 - $215,400 per year. 
Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:
https://careers.microsoft.com/us/en/us-corporate-pay

This position will be open for a minimum of 5 days, with applications accepted on an ongoing basis until the position is filled.


Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance with religious accommodations and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations."
2025-12-12T01:54:02.588,"Data Science Engineer, New College Grad- Master's/PhD (Santa Clara, CA)",Applied Materials,"Assist in developing data science software prototypes and interfaces for monitoring semiconductor process tools Develop Python scripts to implement key concepts Collaborate closely with algorithm developers to characterize the algorithms and benchmark their performance, collecting quantitative data assessing effectiveness Evaluate the effectiveness and accuracy of the algorithms by working closely with process and equipment experts, providing feedback to algorithm developers Provide solutions which can be implemented by engineers without a deep statistical or mathematical background Deploy and maintain solutions at service sites Troubleshoot solutions, provide workarounds, and assist users in using solutions Assess effectiveness of solutions and provide data science insight Communicate well with algorithm developers and process experts Train field engineers to use solutions Present work and conclusions clearly and succinctly to peers Work well in team, providing and receiving constructive input with team members Monitor and quantify the results of complex algorithms in a production environment. Train a variety of individuals on the operation of these algorithms. Experience with various Artificial Intelligence Solutions, including Large Language Models, Computer Vision and Generative AI applications. Python, MATLAB Familiarity with common data science techniques, including regression, decision trees, Principle components, PLS, various Neural networks, time-series techniques, Bayesian techniques, etc. Ability to troubleshoot software applications and perform basic DevOps for deployment Ability to interact with Process and Customer Engineers Semiconductor process or equipment experience preferred. Demonstrates depth and/or breadth of expertise in own specialized discipline or field May lead small functional teams or projects with moderate resource requirements, risk, and/or complexity Communicates difficult concepts and negotiates with others to adopt a different point of view Master's or PhD in Computer Science, Data Science, Software Engineering, Mechanical Engineering, or related field. Preferred GPA of 3.0 or above"
2025-12-12T01:52:09.253,"Vice President, Data Engineer",BNY,"Bachelor's or master's degree in computer science or a related discipline, or equivalent work experience is required. 10+ years of data modeling, database design and development or related experience is required. Prior experience in managing DB development team Experience modeling Financial data Prior experience modeling Client and Entitlement Data Good knowledge of Financial Accounts, Transactions and Positions data Hands-on experience with any RDBMS, preferably MS SQL Server or Oracle Good SQL knowledge Excellent communication skills Good Problem Solving & Analytical Skills Work experience in Financial Services Work experience on any data modeling tool, viz. Erwin, DBArtisan etc. Experience with writing ANSI SQL code Prior Experience with a scripting language, preferably Python Experience working with Cloud native databases Bachelor's or Master's degree in Computer Science or a related discipline, or equivalent work experience is required. Advanced degree is preferred. Experience in the Securities or Financial Services industry."
2025-12-12T01:08:33,Data Analytics Engineer,Masimo,"The Data Analytics Engineer will support Masimo’s Quality organization by developing dashboards, performing data analysis, and transforming large datasets into meaningful insights. This role partners closely with Quality Compliance, Product Assurance, Engineering, Operations and cross-functional stakeholders to enhance data visibility, drive data-informed decisions, and support continuous improvement across the organization. The ideal candidate is technically strong in analytics tools, comfortable working with structured and unstructured data, and eager to grow in a fast-paced and evolving environment.
Duties & Responsibilities
Develop and maintain Power BI dashboards and reports that translate complex data sets into clear, actionable information.
Perform data transformation and modeling using SQL, Power Query (M), and DAX to support quality metrics, KPIs, and trend analysis.
Support routine and ad-hoc data analytics requests related to customer feedback, failure analysis, operations, and compliance activities.
Analyze large datasets to identify trends and process improvement opportunities.
Collaborate with Quality Compliance, Product Assurance, and cross-functional engineering teams to ensure data accuracy, consistency, and alignment with business needs.
Communicate findings through effective data storytelling, written summaries, and monthly presentations to cross functional leaders across the organization.
Contribute to continuous improvement efforts in reporting automation, dashboard optimization, and analytics best practices.
Minimum & Preferred Qualifications and Experience
Experience
0–2+ years of experience in data analytics, business intelligence, or engineering analytics; internship or project experience considered.
Hands-on experience with SQL and Power BI (including Power Query/M and DAX).
Experience using Python or R for data manipulation, modeling, or visualization preferred.
Familiarity with data visualization tools (Power BI highly preferred; Tableau or Looker a plus).
Understanding of statistics, data modeling, or quantitative analysis techniques.
Skills & Competencies
Strong analytical and problem-solving skills with high attention to detail.
Ability to translate data into clear insights for technical and non-technical partners.
Strong verbal, written, and visual communication skills, with the ability to present confidently and engage diverse audiences.
Ability to work independently and in a team environment.
Curiosity and willingness to learn new tools, systems, and techniques.
Education
Bachelor’s degree in Data Analytics, Data Science, Business Intelligence, Computer Science, Engineering, or a related field required.
Master’s degree in a relevant field is a plus but not required.
Compensation:
The anticipated salary range for this position is $90,000 - $110,000 plus benefits. Actual placement within the range is dependent on multiple factors, including but not limited to skills, education, and experience. 
This position also qualifies for up to 10% annual bonus based on Company, department, and individual performance. 
Masimo offers benefits such as Medical, Dental, Vision, Life/AD&D, Disability Insurance, 401(k), Vacation, Sick, Holiday, Paid Maternity Leave, Flexible Spending Accounts, Voluntary Accident, Critical Illness, Hospital, Long-Term Care, Employee Assistance Program, Pet Insurance, On-site wellness clinic, fitness center, and cafe. All benefits are subject to eligibility requirements."
2025-12-12T00:39:10,Data Engineer,HealthPartners/GHI,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:39:10,Data Engineer,HealthPartners,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:14:05.56,Sr. Data Engineer,Apple,"As a Data Engineer on the Capacity Engineering team, you will help design,
build, and operate the data foundation that drives capacity, cost, and
power-related decisions across Apple’s infrastructure footprint. In this role,
you will: Architect, implement, and maintain large-scale batch and streaming
pipelines that ingest, process, and model infrastructure telemetry, cost,
metering, utilization, forecasting, and power metrics from multiple clouds and
bare metal environments. Design and evolve robust data models (with a strong
focus on dimensional modeling) and storage patterns that support analytics,
internal billing, and efficiency use-cases. Treat data as a product: define
quality checks, SLAs, and observability to ensure data is accurate, timely, and
trusted by stakeholders across Apple. Integrate and enrich raw signals with
metadata and attribution to power use cases such as internal billing/showback,
usage understanding, efficiency and optimization, clawbacks, planning, and
procurement. Collaborate closely with data scientists, software engineers,
platform teams, finance partners, program managers, and leadership to translate
requirements into scalable, reliable data solutions and services. Implement
standard methodologies for data governance, lineage, metadata management, and
security, in alignment with Apple’s standards for data protection and privacy.
Build end-to-end data solutions that include logging, anomaly detection, data
validation, cleaning, and transformation, with strong emphasis on monitoring,
debuggability, and continuous improvement. Contribute to the evolution of our
data and platform stack, including tooling, frameworks, and standards for
development, testing, deployment, and operations (CI/CD, infrastructure as code,
etc.).


DESCRIPTION


Apple’s Capacity data engineering team, within the Apple Services Engineering
organization, is building the centralized data backbone that powers how Apple
understands, plans, and optimizes its cloud and data center infrastructure. We
engineer a unified, trusted data lake that consolidates cost, metering,
utilization, forecasting, and power metrics produced by Apple platforms and
systems (including bare metal) across both third-party and Apple internal
clouds. Enriched with metadata and attribution, this becomes the single source
of truth for internal billing, understanding usage and utilization, clawbacks,
planning, procurement, and efficiency initiatives. We collaborate with platform
engineering, finance, capacity engineering, and leadership teams to build
large-scale data pipelines, enable descriptive and predictive analytics, and
power dashboards and products that support critical business decisions. This is
your opportunity to help design and operate highly visible, global-scale systems
processing petabytes of data and supporting hundreds of users across Apple. Come
join us to help deliver the next generation of infrastructure insights at Apple.


MINIMUM QUALIFICATIONS


Bachelors degree or equivalent experience in Computer Science, Information
systems, Software Engineering, Data Science or related field. Advanced degree in
a related field a plus. 5+ years of experience in data engineering (or
equivalent practical experience), including: Building and maintaining
large-scale ETL/ELT data pipelines Distributed computing (e.g., Spark / PySpark)
for data processing and automation Query performance optimization and tuning at
scale Hands-on experience with: Apache Spark and Airflow (or similar
workflow/orchestration tools) for efficient large-scale data pipelines Data
modeling, especially dimensional modeling, and designing schemas optimized for
analytics and reporting Big data platforms and/or data lake architectures


PREFERRED QUALIFICATIONS


Experience with cloud technologies, specifically AWS (e.g., S3, EMR, Lambda,
Glue, RDS/Redshift, or similar services) Tooling & ecosystem: Experience with
CI/CD tooling such as Jenkins (or similar tools) Experience with data
visualization / BI tools, such as Superset or Tableau (other tools like
QuickSight, QlikView, Cognos, or Business Objects are a plus) Experience with
containerization and orchestration, such as Docker and Kubernetes/EKS is a plus
Understanding of authentication and authorization (AuthN/AuthZ) patterns
Knowledge of data governance principles, data security best practices, and data
privacy regulations"
2025-12-12T00:00:00,Lead Data Engineer,Nuna,"At Nuna, our mission is to make high-quality healthcare affordable for everyone. We are dedicated to tackling one of our nation’s biggest problems with ingenuity, creativity, and a keen moral compass.
Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why.
Nuna has established its brand in the B2B space over the last decade by shifting the US healthcare system towards an incentive model that rewards healthcare providers for positive outcomes. Marshalling our collective backgrounds and insights, we are now crafting an innovative, consumer app - a clinically driven healthcare companion experience that leverages AI, gamification and social support techniques to improve outcomes for people with chronic conditions.
As a sign of the impact Nuna has already made in this space, Nuna was recently selected to join the Centers for Medicare & Medicaid Services (CMS) Health Tech Ecosystem, a landmark public-private initiative designed to transform healthcare for Americans.
YOUR TEAM
The Data org at Nuna is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research.
The Data Engineer team is a core part of the broader Data organization, which is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research. The Data Engineer team acts as the technical backbone for data architecture, platform development, and data operations, empowering the organization to deliver impactful data-driven solutions in healthcare.
YOUR OPPORTUNITIES
We are looking for someone who is excited to use their creativity and engineering skills to make a difference in healthcare. You will have a foundational role on a team building a consumer product that incentivizes healthy behavior. You will be responsible for the data architecture and direction of the data platform that powers our data operations and data science initiatives.
Own the architecture and evolution of the data platform, based on business needs and considering trade-offs in timelines, cost, and resources
Define and enforce standards for code development, contribution, and deployment for data engineering workflows.
Oversee integrations with external services, including data ingestion, distribution, and service-to-service data flows.
Contribute hands-on to data transformations and optimizations
Establish security, governance, and operational best practices for the data platform in collaboration with security and enterprise data engineering teams.
Curate and develop datasets needed to support Data org project deliverables
Collaborate with cross-functional partners in engineering, design, and product to develop solutions
Generate and prioritize new opportunities for improvements
Provide build vs buy assessments and recommendations as the platform expands
QUALIFICATIONS
Required Qualifications
Deep hands-on expertise in designing, coding, developing, and maintaining data platforms that support data analytics and data science use cases
Proven ability to design, develop and implement robust data ingestion pipelines (ETL) from external sources into a data platform.
Experience establishing standards for code development, deployment, and contributions in a data engineering environment.
Ability to solicit and translate customer and business needs into requirements and an evaluation framework
Interest in improving healthcare and working with interdisciplinary project teams
Clear communication and presentation skills
Experience with Databricks
Expertise in data platform languages such as python, pyspark and SQL
+ 5-10 years of industry experience with technical lead experience of running a data platform for business operations
Preferred Qualifications
MS in quantitative field (e.g. Data Science, Economics, Statistics, Engineering)
Experience building a data platform from zero to one
Experience working with healthcare data
Experience with SDLC and management of machine learning models (MLOps)
Bonus points if experience with MLOps on LLM/GenAi features (evals, context building, …)
We take into account an individual’s qualifications, skillset, and experience in determining final salary. This role is eligible for health insurance, life insurance, retirement benefits, participation in the company’s equity program, paid time off, including vacation and sick leave. The expected salary range for this position is $208,000 - $260,000. The actual offer will be at the company’s sole discretion and determined by relevant business considerations, including the final candidate’s qualifications, years of experience, and skillset.
Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status.
#LI-FK1"
2025-12-12T00:00:00,Development Project Engineer (Data Center Construction),QTS Data Centers,"Who we are: It's pretty exciting to find yourself standing in a pivotal moment in time. It’s even more exciting to be out front leading it. At QTS, our world-class data centers are supporting our customers’ most strategic growth initiatives, positioning us at the forefront of today’s dynamic digital transformation. As AI and cloud drive the demand for increased speed, capacity and capability, QTS has emerged as the global digital infrastructure leader, committed to connecting the world for good. Driven by purpose and fueled by a spirit of innovation, QTS designs, builds and operates some of the world’s most advanced, forward-thinking data centers. QTS is a portfolio company of Blackstone. QTS is Powered by People. People who play a vital role in our company’s culture, innovation and growth. People who are committed to contributing to the communities where we operate and work. People who are knowledgeable, resourceful and mission driven. Together, we do great things. Who You Are: The Development Project Engineer (Data Center Construction) is primarily responsible for assisting with the design, preconstruction and construction activities on a given project(s). The Development Project Engineer will interact on a daily basis with Facilities, Contractors, Designers, Engineers, Commissioning Agents, Vendors, and Data Center Operations & Corporate real estate staff and should have both written and oral communication skills commensurate with this level of regular communication. What You Will Do: Assist Development leadership and Project Manager with day to day activities and responsibilities Assist with multiple projects on a campus(es) and maintain updated budgets, schedules, and status reports for each Assist with updates on development program & project status on a monthly basis suitable for executive level reviews. Work with QTS stakeholders, design, and construction teams to help with master development program for site(s), including a complete campus design solution and capital budget. Assist with entitlement and permitting needs for each assigned site project(s) Assist with scopes of work for design, construction, commissioning services & participate in procurement and project cost estimates Evaluate and level pricing proposals for design, construction, and commissioning services Work closely with strategic procurement team on equipment procurement and delivery process Ensure appropriate submittals are coordinated with site stakeholders Assist with monitoring project budget / cost-to-date against overall project budget. Review project schedules and manage teams to on-time completion Review change order requests from contractors and negotiate pricing Assist with establishing site construction security procedures in conjunction with site security team Establish and maintain relationships serving as liaison with key QTS stakeholders Represent QTS Interests in OAC meetings Create & build relationships that enhance QTS’s ability to be a leader in creating the World’s Most Valuable Data Center Real Estate Aid in due diligence efforts on an as-needed basis by participating with real estate efforts on potential or new land banks and properties, including: Evaluate opportunities to design & build new data centers by working with key stakeholders: Corporate Real Estate, Connectivity, Power & Construction teams. Assist with establishing and monitoring entitlement and permit processes for individual projects as needed Work with the internal development team to enhance project management processes and protocols What You Will Need to be Successful (basic qualifications): Bachelor’s degree in Engineering or Construction Management field or equivalent professional experience Experience with Microsoft Office suite, specifically PowerPoint for use in communicating program updates to executive level, and Excel to create and maintain site program & individual project budgets Excellent interpersonal skills with the ability to interface with all levels of the organization Must be a capable, proven team player that both fosters and operates well within internal and external team environments. Able to solve problems at a tactical and functional level Strong Verbal and Written Communication Skills Ability to manage multiple projects simultaneously Other Key Skills: One or more years of professional experience in commercial construction practices and procedures, including management of Lump Sum, Construction Management @ Risk, and Design Build project delivery methods from conceptual development through procurement to close out Documented experience using AutoCAD, BlueBeam, P6, and CxAlloy Experience or exposure in mission critical data center facilities Experience with management of MEP trades Experience managing document control for active data center build sites The Perks (and these are just a few!): Q-Rest Sabbatical Employee Stock Purchase Plan QTS scholarship for dependents Eagle Club Award Trip Eligibility Paid Volunteer and Floating days Tuition Assistance, Parental Leave and Military Leave Assistance We conform to all the laws, statutes, and regulations concerning equal employment opportunities and affirmative action. We strongly encourage women, minorities, individuals with disabilities and veterans to apply to all of our job openings. We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, gender identity, or national origin, age, disability status, Genetic Information & Testing, Family & Medical Leave, protected veteran status, or any other characteristic protected by law. We prohibit retaliation against individuals who bring forth any complaint, orally or in writing, to the employer or the government, or against any individuals who assist or participate in the investigation of any complaint or discrimination claim. The ""Know Your Rights"" Poster is included here: Know Your Rights (English) Know Your Rights (Spanish) The pay transparency policy is available here: Pay Transparency Nondiscrimination Poster-Formatted QTS is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please send an e-mail to talentacquisition@qtsdatacenters.com and let us know the nature of your request and your contact information. It’s exhilarating to find yourself at a pivotal moment in history— and even more so to be leading the way. At QTS Data Centers, we are proud to stand at the forefront of today’s dynamic digital transformation. Our world-class data centers empower our customers’ most strategic growth initiatives, positioning us as a global leader in digital infrastructure. As AI and cloud technologies fuel the demand for increased speed, capacity, and innovation, QTS has emerged as the global digital infrastructure leader. We are committed to connecting the globe for good. Driven by purpose and a spirit of innovation, we design, build, and operate some of the most advanced data centers worldwide. In addition to our cutting-edge technology, we are dedicated to sustainability, incorporating renewable energy solutions to minimize our environmental footprint and drive meaningful impact. As a proud portfolio company of Blackstone, QTS is uniquely positioned to achieve ambitious growth and innovation goals. At QTS, we are Powered by People. Our team members are the cornerstone of our culture, innovation, and growth. They are mission-driven, resourceful, and committed to making a positive impact in the communities where we live and work. Together, we’re achieving remarkable things and shaping the future of digital infrastructure. And we’d like to invite you to join us. In addition to a variety of benefit packages, QTS goes above and beyond for our employees: Roth and Traditional 401(k) matching contributions with immediate vesting Every employee is bonus or commission eligible Generous PTO, Paid Volunteer Days Plus Floating Holidays Stock Purchase Plan (SPP) 11 paid Holidays Annually/Holiday compensation when worked Pet and Legal Insurance Q-Rest Sabbatical Program Q-Anniversary Service Award Program Parental Leave for primary and secondary caregivers Military Benefits Package QTS Charitable Matching Gift Program QTS Scholarship for Employee Dependents QTS Crisis Fund Wellness Program Tuition Reimbursement Program"
2025-12-12T00:00:00,"Data Engineer I, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $109,300.00 - $180,200.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data across the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape by designing, building, and deploying data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning, and business intelligence initiatives. You will work closely with Data Science and Decision Science teams to build, test, and maintain data pipelines and model workflows that support both analytical research and production use cases in our Databricks/AWS/Snowflake environment. In addition to your strong analytical mind, you will bring an inquisitive attitude and the ability to translate the stories found in data into actionable insights while contributing to technical discussions and process improvements. Applicants must be authorized to work for ANY employer in the U.S. The company does not sponsor/support H-1B petitions, TN, or Forms I-983/STEM OPT, for this role. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions. Design data solutions. Analyze sources to determine value and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Collaborate within and across teams to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate. Test data movement, transformation code, and data components. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent. Six years of related experience. Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions. Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on. Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems. Strong verbal and written communication skills with the ability to interact with team members and business partners. Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Four years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,"Senior Data Engineer, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $139,400.00 - $230,000.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions. Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies. Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate. Collaborate across team to support delivery and educate end users on complex data products/analytic environment. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent Ten years of related experience Primary Job Requirements: Architect and design scalable, secure data solutions using AWS, Databricks, and Ab Initio. Lead technical direction for data engineering initiatives across cloud and on-premises infrastructure. Hands-on development: build ETL pipelines, optimize Spark jobs, and create Ab Initio graphs. Troubleshoot production issues and provide technical guidance to junior engineers. Conduct mentoring sessions and offer technical guidance to the 20-person admin team. Collaborate with DBA teams, business analysts, and QA teams to ensure data governance and quality. Manage infrastructure deployment and optimize cloud resources. Lead technical design reviews and architecture discussions. Implement data integration solutions and ensure compliance with data protection regulations. Establish and enforce coding standards, best practices, and data governance policies. Technical Skills: AbInitio: Expert proficiency with GDE, Co>Operating System, EME, BRE, Express>It, metaprogramming (PDL) Programming: Python, PySpark, SQL Cloud: AWS architecture and services Databricks: Workspace management, cluster configuration, Delta Lake, Unity Catalog Data Warehousing: Strong understanding of data modeling, dimensional modeling (star/snowflake schemas) ETL/ELT: End-to-end ETL development lifecycle Version Control: Git, CI/CD pipelines Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices. Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems. Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers. Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize. Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas. Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Five years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,Data Flow Engineer,Scientific Research Corporation,"Description
The Data Flow Engineer will be a member of a Cryptologic Carry-On Program (CCOP) and Ship’s Signals Exploitation Equipment (SSEE) Systems Engineering team primarily responsible for ensuring the processing and distribution of data to and from intelligence community networks. The ideal candidate will have a history of direct involvement with successful NiFi data flow engineering and resolving Navy hardware and software functionality problems by providing a high degree of timely customer service and technical expertise in support of the US Navy information warfare community.
Installing, configuring, integrating, and maintaining NiFi servers and processors into new or existing system architectures
Verifying and maintaining all NiFi processors and flows to and from deployed (and test) systems, from the field system through customer back-end repositories
Assisting end users with the operational readiness and configuration of deployed systems for optimal data flow to satisfy customer requirements
Designing and developing NiFi processors and flows for deployed systems, containing multiple subsystems and requiring integration with external networks
Implementing expression language in NiFi processors in response to emerging customer requirements
Exhibiting developed verbal and written communication skills and the ability to express concepts and ideas in a clear and concise manner; employing technical writing techniques
Performing as a team player, dedicated to the endeavors of the mission, the customer, and the team itself
Being a self-starter who is accountable and requires minimal direction and supervision; capable of multitasking and working several complex and diverse tasks with simultaneous or near simultaneous deadlines
#LI-LL1
Requirements
Must possess an active TS/SCI clearance and be able to obtain a CI Polygraph
Requires a bachelor’s degree in related technical field or equivalent work experience
Intermediate Linux Command Line Interface (CLI) experience
1-3 years of Apache Niagara Files (NiFi) experience (negotiable with other qualifications)
Strong background in using and troubleshooting Software Defined Radio (SDR) systems
Fundamental knowledge of wireless protocols in common use
Experience providing technical support to customers over Internet Relay Chat (IRC) or similar applications
Familiarity with back-end databases and repositories
Must be willing to travel up to 10% of the year
Must currently be DoD 8570-compliant with the equivalent of an IAT II certification or have the ability to do so within 6 months of employment
Desired Skills
Current Linux+/LPIC 1 and/or Network+ certification
Familiarity with Regular Expression (REGEX), Cisco Networking, and Amazon Web Services (AWS)
Expert-level SDR knowledge and experience
Experience with strategic-level intelligence processes
Basic computer programing experience (i.e. Python, JavaScript, bash)
Prior Navy CTR/CTM/CTN with shipborne, expeditionary, or other comparable experience 
Clearance Information
SRC IS A CONTRACTOR FOR THE U.S. GOVERNMENT. THIS POSITION WILL REQUIRE U.S. CITIZENSHIP AS WELL AS A U.S. GOVERNMENT SECURITY CLEARANCE AT THE TOP SECRET / SCI LEVEL with CI POLY ELIGIBILITY
Travel Requirements
up to 10% travel may be required
About Us
Scientific Research Corporation is an advanced information technology and engineering company that provides innovative products and services to government and private industry, as well as independent institutions. At the core of our capabilities is a seasoned team of highly skilled engineers and scientists with multidisciplinary backgrounds. This team is challenged daily to provide cutting edge technology solutions to our clients.
SRC offers a generous benefit package, including medical, dental, and vision plans, 401(k) with a company match, life insurance, vacation and sick paid time off accruals starting at 10 days of vacation and 5 days of sick leave annually, 11 paid holidays, tuition reimbursement, and a work environment that encourages excellence and more. For positions requiring a security clearance, selected applicants will be subject to a government security investigation and must meet eligibility requirements for access to classified information.
EEO
Scientific Research Corporation is an equal opportunity employer that does not discriminate in employment.
All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other protected characteristic under federal, state or local law.
Scientific Research Corporation endeavors to make www.scires.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact jobs@scires.com for assistance. This contact information is for accommodation requests only and cannot be used to inquire about the status of applications."
2025-12-12T00:00:00,"Research Data Engineer II, CHeT Analytics",University of Rochester,"As a community, the University of Rochester is defined by a deep commitment to Meliora - Ever Better. Embedded in that ideal are the values we share: equity, leadership, integrity, openness, respect, and accountability. Together, we will set the highest standards for how we treat each other to ensure our community is welcoming to all and is a place where all can thrive. Job Location (Full Address): 265 Crittenden Blvd, Rochester, New York, United States of America, 14642 Opening: Worker Subtype: Regular Time Type: Full time Scheduled Weekly Hours: 40 Department: 400980 Neuro-Ctr Health & Tech/Admin Work Shift: UR - Day (United States of America) Range: UR URG 113 Compensation Range: $77,216.00 - $115,824.00 The referenced pay range represents the minimum and maximum compensation for this job. Individual annual salaries/hourly rates will be set within the job's compensation range, and will be determined by considering factors including, but not limited to, market data, education, experience, qualifications, expertise of the individual, and internal equity considerations. Responsibilities: GENERAL PURPOSE Participates in the design, implementation and maintenance of analytical and data science-based software and data pipelines to support scientific workflows. Focuses on developing and supporting data collection frameworks that integrate structured and unstructured data from multiple sources and systems to support specific research study teams. Supports the development and maintenance of infrastructure systems (e.g., data warehouses, data lakes), including data access Application Programming Interface(s) (APIs). Works in partnership with team members to provide robust, scalable software solutions to the research enterprise. ESSENTIAL FUNCTIONS Builds, maintains and evolves general Extract, Transform and Load (ETL) data pipelines and overall data architecture to accommodate a growing amount of data from a variety of large research data sources. Works with research team members to convert business and technical requirements into professional software solutions. Ensures timely completion of tasks while managing multiple assignments, project timelines and business user expectations. Designs and implements custom research project-specific data workflow solutions for data collection, management, reporting and analytics. Contributes to the scientific research. Adheres to defined application development life-cycle practices, including but not limited to, requirements gathering, writing test plans, source code management, peer code review and quality assurance through unit/system/user acceptance testing. Participates in specification, implementation and execution of testing procedures to ensure quality of deliverables, system and data workflow reliability. Produces and maintains comprehensive technical documentation for all systems under the Engineer's responsibilities. Keeps abreast of current application developments through continuing education, professional reading, online forums, conferences, workshops and professional groups. Other duties as assigned. MINIMUM EDUCATION & EXPERIENCE Bachelor's degree in Data Science, Biomedical Science, Computer Science, Mathematics, Statistics or similar discipline and 2 years of experience in technology and data intensive roles and environments required Or equivalent combination of education and experience Programming experience in Structured Query Language (SQL) and one other applicable language (Java, Python, and/or R) required Experience with Change Management solutions required Experience with Version Control solutions (e.g. Git) required Experience implementing and supporting data management systems in a scientific, research context (e.g. biospecimen software, electronic laboratory notebooks, REDCap) preferred Experience with Linux, container and cloud technologies (e.g. HPC, IaaS and PaaS) preferred KNOWLEDGE, SKILLS AND ABILITIES Understanding of data analytics and statistical methods required Expertise of software engineering best practices such as version control and software release management required Strong analytical and problem-solving skills required Strong organizational skills required Ability to work with others in a matrix management environment required Excellent communication skills for describing progress and challenges to stakeholders required Attention to detail, patience and a positive, customer-centric attitude required Strong technical presentation skills required Demonstrated ability to develop proficiency with unfamiliar toolsets preferred Familiarity with file formats, metadata, and data exchange and storage standards applicable in management of scientific and clinical research required The University of Rochester is committed to fostering, cultivating, and preserving an inclusive and welcoming culture to advance the University’s Mission to Learn, Discover, Heal, Create – and Make the World Ever Better. In support of our values and those of our society, the University is committed to not discriminating on the basis of age, color, disability, ethnicity, gender identity or expression, genetic information, marital status, military/veteran status, national origin, race, religion, creed, sex, sexual orientation, citizenship status, or any other characteristic protected by federal, state, or local law (Protected Characteristics). This commitment extends to non-discrimination in the administration of our policies, admissions, employment, access, and recruitment of candidates, for all persons consistent with our values and based on applicable law. Notice: If you are a Current Employee, please log into myURHR to search for and apply to jobs using the Jobs Hub. Your application, if submitted using this portal, cannot be moved forward. Learn. Discover. Heal. Create. Located in western New York, Rochester is our namesake and our home. One of the world’s leading research universities, Rochester has a long tradition of breaking boundaries—always pushing and questioning, learning and unlearning. We transform ideas into enterprises that create value and make the world ever better. If you’re looking for a career in higher education or health care, the University of Rochester may offer the perfect opportunity for your background and goals. At the University of Rochester, we are committed to fostering, cultivating, and preserving an inclusive and welcoming culture and are united by a strong commitment to be ever better—Meliora. It is an ideal that informs our shared mission to ensure all members of our community feel safe, respected, included, and valued."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,Data Engineer II (Onsite),RTX,"Date Posted: 2025-12-12 Country: United States of America Location: PW147: PW OKC Campus 8120 S. Air Depot Blvd , Oklahoma City, OK, 73135 USA Position Role Type: Onsite U.S. Citizen, U.S. Person, or Immigration Status Requirements: U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Security Clearance: None/Not Required Pratt & Whitney is working to once again transform the future of flight—designing, building and servicing engines unlike any the world has ever seen. And because transformation begins from within, we’re seeking the people to drive it. So, calling all curious. Come ready to explore and you’ll find a place where your talent takes flight—beyond the borders of title, a country or your comfort zone. Bring your passion and commitment and we’ll welcome you into a tight-knit team that takes our mission personally. Channel your drive to make a difference into shaping an organization and an industry that’s evolving fast to the future. At Pratt & Whitney, the difference you make is on display every day. Just look up. Are you ready to go beyond? You will be an integral part of Pratt & Whitney’s Sustainment Operational Excellence Data Engineering & Analytics team. This team supports the global aftermarket maintenance and overhaul of engines for the F117, F119, and F135 programs. We are looking for a Data Engineer II to advance the digital and data capability of the Military Engines Global Depot Network organization. You will be working on exciting new technologies like cloud and open-source tools among others, and be responsible for cleaning, standardizing, transforming, and configuring data products within our emerging data mesh. What You Will Do: Create and maintain scripts written in Spark SQL or Pyspark in Databricks Notebooks. Also, work with SMEs to understand complex datasets for next generation data products and data visualizations to create data mesh tables. Develop scalable and sustainable data product transformations that curate, clean and store data efficiently; perform statistical analysis to quantify completeness and validity; perform bug fixes and apply enhancements to the models when the need arises. Ensure high performance and reliability of data transformation processes and pipelines. Collaborate cross-functionally to gather insights, refine requirements, and ensure alignment between product goals and team efforts. Document data processes, logic, and data sources to ensure transparency and knowledge sharing as well as support the overall team with any ad-hoc data related tasks. Work to convert our existing data visualizations in Power BI to use Databricks instead of Azure Synapse. Keep up to date with technologies and use advanced cloud data warehouse and data transformation techniques to build innovative solutions. Qualifications You Must Have: A degree in Science, Technology, Engineering or Mathematics (STEM) with 2+ years of experience in the use of SQL and/or Python to transform, clean, and integrate data from a variety of source pipelines. U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Qualifications We Prefer: Experience with transformation tools such as dbt, Databricks pipelines, or relevant tools such as SSIS, ADF, or Matillion. Demonstrated experience with Git/GitHub; experience working in cloud data warehouses like Databricks. Familiarity with agile methodologies and Kanban boards. Self-motivated, team player with good communication skills. Ability to focus on results and successfully manage multiple tasks/projects. An astute individual, with the ability to build strong cross-functional relationships; excited at the prospect of developing and implementing new data products that add organizational value & improve decision making capabilities. Business experience with Aerospace or other heavy manufacturing industry. An understanding of ER Diagrams for data modeling. Demonstrated understanding of data mesh design principles and data engineering best practices. Learn More & Apply Now! What is my role type? In addition to transforming the future of flight, we are also transforming how and where we work. We’ve introduced role types to help you understand how you will operate in our blended work environment. This role is: Onsite: Employees who are working in Onsite roles will work primarily onsite. This includes all production and maintenance workers, as they are essential to the development of our engines. Candidates will learn more about role type and current site status throughout the recruiting process. For onsite and hybrid roles, commuting to and from the assigned site is the employee’s personal responsibility. As part of our commitment to maintaining a secure hiring process, candidates may be asked to attend select steps of the interview process in-person at one of our office locations, regardless of whether the role is designated as on-site, hybrid or remote. The salary range for this role is 66,000 USD - 130,000 USD. The salary range provided is a good faith estimate representative of all experience levels. RTX considers several factors when extending an offer, including but not limited to, the role, function and associated responsibilities, a candidate’s work experience, location, education/training, and key skills. Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement. Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company’s performance. This role is a U.S.-based role. If the successful candidate resides in a U.S. territory, the appropriate pay structure and benefits will apply. RTX anticipates the application window closing approximately 40 days from the date the notice was posted. However, factors such as candidate flow and business necessity may require RTX to shorten or extend the application window. RTX is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or veteran status, or any other applicable state or federal protected class. RTX provides affirmative action in employment for qualified Individuals with a Disability and Protected Veterans in compliance with Section 503 of the Rehabilitation Act and the Vietnam Era Veterans’ Readjustment Assistance Act. Privacy Policy and Terms: Click on this link to read the Policy and Terms RTX is an aerospace and defense company that provides advanced systems and services for commercial, military and government customers worldwide. It comprises three industry-leading businesses – Collins Aerospace, Pratt & Whitney, and Raytheon. Its 195,000 employees enable the company to operate at the edge of known science as they imagine and deliver solutions that push the boundaries in quantum physics, electric propulsion, directed energy, hypersonics, avionics and cybersecurity. The company, formed in 2020 through the combination of Raytheon Company and the United Technologies Corporation aerospace businesses, is headquartered in Arlington, Virginia."
2025-12-12T00:00:00,"Senior Engineer, BAW R&D Trimming and Data Infrastructure",Qorvo,"
                Qorvo (Nasdaq: QRVO) supplies innovative semiconductor solutions that make a better world possible. We combine product and technology leadership, systems-level expertise and global manufacturing scale to quickly solve our customers' most complex technical challenges. Qorvo serves multiple high-growth segments of large global markets, including consumer electronics, smart home/IoT, automotive, EVs, battery-powered appliances, network infrastructure, healthcare and aerospace/defense. Visit www.qorvo.com to learn how our innovative team is helping connect, protect and power our planet.

 
Summary:
 Qorvo’s BAW R&D Data Infrastructure team is seeking a talented engineer for semiconductor data infrastructure, frequency trimming and process automation. The candidate chosen for this role will develop data infrastructure and software tools to support efficient development and production of new Bulk Acoustic Wave (BAW) filter technologies. The candidate will use MATLAB, data analysis tools (SpotFire), databases and other software tools for process control improvements, faster design cycles, and general automation to efficiently develop and produce new technologies.
 
Key Roles and responsibilities:

Research, implement, deploy, and maintain internal software applications used by Manufacturing and R&D Engineering teams to process and trim BAW filters wafers.
Work closely with Process Integration and Process Engineering teams to understand new BAW technology needs to define requirements and implement.
Provide comprehensive support to internal customers: resolve outstanding issues for R&D engineers, designers, and production at Qorvo’s fabrication facility.
Own critical data infrastructure projects and successfully deliver results in a timely manner

 
Technical Knowledge/Skills/Abilities Required:

Excellent MATLAB or Python programming capabilities
Knowledge of semiconductor processing
Practical knowledge of software development and object-oriented programming
Excellent debugging and problem-solving skills


Strong data analysis and mathematical skills


Experience with version control utilizing Git and GitLab
Good knowledge of SQL database (Oracle is a plus)
Experience in the full life cycle of the software design process including requirement analysis, design, prototyping, coding, documentation, implementation, and maintenance

 
Personal Skills:

Self-motivated, independent, proactive, detail oriented, and responsible team-player
Excellent analytical skills
Comfortable working in a dynamic and fast paced environment
Passion for innovation and emerging technologies
Excellent communication and interpersonal skills
Able to handle multiple priorities
Proficient in English

 
Desired experiences:

Experience with software development for semiconductor processing 
Expertise in electromagnetics, physics, or material science
Expertise in Oracle PL/SQL databases
Experience with data analysis tools such as Spotfire or similar application
Experience with GitLab workflows and pipeline automation 
Experience with Visual Studio Code and GitHub Copilot
Experience with unit testing in past development projects

 
Qualifications:
Education & Experience:

BS or MS in Computer Science, Electrical Engineering, Physics or Material Science
5+ years of code development experience.(or if Master's degree 2+ years experience)

 
This position is not eligible for visa sponsorship by the Company.
 
#LI-KR1
 MAKE A DIFFERENCE AT QORVO   

 We are Qorvo. We do more than create innovative RF and Power solutions for the mobile, defense and infrastructure markets – we are a place to innovate and shape the future of wireless communications. It starts with our employees. As a unified global team, we bring a commitment to excellence, growth and a passion for creating what's next. Explore the possibilities with us.

We are an Equal Employment Opportunity (EEO) employer and welcome all qualified applicants. Applicants will receive fair and impartial consideration without regard to any characteristics protected by applicable law, including race, color, religion, sex (as defined by law), national origin, age, military or veteran status, genetic information, or disability.  
                
    "
2025-12-12T18:28:05.616,Sr Staff Engineer Software (Data Plane Applications),Palo Alto Networks,"Company Description
Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
Who We Are
We believe collaboration thrives in person. That’s why most of our teams work from the office full time, with flexibility when it’s needed. This model supports real-time problem-solving, stronger relationships, and the kind of precision that drives great outcomes.
Job Description
Your Career
Prisma Access™ (formally GlobalProtect Cloud Service) provides protection straight from the cloud to make access to the cloud secure. It combines the connectivity and security you need and delivers it everywhere you need it. Using cutting-edge public and private cloud technologies extending the next-generation security protection to all cloud services, customers on-premise remote networks and mobile users.
We are seeking an experienced Software Engineer to design, develop and deliver next-generation technologies within our Prisma Access team. We want passionate engineers who love to code and build great products. Engineers who bring new ideas in all facets of software development. We are looking for leaders who take ownership of their areas of focus and who are driven to solve problems at every level. Collaboration and teamwork are at the foundation of our culture and we need engineers who can communicate at a high level and work well with others towards achieving a common goal.
Your Impact
Design, develop and implement highly scalable software features and infrastructure on our next-generation security platform ready for cloud native deployment from inception to completion
Work with different development and quality assurance groups to achieve the best quality - You accomplish this by being hands-on, creating tools, processes, and systems that produce transparency, alignment, and direction
Profile, optimize and tune systems software (management/control/dataplane) for efficient cloud operation
Work with DevOps and the Technical Support teams to troubleshoot customer issues
Work with other software development team to apply PanOS features on Prisma Access
Interview, mentor and coach new team members 
Qualifications
Your Experience 
5+ years of experience in developing and troubleshooting dataplane applications
Required hands-on programming experience in Python and Go
Nice to have C/C++ Programming
Strong Data structures/Algorithms
Strong analytical skills, problem solving and debugging skills
Nice to have experience with LLMs and GenAI applications. Or Machine learning/Data science with experience in ETL, curating datasets, running evals. 
Experience with building applications in the cloud
In-depth understanding of Operating System principles and OS like Linux/Unix
In-depth understanding of networking concepts and TCP/IP stack, TLS
Exposure to building Microservices 
Enjoys working with many different teams with strong collaboration and communication skills
Solid foundation in design, data structures, and algorithms, and strong analytical and debugging skills
Education : M.S./B.S. degree in Computer Science or equivalent military experience required
Additional Information
The Team
Our engineering team is at the core of our products – connected directly to the mission of preventing cyberattacks. We are constantly innovating – challenging the way we, and the industry, think about cybersecurity. Our engineers don’t shy away from building products to solve problems no one has pursued before.
We define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment.
Compensation Disclosure
The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $170,000 - $190,000/YR. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.
Our Commitment

We’re problem solvers that take risks and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at [email protected].
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
Is role eligible for Immigration Sponsorship?: Yes"
2025-12-12T18:20:27,Data Engineer,Real Chemistry,"At Real Chemistry, making the world a healthier place isn’t just an aspiration—it’s our everyday reality. Our drive to transform healthcare is informed by our blend of deep scientific expertise, human-centred creativity, and AI-driven insights, fostering a unique environment where innovation thrives and our people are impact-obsessed. As a global agency, we provide a full suite of services across healthcare communications and marketing to our clients, including top players in the pharmaceutical and biotech industries.
Our #LifeatRealChem culture is rooted in our people—we believe we are best together and are committed to excellence for both our clients and colleagues. Whether you're a seasoned professional or just starting your career, if you share our passion for healthcare and connection, we invite you to explore our opportunities.
Discover your purpose. Embrace innovation. Experience #LifeatRealChem.
Job Summary 
We’re looking for a hands-on Data Engineer to help build and maintain the data infrastructure that powers our AI products and solutions. This role sits within our AI organization and focuses on designing, developing, and optimizing scalable data pipelines, data models, and cloud-based data systems. You’ll collaborate closely with data scientists, ML engineers, product teams, and other technical partners to ensure high-quality, reliable, and well-structured data is available across the organization. 
Key Responsibilities 
Data Pipeline Development 
Build, optimize, and maintain scalable ETL/ELT pipelines for structured and unstructured data. 
Implement reliable, fault-tolerant ingestion and transformation workflows. 
Automate routine data processes where possible. 
Data Architecture & Modeling 
Develop well-structured data models that support analytics, ML use cases, and downstream applications. 
Support the design and enhancement of AI-related data architecture across cloud environments. 
Data Quality & Governance 
Implement automated data validation, monitoring, and alerting. 
Ensure high data accuracy, completeness, and integrity across ingestion and transformation layers. 
Cross-Functional Collaboration 
Partner with data scientists, ML engineers, product managers, and IT teams to understand data requirements and translate them into technical solutions. 
Troubleshoot issues and support stakeholders with data access and pipeline improvements. 
Cloud & Infrastructure 
Work with modern cloud platforms (AWS, Azure, or GCP) and associated data storage, compute, and orchestration services. 
Support deployment, scaling, and operational health of data systems. 
Innovation & Continuous Improvement 
Stay current with emerging data engineering tools and best practices. 
Propose opportunities to improve performance, efficiency, or reliability within the data stack. 
Qualifications & Skills 
Education & Experience 
Bachelor’s degree in Computer Science, Data Engineering, or related technical field (or equivalent experience). 
3–7 years of hands-on experience in data engineering or data pipeline development. 
Technical Skills 
Strong SQL skills and proficiency in Python or Scala. 
Experience with data warehousing technologies such as Snowflake, BigQuery, Redshift, or Databricks. 
Hands-on experience with cloud services (AWS, Azure, or GCP). 
Knowledge of data modeling, schema design, and ETL/ELT principles. 
Familiarity with distributed computing frameworks such as Spark or Flink. 
Experience with workflow orchestration tools like Airflow, Prefect, or Dagster is a plus. 
Soft Skills 
Strong problem-solving skills and attention to detail. 
Ability to communicate technical concepts clearly to peers and cross-functional partners. 
Comfortable working in a fast-moving, collaborative environment. 
Preferred Qualifications 
Experience with streaming data tools such as Kafka or Kinesis. 
Experience building CI/CD pipelines for data workflows. 
Experience in healthcare, biotech, life sciences, or commercial/marketing data environments. 
Experience in agency or consulting settings. 
Posting Salary
$140,000—$175,000 USD
Real Chemistry is proud to be Great Place to Work® certified; check out what our people shared about our culture and workplace on our Great Places to Work Profile here.
We believe we can do our best when feeling our best, which is why we’ve put together a benefits program designed to give you the support you and your family need at every stage of life. Real Chemistry offers a comprehensive benefit program and perks, tailored to your region. Globally, this includes offices in our key markets with free snacks to keep you running all day long, generous holiday and paid time off, options for private medical, dental, and vison plans, and support in saving for the future. Other perks include mental wellness coaching and support and access to more than 13,000 online classes with LinkedIn Learning. Learn more about our great benefits and perks and search specific offerings in your region at: www.realchemistrybenefits.com.
Working with Real HART: Since the pandemic, we have adapted to how our people told us they want to work. We have office locations in cities in the US, UK, and Europe with many employees and clients that serve as hubs where and when they need us. For employees who are within an hour of one of our offices, we expect attendance in the office two days per week, either at a Real Chemistry office or onsite with clients. We are also actively opening new office locations, so if one opens near you, our Real HART policy will apply. We are not looking for attendance for the sake of attendance but believe that the opportunity to coordinate in-office team meetings, 1:1 meetings with managers, taking advantage of on-site learning, and connecting with client partners is a critical to delivering on our purpose of making healthcare what it should be. Outside of these offices, we have regions, where people work remotely but come together quarterly for collaboration, culture and learning opportunities. We call this our Real Hybrid and Regional Teams (Real HART) approach. Real Chemistry believes we are best together – and our workplace strategy fosters connection and collaboration in person – but also supports flexibility for our people.
Real Chemistry is an Equal Opportunity employer. We continually strive to build and sustain an inclusive and equitable work environment where our employees feel empowered to leverage all they bring from their personal lived experience and professional expertise, to make our team the best in the industry. We encourage motivated and qualified applicants to apply without regard to race, color, religion, sex (including pregnancy), sexual orientation, gender identity/expression, ethnic or national origin, age, physical or mental disability, genetic information, marital information, or any other characteristic protected by federal, state, or local employment discrimination laws where Real Chemistry operates. Should you require accommodations throughout the interview process please let your recruiter know.
*Notice: Real Chemistry and its affiliates' names are being misused by scammers through messaging services, fake websites, and apps. Do not share personal or financial information or make payments to any unverified sources claiming to be connected to Real Chemistry. We are working to stop these unauthorized activities and protect our community. Read more here."
2025-12-12T17:29:23,Senior Python Data Engineer - (Remote)  ,KBRA,"Position Title: Senior Python Data Engineer - (Remote) 
Entity: KBRA Holdings LLC
Employment Type: Full-Time
Location: Remote (Remote only in CA, CO, DC, FL, IL, MD, NJ, MA, NY, PA, SC, TX, VA)
Summary/Overview:
KBRA (KBRA Holdings, LLC) is seeking an engaged and proactive Senior Python Data Engineer to work on our financial analytical system. We want someone who loves solving difficult problems, digs deeply to understand the domain in which they’re working, and excels at creating high-quality software in a collaborative environment.
About the Team:
We believe that small, empowered teams can do amazing things. Across the engineering organization, we work hard to make the best systems for our customers using modern engineering practices. We are intentional in our investments in time and effort around creating a safe and successful workplace for our team members. We understand software engineering goes beyond the 1’s and 0’s and prioritize concrete value for our customers.
About the Job:

This role involves joining an existing team with a well-defined product vision. This team operates collaboratively, and there is an expectation to get involved in all aspects of design, delivery, and support of our systems.

This role emphasizes collaboration with our technical and non-technical counterparts to learn our domain and its unique challenges, while delivering value to our customers. It also requires collaboration with our other engineering, design, product, and platform teams to develop, build, run, and support the system.
About You:

You will be successful in this role if you:
Develop, test, and maintain scalable Python applications.
Collaborate with product managers, designers, and other engineers to deliver high-quality software.
Write clean, efficient, and reusable code following best practices.
Participate in code reviews to ensure code quality and share knowledge with the team.
Troubleshoot and debug issues in a timely manner.
Contribute to the design and architecture of new features and systems.
Have a sense of ownership and craftsmanship around the code base and your work.
Enjoy helping other developers grow and learn new technologies.
Display a strong track record of mentorship with engineers at various levels.
Are mindful of application security and performance.
Take pride in learning, and want opportunities to learn throughout your day-to-day.
Possess a pragmatic mindset. 
Familiarity with Generative AI tools such as ChatGPT for research, data insights, and general productivity is a plus.
Must have skills:
3–6 years of professional software engineering experience, with a strong portfolio of full stack development work.
Proficiency in Python, including experience with web frameworks such as Flask.
Cloud experience, particularly with AWS (Amazon Web Services).
Experience integrating frontend applications with RESTful APIs and backend services.
Relational and non-relational databases (SQL Server, Snowflake and MongoDB).
Debugging, issue resolution, and troubleshooting.
Nice to have skills:
Familiarity with UX design tools (Figma) and solid understanding of the design-engineering hand-off process
Containerized development and deployment (i.e. Docker, Docker swarm, Kubernetes)
Infrastructure as Code (Terraform)
Familiarity with deployment pipelines, CICD tools.
Exposure to financial systems or credit modeling is strongly preferred.
Salary Range:
The anticipated annual base salary range for this full-time position is $130,000 - $160,000. Offer amounts are determined by factors such as experience, skills, geography, and other job-related factors.
Benefits:
Competitive benefits and paid time off
Paid family and disability leave
401(k) plan, including employer match (100% vested)
Educational and professional development financial assistance
Employee referral bonus program
About Us:
KBRA is a full-service credit rating agency registered in the U.S., the EU and the UK, and is designated to provide structured finance ratings in Canada. KBRA’s ratings can be used by investors for regulatory capital purposes in multiple jurisdictions.
More Info:
KBRA encourages applications from all qualified individuals without regard to race, color, religion, gender, sexual orientation, gender identity or expression, age, national origin, marital status, citizenship, disability, and veteran status or any other basis prohibited by federal, state or local law.
#LI-KS1
#REMOTE"
2025-12-12T17:19:54,Data Platform Engineer,Dragonfli Group,"Dragonfli Group is a cybersecurity and IT consulting firm providing services to federal agencies and Fortune 100 enterprises. Headquartered in Washington, DC, Dragonfli supports clients in securing mission-critical systems across on-site, hybrid, and fully remote environments.

This contract Data Platform Engineer role supports a large federal agency in protecting security data platforms within a large-scale IT environment. The engineer will manage security data platforms such as Splunk and data lakes, ensuring effective data flows, integrations, and platform support. Key technologies include Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS. The role requires seasoned IT security expertise, hands-on technical skills, and strong communication and planning abilities. It's a high-impact opportunity to shape security analytics capabilities within a major federal agency.

This is a multi-year contract position involving a large US federal agency. Candidates with previous federal contracting experience are preferred. U.S. Citizenship or Permanent Residency required. If hired, all work related to this role must be performed within the continental U.S.

Responsibilities:
Manage security data platforms, such as Splunk and data lakes.
Ensure effective data flows, integrations, and platform support.
Support event ingestion, platform maintenance, and technical add-ons.
Troubleshoot to support operational and compliance reporting.
Optimize data use for security monitoring, incident response, and threat analysis.
Collaborate across teams to enhance security analytics capabilities.
Configure and maintain various event ingestion methods.
Create and maintain custom TAs for data parsing into Splunk CIM format.
Monitor and perform routine maintenance of data systems.
Drive process improvements and attention to detail.

Requirements
Four (4)+ years of experience supporting enterprise data platforms.
BS/BA in a cyber-related field or equivalent experience/certifications.
Experience with installing, updating, and maintaining ELM and SIEM.
Proficiency with Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS.
Experience configuring and maintaining event ingestion methods.
Ability to create and maintain custom TAs for Splunk.
Experience in troubleshooting, monitoring, and maintaining data systems.
Familiarity with enterprise security operations.
Strong cross-functional communication skills.

Skill(s)
Hands-on management of security data platforms.
Expertise in data flows and platform integrations.
Proficiency in Splunk and related technologies.
Strong troubleshooting and problem-solving skills.
Ability to optimize security monitoring and incident response.
Excellent cross-functional communication abilities.
Attention to detail and process improvement mindset.
Ability to work collaboratively across teams.
Strong planning and organizational skills.

Benefits
Insurance – health, dental, and vision
Paid Time Off (PTO) and 11 Federal Holidays
401(k) employer match

Travel
null"
2025-12-12T16:50:01,Staff Configuration Data Engineer,Archer,"Archer is an aerospace company based in San Jose, California building an all-electric vertical takeoff and landing aircraft with a mission to advance the benefits of sustainable air mobility. We are designing, manufacturing, and operating an all-electric aircraft that can carry four passengers while producing minimal noise.
Our sights are set high and our problems are hard, and we believe that diversity in the workplace is what makes us smarter, drives better insights, and will ultimately lift us all to success. We are dedicated to cultivating an equitable and inclusive environment that embraces our differences, and supports and celebrates all of our team members.
What you'll do:
As the Configuration Data Engineer, you will combine software development expertise with configuration management practices to safeguard product data integrity, traceability, and compliance. You will design tools, reports, and automations that enable engineering and product teams to make faster, more accurate configuration decisions.
Develop and maintain tools and reports to monitor bills of materials (BOMs), effectivity assignments, and configuration changes
Create automated quality checks to validate workflows and ensure compliance with configuration management standards
Integrate with Teamcenter APIs and background services to access, analyze, and validate engineering data
Build automation scripts to support NX, CATIA, and other CAD-driven workflows (NX Open, CATIA VB, Check-Mate, NX Check-Mate)
Support the definition, maintenance, and auditing of BOM structures, unit effectivity, and date-based effectivity for engineering changes
Develop dashboards and metrics reporting to provide visibility into change requests, change notices, and configuration status accounting
Collaborate with configuration management, engineering, and IT teams to streamline data flow across systems
Investigate data anomalies and provide corrective recommendations to maintain design and change integrity
Partner with project teams to ensure effectivity assignments are properly implemented and reflected in reports
Contribute to the improvement of enterprise configuration management processes through data-driven insights
Serve as a technical resource to CM specialists for reporting, automation, and API usage
What You Need
To be a self starter with a strong desire to learn new technologies
Ability to translate engineering/CM requirements into automated solutions
2+ years of experience developing tools and reports for a Product Lifecycle Management (PLM) tools (e.g., Teamcenter, Windchill, Enovia, 3DX) or equivalent engineering data environments
Experience with relational databases (SQL, PostgreSQL, Oracle) for reporting and automation
Ability to interpret engineering drawings, CAD data, and metadata
Understanding of BOM structures, unit effectivity, and date-based effectivity methods
Familiarity with engineering change processes, including Change Requests (CRs) and Change Notices (CNs)
Experience with scripting or automation in CAD/PLM environments (NX Open, CATIA VB, or similar)
Strong problem-solving skills and ability to analyze complex datasets for process improvements
Effective written communication skills to document procedures and produce clear reports
Ability to work in a collaborative environment across engineering, CM, and IT teams
Bonus Qualifications
Hands-on experience with Siemens Teamcenter APIs or integrations
Experience with Business Intelligence tools such as Power BI, Sigma, or SAP Hana
Experience with ITI CADIQ tools and CAD data validation workflows
Experience with Elysium CAD Translation tools
Familiarity with NX Check-Mate and automations
Familiarity with ASME Y14.5 Dimensioning and Tolerancing
Experience developing Adobe Forms with JavaScript and PDF publishing workflows
Exposure to aerospace, automotive, or other complex product development environments
Knowledge of configuration management standards and compliance practices (CMII, EIA-649, etc.)
This role is ideal for engineers who enjoy bridging software development with product lifecycle control. You will directly impact how engineering data is managed, ensuring accuracy, efficiency, and compliance across the enterprise
Archer is committed to working with and providing reasonable accommodations to job applicants with physical or mental disabilities, and those with sincerely held religious beliefs. Applicants who may require reasonable accommodation for any part of the application or hiring process should provide their name and contact information to Archer’s People Team at people@archer.com. Reasonable accommodations will be determined on a case-by-case basis.
Information collected and processed as part of any job applications you choose to submit is subject to Archer's Candidate Privacy Policy.
Archer is unable to provide work visa sponsorship for this position at the present time.
Archer is proud to be an Equal Opportunity employer committed to diversity and inclusivity in the workplace. All aspects of employment are decided on the basis of merit, qualifications, and business needs. We do not discriminate based upon race, color, religion, sex, sexual orientation, age, national origin, disability status, protected veteran status, gender identity or any other characteristic protected by federal, state or local laws.
Archer Aviation does not engage with external recruiting agencies/individual recruiters with whom it does not have a prior written agreement. Archer reserves the right to make use of any unsolicited resumes that it receives and bears no responsibility for payment of any fees asserted from the use of unsolicited resumes. If you are a recruiting agency or individual recruiter wishing to do business with Archer, please reach out to People@archer.com. All employment processes are managed by the Archer People Team."
2025-12-12T16:14:31,Data Engineer - Integrated Supply Chain,Textron,"Data Engineers build and maintain data systems in support of data analytics and data science activities. The Data Engineer will implement methods to improve data reliability, data quality, and ensure success in data-driven initiatives.
This position within Integrated Supply Chain Analytics is responsible for identifying, developing, and executing solutions that support reliable and efficient extraction of data from source systems and loading of that data into analytic platforms. The Data Engineer will help administer data platforms and consult with data analysts and data scientists on process optimization and data quality improvements.
At Textron Aviation, we are building a community of Data & Analytics professionals with an emphasis on collaboration and cross functional support. You will have the opportunity to work closely with your peers throughout the organization toward a vision of data driven strategy.


JOB RESPONSIBILITIES:
· Gain core business understanding of Textron Aviation and aircraft design, operation, and support
· Query, clean, transform, and stage data (ETL/ELT) across on-prem and cloud environments
· Support data analytics and data science activities by implementing, maintaining, and optimizing production ready data pipelines
· Install and update software to ensure data platform continuity
· Administer a CI/CD compliant code repository during development and update activities
· Research and help implement new technologies to support analytics function
· Interface with other data professionals throughout the organization to embrace cross functional growth in analytics capabilities
· Work to improve data quality by assisting data governance efforts in creating and maintaining data quality standards
· Plan and execute projects according to established milestones and schedules
· Train users in data & analytic tools and processes per best practices and compliance standards
· Contribute to the resolution of service tickets pertaining to data infrastructure
· Serve as an internal consultant to business leaders by advising on system capabilities
EDUCATION/ EXPERIENCE:
· Bachelor’s degree in Computer Science, Software Engineering, Data Science/Analytics, MIS, or other related technical field
· Minimum 2 years relevant technical experience required, focused on data collection, utilization, and analysis.
· Aviation experience preferred
Textron Aviation Inc. must comply with U.S export control laws and regulations. If a position requires access to sensitive information controlled under these laws and regulations, a successful applicant must be eligible to meet any requirements to access controlled information."
2025-12-12T16:07:56,Senior Data Engineer ,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:55,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:54,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T15:01:13.806,"Software Engineer III, Infrastructure, Audience Data Processing",Google,"MINIMUM QUALIFICATIONS:

 * Bachelor’s degree or equivalent practical experience.
   
 * 2 years of experience with software development in C++, SQL, Borg, Flume, or
   1 year of experience with an advanced degree.
 * 2 years of experience with developing large-scale infrastructure, distributed
   systems or networks, or experience with compute technologies, storage or
   hardware architecture.



PREFERRED QUALIFICATIONS:

 * Master's degree or PhD in Computer Science or related technical fields.
   
 * 2 years of experience with data structures and algorithms.
 * Experience with Flume and large scale data processing pipelines.
 * Experience developing accessible technologies.
   


ABOUT THE JOB:

Google's software engineers develop the next-generation technologies that change
how billions of users connect, explore, and interact with information and one
another. Our products need to handle information at massive scale, and extend
well beyond web search. We're looking for engineers who bring fresh ideas from
all areas, including information retrieval, distributed computing, large-scale
system design, networking and data storage, security, artificial intelligence,
natural language processing, UI design and mobile; the list goes on and is
growing every day. As a software engineer, you will work on a specific project
critical to Google’s needs with opportunities to switch teams and projects as
you and our fast-paced business grow and evolve. We need our engineers to be
versatile, display leadership qualities and be enthusiastic to take on new
problems across the full-stack as we continue to push technology forward.

As a Software Engineer on the Audience Data Processing Infrastructure team, you
will innovate and optimize planet-scale data processing flows to support Google
Ads.

While we're an infrastructure team, we operate in a fast-paced environment with
evolving requirements. Our focus is on supporting client data processing needs,
enhancing operational excellence and developer velocity, and significantly
improving resource efficiency.


Google Ads is helping power the open internet with the best technology that
connects and creates value for people, publishers, advertisers, and Google.
We’re made up of multiple teams, building Google’s Advertising products
including search, display, shopping, travel and video advertising, as well as
analytics. Our teams create trusted experiences between people and businesses
with useful ads. We help grow businesses of all sizes from small businesses, to
large brands, to YouTube creators, with effective advertiser tools that deliver
measurable results. We also enable Google to engage with customers at scale.

The US base salary range for this full-time position is $141,000-$202,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Write product or system development code in C++ for infrastructure
   responsible for managing and optimizing processing of planet-scale data
   processing.
 * Investigate data storage and processing use cases, techniques, and
   identifying opportunities for future innovation.
 * Review code developed by other developers and provide feedback to ensure best
   practices (e.g., style guidelines, checking code in, accuracy, testability,
   and efficiency).
 * Contribute to existing documentation or educational content and adapt content
   based on product/program updates and user feedback.
 * Triage product or system issues and debug/track/resolve by analyzing the
   sources of issues and the impact on hardware, network, or service operations
   and quality."
2025-12-12T13:26:27,Cleared On Site Data Engineer (4899),SMX,"SMX is seeking a Senior Data Architect to provide strategic and technical leadership for enterprise data architecture and analytics modernization efforts. This individual will design, optimize, and oversee data solutions that enable advanced analytics, business intelligence, and reporting capabilities across multiple secure environments. This role will focus on designing, developing, optimizing, and maintaining data pipelines and backend data engineering solutions that power critical analytical products used by senior FBI leadership. The ideal candidate brings deep technical expertise in ETL processes, SQL, Python, AWS data services, and enterprise-scale data warehousing, with strong familiarity in BI ecosystems such as MicroStrategy (Strategy), ThoughtSpot, and related tools used within the HR Reports program. The position requires close collaboration with government leads, senior data developers, BI engineers, and cross-functional analytics teams to ensure high reliability, performance, and security of data products supporting mission-critical operations. 
This is a full-time position requiring on-site work five days a week at a client’s office in Washington, D.C. An active Top Secret clearance is mandatory.
Essential Duties and Responsibilities: 
Design, build, and maintain scalable, secure ETL/ELT pipelines supporting HR Reports analytics and dashboard products.
Develop and optimize SQL-based transformations, stored procedures, and data models for high-volume enterprise datasets.
Implement data orchestration workflows using AWS services (e.g., Glue, Lambda, Step Functions, CloudWatch).
Ensure data quality, lineage, and integrity across multiple enterprise data sources.
Support and enhance cloud-based warehouse environments within AWS (e.g., Redshift, S3, IAM).
Collaborate with BI developers to ensure backend data structures meet MicroStrategy/Strategy and ThoughtSpot reporting needs.
Troubleshoot complex data pipeline or performance issues and implement long-term remediation solutions.
Translate government stakeholder requirements into technical specifications for new data sources and pipelines.
Partner with Data Analysts, Data Scientists, and BI Developers to support advanced analytics and ad-hoc data requests.
Apply data governance, security, and compliance best practices in alignment with FBI and SMX standards.
Recommend and implement improvements to automation, data architecture, pipeline reliability, and overall performance.
Maintain documentation for pipelines, logic, data flows, and system dependencies.
Stay current with modern data engineering practices and AWS service enhancements relevant to pipeline automation and warehousing.
Required Skills: 
10+ years of experience in data architecture, data warehousing, or enterprise analytics systems.
Expert-level proficiency in SQL and data modeling
Hands-on experience designing and implementing ETL/ELT frameworks (e.g., Apache Airflow, dbt, AWS Glue, Informatica).
Demonstrated success architecting and optimizing large-scale BI/reporting solutions (MicroStrategy, ThoughtSpot, Power BI, Tableau).
Strong knowledge of AWS data ecosystem (Redshift, Athena, S3, Glue, Lambda) or similar cloud environments.
Experience defining and enforcing data governance, quality, and security standards.
Ability to design and document end-to-end data flows and integrations between transactional and analytical systems.
Excellent communication, analytical, and problem-solving skills.
Desired Skills/Experience:
Bachelor’s or Master’s degree in Computer Science, Information Systems, Data Engineering, or related technical field.
10+ years of experience in data engineering, backend data development, or enterprise-scale ETL development.
Experience supporting federal government IT systems or analytics programs.
Familiarity with Agile methodologies and Jira-based workload management.
Experience supporting or modernizing enterprise BI ecosystems.
**This position requires five days a week on site at customer location in Washington DC.
Application deadline 1-16-2026
#LI-SA
#cjpost
The SMX salary determination process takes into account a number of factors, including but not limited to, geographic location, Federal Government contract labor categories, relevant prior work experience, specific skills, education and certifications. At SMX, one of our Core Values is to Invest in Our People so we offer a competitive mix of compensation, learning & development opportunities, and benefits. Some key components of our robust benefits include health insurance, paid leave, and retirement.
The proposed salary for this position is:
$114,600—$192,500 USD
At SMX®, we are a team of technical and domain experts dedicated to enabling your mission. From priority national security initiatives for the DoD to highly assured and compliant solutions for healthcare, we understand that digital transformation is key to your future success.
We share your vision for the future and strive to accelerate your impact on the world. We bring both cutting edge technology and an expansive view of what’s possible to every engagement. Our delivery model and unique approaches harness our deep technical and domain knowledge, providing forward-looking insights and practical solutions to power secure mission acceleration.
SMX is an Equal Opportunity employer including disabilities and veterans.
Selected applicant may be subject to a background investigation and/or education verification.
SMX does not sponsor a new applicant for employment authorization or immigration related support for this position (i.e. H1B, F-1 OPT, F-1 STEM OPT, F-1 CPT, J-1, TN, E-2, E-3, L-1 and O-1, or any EADs or other forms of work authorization that require immigration support from an employer)."
2025-12-12T12:29:19.508,"Data Center Plant Engineer, Mechanical, Electrical",Google,"MINIMUM QUALIFICATIONS:

 * Associate's degree, trade school certification, or other certified training
   in a related technical field, or equivalent practical experience.
 * 7 years of experience in electrical, mechanical/HVAC, or controls/automation
   experience in an industrial or commercial environment.



PREFERRED QUALIFICATIONS:

 * Experience working in data centers, hospitals, or power plants.
 * Knowledge of electrical and mechanical systems used in a data center
   environment (e.g., Feeders, Transformers, Generators, Switchgear, UPS
   systems, ATS/STS units, PDU/PMM units, Chillers, Air handling units, and CRAC
   units).
   
 * Knowledge of meters, devices, sensors, and troubleshooting utilizing standard
   hand tools, digital metering, or calibration/diagnostic equipment.
   
 * Ability to communicate with contractors who perform maintenance or upgrade
   work on the data center systems.
   


ABOUT THE JOB:

The Data Center team designs and operates some of the most sophisticated
electrical engineering, mechanical engineering and HVAC systems in the world.
Facilities Technicians at Google data centers operate, monitor and support
physical facilities conditions. Some of these duties will include heating and
cooling of air and water, power supply, generators, UPS systems, electrical
distribution and control and monitoring systems. You regularly help inspect,
maintain and repair various data center systems such as piping and non-critical
electrical or mechanical system components). You provide daily assistance to
senior technicians as you read blueprints/schematics, conduct tours of systems
and assess their working order.

As a master of exceptional practices, you develop creative approaches to
reducing operational costs while improving overall data center efficiency. You
ensure that environmental and safety standards are consistently met, identifying
problems and making repairs quickly In emergency situations or abnormal
conditions, you manage data center performance issues and outages to minimize
the recovery time from failures.The AI and Infrastructure team is redefining
what’s possible. We empower Google customers with breakthrough capabilities and
insights by delivering AI and Infrastructure at unparalleled scale, efficiency,
reliability and velocity. Our customers include Googlers, Google Cloud
customers, and billions of Google users worldwide.

We're the driving force behind Google's groundbreaking innovations, empowering
the development of our cutting-edge AI models, delivering unparalleled computing
power to global services, and providing the essential platforms that enable
developers to build the future. From software to hardware our teams are shaping
the future of world-leading hyperscale computing, with key teams working on the
development of our TPUs, Vertex AI for Google Cloud, Google Global Networking,
Data Center operations, systems research, and much more.

The US base salary range for this full-time position is $105,000-$151,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Inspect, maintain, and repair various data center systems such as piping and
   non-critical electrical or mechanical system components.
   
 * Provide daily assistance to technicians as you read blueprints/schematics,
   conduct tours of systems, and assess their working order.
   
 * Manage the uptime and maintenance of water pumps and treatment systems, HVAC,
   UPS, generators, electrical distribution, and control and monitoring systems.
   
 * Operate, monitor, maintain, and respond to abnormal conditions in the data
   center facilities systems and equipment.
   
 * Support startup, commissioning, and integration of new equipment and systems
   into facilities infrastructure.
   "
2025-12-12T09:01:55.769,Data Engineer II,Microsoft,"Overview
With continued growth in digital data and the desire to leverage data to measure in-production quality and address problems that touch all aspects of our lives, Microsoft’s Windows Servicing & Delivery Org is looking for an equally data- and quality-minded engineer to meet these challenges! Join the Update Platform team for the chance to have an impact on billions of customers every day. The Update Platform Team is responsible for ensuring the seamless delivery and integration of software updates and keeping our customers up-to-date and secure at all times.
As a Data Engineer II member of the Update Platform Insights team, you will be at the forefront of leveraging data to assess the quality of the product, detect issues before they reach broad customer application to assure top product quality for partners and customers alike while keeping billions of devices secure and up-2-date.

In this exciting role, you'll work with a diverse group of talented professionals, innovate for greater platform efficiency as well as leveraging the latest technologies and best practices to streamline our update processes with timely in-depth insights and intelligent features.

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.


Responsibilities
Data Management and Transformation: With guidance, you will apply modification techniques to transform raw data into compatible formats for downstream systems. Utilize software and computing tools to ensure data quality and completeness. Implement code to extract and validate raw data from upstream sources, ensuring accuracy and reliability.
Drive Customer Success: Through Data and Business Insight: You will play a pivotal role in building a metrics-driven culture that directly impacts product quality and customer outcomes. This role goes beyond technical execution—you will design and implement measurement frameworks from the ground up while applying a strategic, top-down perspective to ensure the right metrics are in place. Your ability to translate data into actionable insights, aligned with business priorities and rhythm of business, will enable informed decisions that drive high-quality product outcomes and measurable customer success.

Data Requirements and Modeling: Collaborate with stakeholders to document and understand data requirements. Evaluate project plans to assess data costs, access, and availability. Draft design specifications to model data flow and storage, ensuring data is easy to connect and manage.
Compliance: You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams. You’ll also learn about permissions and approvals for data access within a data pipeline.

Validation and Quality Mindset: Apply and use operational fundamentals to validate and ensure quality of the product as well as the underlying data pipeline and assets to secure trustworthiness in your data daily.

Customer Focus: Be driven by a focus on customer happiness and success. We as a team only succeed if our customers are secure and protected via the updates we deliver.


Qualifications
Required Qualifications:
Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 1+ year(s) experience in business analytics, data science, software development, data modeling, or data engineering
OR Bachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 2+ years experience in business analytics, data science, software development, data modeling, or data engineering
OR equivalent experience.
Other Requirements:
Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include but are not limited to the following specialized security screenings:
Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.
Preferred Qualifications:
3+ years with scripting and coding languages with a focus on data engineering, like SQL, KQL, python, Scope, C# (or similar object-oriented languages) and others.
1+ years of experience with building large data processing frameworks using technologies like Azure Data Factory, Azure Data Explorer, PowerBI and/or other public and Microsoft internal tools.
1+ years of experience in analytics to define, monitor, and optimize key performance indicators (KPIs) and connected business metrics that ensure measurable customer success.
1+ years of proven ability to orchestrate and sustain a data-driven rhythm of business, transforming insights into actionable strategies that align with organizational priorities and deliver impactful outcomes.
A solid quality mindset with the ability to deliver end-to-end data solutions that build partner and customer confidence, ensuring alignment with business objectives and measurable outcomes.
Experience with Git, ADO or equivalent Source Control Systems.
Experience with data visualization tools and how to effectively communicate Insights to consumers of varying types of audiences.
Experience leveraging AI to define and evaluate quality standards


Data Engineering IC3 - The typical base pay range for this role across the U.S. is USD $100,600 - $199,000 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $131,400 - $215,400 per year. 
Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:
https://careers.microsoft.com/us/en/us-corporate-pay

This position will be open for a minimum of 5 days, with applications accepted on an ongoing basis until the position is filled.


Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance with religious accommodations and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations."
2025-12-12T01:54:02.588,"Data Science Engineer, New College Grad- Master's/PhD (Santa Clara, CA)",Applied Materials,"Assist in developing data science software prototypes and interfaces for monitoring semiconductor process tools Develop Python scripts to implement key concepts Collaborate closely with algorithm developers to characterize the algorithms and benchmark their performance, collecting quantitative data assessing effectiveness Evaluate the effectiveness and accuracy of the algorithms by working closely with process and equipment experts, providing feedback to algorithm developers Provide solutions which can be implemented by engineers without a deep statistical or mathematical background Deploy and maintain solutions at service sites Troubleshoot solutions, provide workarounds, and assist users in using solutions Assess effectiveness of solutions and provide data science insight Communicate well with algorithm developers and process experts Train field engineers to use solutions Present work and conclusions clearly and succinctly to peers Work well in team, providing and receiving constructive input with team members Monitor and quantify the results of complex algorithms in a production environment. Train a variety of individuals on the operation of these algorithms. Experience with various Artificial Intelligence Solutions, including Large Language Models, Computer Vision and Generative AI applications. Python, MATLAB Familiarity with common data science techniques, including regression, decision trees, Principle components, PLS, various Neural networks, time-series techniques, Bayesian techniques, etc. Ability to troubleshoot software applications and perform basic DevOps for deployment Ability to interact with Process and Customer Engineers Semiconductor process or equipment experience preferred. Demonstrates depth and/or breadth of expertise in own specialized discipline or field May lead small functional teams or projects with moderate resource requirements, risk, and/or complexity Communicates difficult concepts and negotiates with others to adopt a different point of view Master's or PhD in Computer Science, Data Science, Software Engineering, Mechanical Engineering, or related field. Preferred GPA of 3.0 or above"
2025-12-12T01:52:09.253,"Vice President, Data Engineer",BNY,"Bachelor's or master's degree in computer science or a related discipline, or equivalent work experience is required. 10+ years of data modeling, database design and development or related experience is required. Prior experience in managing DB development team Experience modeling Financial data Prior experience modeling Client and Entitlement Data Good knowledge of Financial Accounts, Transactions and Positions data Hands-on experience with any RDBMS, preferably MS SQL Server or Oracle Good SQL knowledge Excellent communication skills Good Problem Solving & Analytical Skills Work experience in Financial Services Work experience on any data modeling tool, viz. Erwin, DBArtisan etc. Experience with writing ANSI SQL code Prior Experience with a scripting language, preferably Python Experience working with Cloud native databases Bachelor's or Master's degree in Computer Science or a related discipline, or equivalent work experience is required. Advanced degree is preferred. Experience in the Securities or Financial Services industry."
2025-12-12T01:08:33,Data Analytics Engineer,Masimo,"The Data Analytics Engineer will support Masimo’s Quality organization by developing dashboards, performing data analysis, and transforming large datasets into meaningful insights. This role partners closely with Quality Compliance, Product Assurance, Engineering, Operations and cross-functional stakeholders to enhance data visibility, drive data-informed decisions, and support continuous improvement across the organization. The ideal candidate is technically strong in analytics tools, comfortable working with structured and unstructured data, and eager to grow in a fast-paced and evolving environment.
Duties & Responsibilities
Develop and maintain Power BI dashboards and reports that translate complex data sets into clear, actionable information.
Perform data transformation and modeling using SQL, Power Query (M), and DAX to support quality metrics, KPIs, and trend analysis.
Support routine and ad-hoc data analytics requests related to customer feedback, failure analysis, operations, and compliance activities.
Analyze large datasets to identify trends and process improvement opportunities.
Collaborate with Quality Compliance, Product Assurance, and cross-functional engineering teams to ensure data accuracy, consistency, and alignment with business needs.
Communicate findings through effective data storytelling, written summaries, and monthly presentations to cross functional leaders across the organization.
Contribute to continuous improvement efforts in reporting automation, dashboard optimization, and analytics best practices.
Minimum & Preferred Qualifications and Experience
Experience
0–2+ years of experience in data analytics, business intelligence, or engineering analytics; internship or project experience considered.
Hands-on experience with SQL and Power BI (including Power Query/M and DAX).
Experience using Python or R for data manipulation, modeling, or visualization preferred.
Familiarity with data visualization tools (Power BI highly preferred; Tableau or Looker a plus).
Understanding of statistics, data modeling, or quantitative analysis techniques.
Skills & Competencies
Strong analytical and problem-solving skills with high attention to detail.
Ability to translate data into clear insights for technical and non-technical partners.
Strong verbal, written, and visual communication skills, with the ability to present confidently and engage diverse audiences.
Ability to work independently and in a team environment.
Curiosity and willingness to learn new tools, systems, and techniques.
Education
Bachelor’s degree in Data Analytics, Data Science, Business Intelligence, Computer Science, Engineering, or a related field required.
Master’s degree in a relevant field is a plus but not required.
Compensation:
The anticipated salary range for this position is $90,000 - $110,000 plus benefits. Actual placement within the range is dependent on multiple factors, including but not limited to skills, education, and experience. 
This position also qualifies for up to 10% annual bonus based on Company, department, and individual performance. 
Masimo offers benefits such as Medical, Dental, Vision, Life/AD&D, Disability Insurance, 401(k), Vacation, Sick, Holiday, Paid Maternity Leave, Flexible Spending Accounts, Voluntary Accident, Critical Illness, Hospital, Long-Term Care, Employee Assistance Program, Pet Insurance, On-site wellness clinic, fitness center, and cafe. All benefits are subject to eligibility requirements."
2025-12-12T00:39:10,Data Engineer,HealthPartners/GHI,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:39:10,Data Engineer,HealthPartners,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:14:05.56,Sr. Data Engineer,Apple,"As a Data Engineer on the Capacity Engineering team, you will help design,
build, and operate the data foundation that drives capacity, cost, and
power-related decisions across Apple’s infrastructure footprint. In this role,
you will: Architect, implement, and maintain large-scale batch and streaming
pipelines that ingest, process, and model infrastructure telemetry, cost,
metering, utilization, forecasting, and power metrics from multiple clouds and
bare metal environments. Design and evolve robust data models (with a strong
focus on dimensional modeling) and storage patterns that support analytics,
internal billing, and efficiency use-cases. Treat data as a product: define
quality checks, SLAs, and observability to ensure data is accurate, timely, and
trusted by stakeholders across Apple. Integrate and enrich raw signals with
metadata and attribution to power use cases such as internal billing/showback,
usage understanding, efficiency and optimization, clawbacks, planning, and
procurement. Collaborate closely with data scientists, software engineers,
platform teams, finance partners, program managers, and leadership to translate
requirements into scalable, reliable data solutions and services. Implement
standard methodologies for data governance, lineage, metadata management, and
security, in alignment with Apple’s standards for data protection and privacy.
Build end-to-end data solutions that include logging, anomaly detection, data
validation, cleaning, and transformation, with strong emphasis on monitoring,
debuggability, and continuous improvement. Contribute to the evolution of our
data and platform stack, including tooling, frameworks, and standards for
development, testing, deployment, and operations (CI/CD, infrastructure as code,
etc.).


DESCRIPTION


Apple’s Capacity data engineering team, within the Apple Services Engineering
organization, is building the centralized data backbone that powers how Apple
understands, plans, and optimizes its cloud and data center infrastructure. We
engineer a unified, trusted data lake that consolidates cost, metering,
utilization, forecasting, and power metrics produced by Apple platforms and
systems (including bare metal) across both third-party and Apple internal
clouds. Enriched with metadata and attribution, this becomes the single source
of truth for internal billing, understanding usage and utilization, clawbacks,
planning, procurement, and efficiency initiatives. We collaborate with platform
engineering, finance, capacity engineering, and leadership teams to build
large-scale data pipelines, enable descriptive and predictive analytics, and
power dashboards and products that support critical business decisions. This is
your opportunity to help design and operate highly visible, global-scale systems
processing petabytes of data and supporting hundreds of users across Apple. Come
join us to help deliver the next generation of infrastructure insights at Apple.


MINIMUM QUALIFICATIONS


Bachelors degree or equivalent experience in Computer Science, Information
systems, Software Engineering, Data Science or related field. Advanced degree in
a related field a plus. 5+ years of experience in data engineering (or
equivalent practical experience), including: Building and maintaining
large-scale ETL/ELT data pipelines Distributed computing (e.g., Spark / PySpark)
for data processing and automation Query performance optimization and tuning at
scale Hands-on experience with: Apache Spark and Airflow (or similar
workflow/orchestration tools) for efficient large-scale data pipelines Data
modeling, especially dimensional modeling, and designing schemas optimized for
analytics and reporting Big data platforms and/or data lake architectures


PREFERRED QUALIFICATIONS


Experience with cloud technologies, specifically AWS (e.g., S3, EMR, Lambda,
Glue, RDS/Redshift, or similar services) Tooling & ecosystem: Experience with
CI/CD tooling such as Jenkins (or similar tools) Experience with data
visualization / BI tools, such as Superset or Tableau (other tools like
QuickSight, QlikView, Cognos, or Business Objects are a plus) Experience with
containerization and orchestration, such as Docker and Kubernetes/EKS is a plus
Understanding of authentication and authorization (AuthN/AuthZ) patterns
Knowledge of data governance principles, data security best practices, and data
privacy regulations"
2025-12-12T00:00:00,Lead Data Engineer,Nuna,"At Nuna, our mission is to make high-quality healthcare affordable for everyone. We are dedicated to tackling one of our nation’s biggest problems with ingenuity, creativity, and a keen moral compass.
Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why.
Nuna has established its brand in the B2B space over the last decade by shifting the US healthcare system towards an incentive model that rewards healthcare providers for positive outcomes. Marshalling our collective backgrounds and insights, we are now crafting an innovative, consumer app - a clinically driven healthcare companion experience that leverages AI, gamification and social support techniques to improve outcomes for people with chronic conditions.
As a sign of the impact Nuna has already made in this space, Nuna was recently selected to join the Centers for Medicare & Medicaid Services (CMS) Health Tech Ecosystem, a landmark public-private initiative designed to transform healthcare for Americans.
YOUR TEAM
The Data org at Nuna is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research.
The Data Engineer team is a core part of the broader Data organization, which is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research. The Data Engineer team acts as the technical backbone for data architecture, platform development, and data operations, empowering the organization to deliver impactful data-driven solutions in healthcare.
YOUR OPPORTUNITIES
We are looking for someone who is excited to use their creativity and engineering skills to make a difference in healthcare. You will have a foundational role on a team building a consumer product that incentivizes healthy behavior. You will be responsible for the data architecture and direction of the data platform that powers our data operations and data science initiatives.
Own the architecture and evolution of the data platform, based on business needs and considering trade-offs in timelines, cost, and resources
Define and enforce standards for code development, contribution, and deployment for data engineering workflows.
Oversee integrations with external services, including data ingestion, distribution, and service-to-service data flows.
Contribute hands-on to data transformations and optimizations
Establish security, governance, and operational best practices for the data platform in collaboration with security and enterprise data engineering teams.
Curate and develop datasets needed to support Data org project deliverables
Collaborate with cross-functional partners in engineering, design, and product to develop solutions
Generate and prioritize new opportunities for improvements
Provide build vs buy assessments and recommendations as the platform expands
QUALIFICATIONS
Required Qualifications
Deep hands-on expertise in designing, coding, developing, and maintaining data platforms that support data analytics and data science use cases
Proven ability to design, develop and implement robust data ingestion pipelines (ETL) from external sources into a data platform.
Experience establishing standards for code development, deployment, and contributions in a data engineering environment.
Ability to solicit and translate customer and business needs into requirements and an evaluation framework
Interest in improving healthcare and working with interdisciplinary project teams
Clear communication and presentation skills
Experience with Databricks
Expertise in data platform languages such as python, pyspark and SQL
+ 5-10 years of industry experience with technical lead experience of running a data platform for business operations
Preferred Qualifications
MS in quantitative field (e.g. Data Science, Economics, Statistics, Engineering)
Experience building a data platform from zero to one
Experience working with healthcare data
Experience with SDLC and management of machine learning models (MLOps)
Bonus points if experience with MLOps on LLM/GenAi features (evals, context building, …)
We take into account an individual’s qualifications, skillset, and experience in determining final salary. This role is eligible for health insurance, life insurance, retirement benefits, participation in the company’s equity program, paid time off, including vacation and sick leave. The expected salary range for this position is $208,000 - $260,000. The actual offer will be at the company’s sole discretion and determined by relevant business considerations, including the final candidate’s qualifications, years of experience, and skillset.
Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status.
#LI-FK1"
2025-12-12T00:00:00,Development Project Engineer (Data Center Construction),QTS Data Centers,"Who we are: It's pretty exciting to find yourself standing in a pivotal moment in time. It’s even more exciting to be out front leading it. At QTS, our world-class data centers are supporting our customers’ most strategic growth initiatives, positioning us at the forefront of today’s dynamic digital transformation. As AI and cloud drive the demand for increased speed, capacity and capability, QTS has emerged as the global digital infrastructure leader, committed to connecting the world for good. Driven by purpose and fueled by a spirit of innovation, QTS designs, builds and operates some of the world’s most advanced, forward-thinking data centers. QTS is a portfolio company of Blackstone. QTS is Powered by People. People who play a vital role in our company’s culture, innovation and growth. People who are committed to contributing to the communities where we operate and work. People who are knowledgeable, resourceful and mission driven. Together, we do great things. Who You Are: The Development Project Engineer (Data Center Construction) is primarily responsible for assisting with the design, preconstruction and construction activities on a given project(s). The Development Project Engineer will interact on a daily basis with Facilities, Contractors, Designers, Engineers, Commissioning Agents, Vendors, and Data Center Operations & Corporate real estate staff and should have both written and oral communication skills commensurate with this level of regular communication. What You Will Do: Assist Development leadership and Project Manager with day to day activities and responsibilities Assist with multiple projects on a campus(es) and maintain updated budgets, schedules, and status reports for each Assist with updates on development program & project status on a monthly basis suitable for executive level reviews. Work with QTS stakeholders, design, and construction teams to help with master development program for site(s), including a complete campus design solution and capital budget. Assist with entitlement and permitting needs for each assigned site project(s) Assist with scopes of work for design, construction, commissioning services & participate in procurement and project cost estimates Evaluate and level pricing proposals for design, construction, and commissioning services Work closely with strategic procurement team on equipment procurement and delivery process Ensure appropriate submittals are coordinated with site stakeholders Assist with monitoring project budget / cost-to-date against overall project budget. Review project schedules and manage teams to on-time completion Review change order requests from contractors and negotiate pricing Assist with establishing site construction security procedures in conjunction with site security team Establish and maintain relationships serving as liaison with key QTS stakeholders Represent QTS Interests in OAC meetings Create & build relationships that enhance QTS’s ability to be a leader in creating the World’s Most Valuable Data Center Real Estate Aid in due diligence efforts on an as-needed basis by participating with real estate efforts on potential or new land banks and properties, including: Evaluate opportunities to design & build new data centers by working with key stakeholders: Corporate Real Estate, Connectivity, Power & Construction teams. Assist with establishing and monitoring entitlement and permit processes for individual projects as needed Work with the internal development team to enhance project management processes and protocols What You Will Need to be Successful (basic qualifications): Bachelor’s degree in Engineering or Construction Management field or equivalent professional experience Experience with Microsoft Office suite, specifically PowerPoint for use in communicating program updates to executive level, and Excel to create and maintain site program & individual project budgets Excellent interpersonal skills with the ability to interface with all levels of the organization Must be a capable, proven team player that both fosters and operates well within internal and external team environments. Able to solve problems at a tactical and functional level Strong Verbal and Written Communication Skills Ability to manage multiple projects simultaneously Other Key Skills: One or more years of professional experience in commercial construction practices and procedures, including management of Lump Sum, Construction Management @ Risk, and Design Build project delivery methods from conceptual development through procurement to close out Documented experience using AutoCAD, BlueBeam, P6, and CxAlloy Experience or exposure in mission critical data center facilities Experience with management of MEP trades Experience managing document control for active data center build sites The Perks (and these are just a few!): Q-Rest Sabbatical Employee Stock Purchase Plan QTS scholarship for dependents Eagle Club Award Trip Eligibility Paid Volunteer and Floating days Tuition Assistance, Parental Leave and Military Leave Assistance We conform to all the laws, statutes, and regulations concerning equal employment opportunities and affirmative action. We strongly encourage women, minorities, individuals with disabilities and veterans to apply to all of our job openings. We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, gender identity, or national origin, age, disability status, Genetic Information & Testing, Family & Medical Leave, protected veteran status, or any other characteristic protected by law. We prohibit retaliation against individuals who bring forth any complaint, orally or in writing, to the employer or the government, or against any individuals who assist or participate in the investigation of any complaint or discrimination claim. The ""Know Your Rights"" Poster is included here: Know Your Rights (English) Know Your Rights (Spanish) The pay transparency policy is available here: Pay Transparency Nondiscrimination Poster-Formatted QTS is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please send an e-mail to talentacquisition@qtsdatacenters.com and let us know the nature of your request and your contact information. It’s exhilarating to find yourself at a pivotal moment in history— and even more so to be leading the way. At QTS Data Centers, we are proud to stand at the forefront of today’s dynamic digital transformation. Our world-class data centers empower our customers’ most strategic growth initiatives, positioning us as a global leader in digital infrastructure. As AI and cloud technologies fuel the demand for increased speed, capacity, and innovation, QTS has emerged as the global digital infrastructure leader. We are committed to connecting the globe for good. Driven by purpose and a spirit of innovation, we design, build, and operate some of the most advanced data centers worldwide. In addition to our cutting-edge technology, we are dedicated to sustainability, incorporating renewable energy solutions to minimize our environmental footprint and drive meaningful impact. As a proud portfolio company of Blackstone, QTS is uniquely positioned to achieve ambitious growth and innovation goals. At QTS, we are Powered by People. Our team members are the cornerstone of our culture, innovation, and growth. They are mission-driven, resourceful, and committed to making a positive impact in the communities where we live and work. Together, we’re achieving remarkable things and shaping the future of digital infrastructure. And we’d like to invite you to join us. In addition to a variety of benefit packages, QTS goes above and beyond for our employees: Roth and Traditional 401(k) matching contributions with immediate vesting Every employee is bonus or commission eligible Generous PTO, Paid Volunteer Days Plus Floating Holidays Stock Purchase Plan (SPP) 11 paid Holidays Annually/Holiday compensation when worked Pet and Legal Insurance Q-Rest Sabbatical Program Q-Anniversary Service Award Program Parental Leave for primary and secondary caregivers Military Benefits Package QTS Charitable Matching Gift Program QTS Scholarship for Employee Dependents QTS Crisis Fund Wellness Program Tuition Reimbursement Program"
2025-12-12T00:00:00,"Data Engineer I, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $109,300.00 - $180,200.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data across the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape by designing, building, and deploying data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning, and business intelligence initiatives. You will work closely with Data Science and Decision Science teams to build, test, and maintain data pipelines and model workflows that support both analytical research and production use cases in our Databricks/AWS/Snowflake environment. In addition to your strong analytical mind, you will bring an inquisitive attitude and the ability to translate the stories found in data into actionable insights while contributing to technical discussions and process improvements. Applicants must be authorized to work for ANY employer in the U.S. The company does not sponsor/support H-1B petitions, TN, or Forms I-983/STEM OPT, for this role. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions. Design data solutions. Analyze sources to determine value and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Collaborate within and across teams to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate. Test data movement, transformation code, and data components. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent. Six years of related experience. Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions. Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on. Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems. Strong verbal and written communication skills with the ability to interact with team members and business partners. Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Four years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,"Senior Data Engineer, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $139,400.00 - $230,000.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions. Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies. Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate. Collaborate across team to support delivery and educate end users on complex data products/analytic environment. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent Ten years of related experience Primary Job Requirements: Architect and design scalable, secure data solutions using AWS, Databricks, and Ab Initio. Lead technical direction for data engineering initiatives across cloud and on-premises infrastructure. Hands-on development: build ETL pipelines, optimize Spark jobs, and create Ab Initio graphs. Troubleshoot production issues and provide technical guidance to junior engineers. Conduct mentoring sessions and offer technical guidance to the 20-person admin team. Collaborate with DBA teams, business analysts, and QA teams to ensure data governance and quality. Manage infrastructure deployment and optimize cloud resources. Lead technical design reviews and architecture discussions. Implement data integration solutions and ensure compliance with data protection regulations. Establish and enforce coding standards, best practices, and data governance policies. Technical Skills: AbInitio: Expert proficiency with GDE, Co>Operating System, EME, BRE, Express>It, metaprogramming (PDL) Programming: Python, PySpark, SQL Cloud: AWS architecture and services Databricks: Workspace management, cluster configuration, Delta Lake, Unity Catalog Data Warehousing: Strong understanding of data modeling, dimensional modeling (star/snowflake schemas) ETL/ELT: End-to-end ETL development lifecycle Version Control: Git, CI/CD pipelines Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices. Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems. Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers. Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize. Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas. Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Five years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,Data Flow Engineer,Scientific Research Corporation,"Description
The Data Flow Engineer will be a member of a Cryptologic Carry-On Program (CCOP) and Ship’s Signals Exploitation Equipment (SSEE) Systems Engineering team primarily responsible for ensuring the processing and distribution of data to and from intelligence community networks. The ideal candidate will have a history of direct involvement with successful NiFi data flow engineering and resolving Navy hardware and software functionality problems by providing a high degree of timely customer service and technical expertise in support of the US Navy information warfare community.
Installing, configuring, integrating, and maintaining NiFi servers and processors into new or existing system architectures
Verifying and maintaining all NiFi processors and flows to and from deployed (and test) systems, from the field system through customer back-end repositories
Assisting end users with the operational readiness and configuration of deployed systems for optimal data flow to satisfy customer requirements
Designing and developing NiFi processors and flows for deployed systems, containing multiple subsystems and requiring integration with external networks
Implementing expression language in NiFi processors in response to emerging customer requirements
Exhibiting developed verbal and written communication skills and the ability to express concepts and ideas in a clear and concise manner; employing technical writing techniques
Performing as a team player, dedicated to the endeavors of the mission, the customer, and the team itself
Being a self-starter who is accountable and requires minimal direction and supervision; capable of multitasking and working several complex and diverse tasks with simultaneous or near simultaneous deadlines
#LI-LL1
Requirements
Must possess an active TS/SCI clearance and be able to obtain a CI Polygraph
Requires a bachelor’s degree in related technical field or equivalent work experience
Intermediate Linux Command Line Interface (CLI) experience
1-3 years of Apache Niagara Files (NiFi) experience (negotiable with other qualifications)
Strong background in using and troubleshooting Software Defined Radio (SDR) systems
Fundamental knowledge of wireless protocols in common use
Experience providing technical support to customers over Internet Relay Chat (IRC) or similar applications
Familiarity with back-end databases and repositories
Must be willing to travel up to 10% of the year
Must currently be DoD 8570-compliant with the equivalent of an IAT II certification or have the ability to do so within 6 months of employment
Desired Skills
Current Linux+/LPIC 1 and/or Network+ certification
Familiarity with Regular Expression (REGEX), Cisco Networking, and Amazon Web Services (AWS)
Expert-level SDR knowledge and experience
Experience with strategic-level intelligence processes
Basic computer programing experience (i.e. Python, JavaScript, bash)
Prior Navy CTR/CTM/CTN with shipborne, expeditionary, or other comparable experience 
Clearance Information
SRC IS A CONTRACTOR FOR THE U.S. GOVERNMENT. THIS POSITION WILL REQUIRE U.S. CITIZENSHIP AS WELL AS A U.S. GOVERNMENT SECURITY CLEARANCE AT THE TOP SECRET / SCI LEVEL with CI POLY ELIGIBILITY
Travel Requirements
up to 10% travel may be required
About Us
Scientific Research Corporation is an advanced information technology and engineering company that provides innovative products and services to government and private industry, as well as independent institutions. At the core of our capabilities is a seasoned team of highly skilled engineers and scientists with multidisciplinary backgrounds. This team is challenged daily to provide cutting edge technology solutions to our clients.
SRC offers a generous benefit package, including medical, dental, and vision plans, 401(k) with a company match, life insurance, vacation and sick paid time off accruals starting at 10 days of vacation and 5 days of sick leave annually, 11 paid holidays, tuition reimbursement, and a work environment that encourages excellence and more. For positions requiring a security clearance, selected applicants will be subject to a government security investigation and must meet eligibility requirements for access to classified information.
EEO
Scientific Research Corporation is an equal opportunity employer that does not discriminate in employment.
All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other protected characteristic under federal, state or local law.
Scientific Research Corporation endeavors to make www.scires.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact jobs@scires.com for assistance. This contact information is for accommodation requests only and cannot be used to inquire about the status of applications."
2025-12-12T00:00:00,"Research Data Engineer II, CHeT Analytics",University of Rochester,"As a community, the University of Rochester is defined by a deep commitment to Meliora - Ever Better. Embedded in that ideal are the values we share: equity, leadership, integrity, openness, respect, and accountability. Together, we will set the highest standards for how we treat each other to ensure our community is welcoming to all and is a place where all can thrive. Job Location (Full Address): 265 Crittenden Blvd, Rochester, New York, United States of America, 14642 Opening: Worker Subtype: Regular Time Type: Full time Scheduled Weekly Hours: 40 Department: 400980 Neuro-Ctr Health & Tech/Admin Work Shift: UR - Day (United States of America) Range: UR URG 113 Compensation Range: $77,216.00 - $115,824.00 The referenced pay range represents the minimum and maximum compensation for this job. Individual annual salaries/hourly rates will be set within the job's compensation range, and will be determined by considering factors including, but not limited to, market data, education, experience, qualifications, expertise of the individual, and internal equity considerations. Responsibilities: GENERAL PURPOSE Participates in the design, implementation and maintenance of analytical and data science-based software and data pipelines to support scientific workflows. Focuses on developing and supporting data collection frameworks that integrate structured and unstructured data from multiple sources and systems to support specific research study teams. Supports the development and maintenance of infrastructure systems (e.g., data warehouses, data lakes), including data access Application Programming Interface(s) (APIs). Works in partnership with team members to provide robust, scalable software solutions to the research enterprise. ESSENTIAL FUNCTIONS Builds, maintains and evolves general Extract, Transform and Load (ETL) data pipelines and overall data architecture to accommodate a growing amount of data from a variety of large research data sources. Works with research team members to convert business and technical requirements into professional software solutions. Ensures timely completion of tasks while managing multiple assignments, project timelines and business user expectations. Designs and implements custom research project-specific data workflow solutions for data collection, management, reporting and analytics. Contributes to the scientific research. Adheres to defined application development life-cycle practices, including but not limited to, requirements gathering, writing test plans, source code management, peer code review and quality assurance through unit/system/user acceptance testing. Participates in specification, implementation and execution of testing procedures to ensure quality of deliverables, system and data workflow reliability. Produces and maintains comprehensive technical documentation for all systems under the Engineer's responsibilities. Keeps abreast of current application developments through continuing education, professional reading, online forums, conferences, workshops and professional groups. Other duties as assigned. MINIMUM EDUCATION & EXPERIENCE Bachelor's degree in Data Science, Biomedical Science, Computer Science, Mathematics, Statistics or similar discipline and 2 years of experience in technology and data intensive roles and environments required Or equivalent combination of education and experience Programming experience in Structured Query Language (SQL) and one other applicable language (Java, Python, and/or R) required Experience with Change Management solutions required Experience with Version Control solutions (e.g. Git) required Experience implementing and supporting data management systems in a scientific, research context (e.g. biospecimen software, electronic laboratory notebooks, REDCap) preferred Experience with Linux, container and cloud technologies (e.g. HPC, IaaS and PaaS) preferred KNOWLEDGE, SKILLS AND ABILITIES Understanding of data analytics and statistical methods required Expertise of software engineering best practices such as version control and software release management required Strong analytical and problem-solving skills required Strong organizational skills required Ability to work with others in a matrix management environment required Excellent communication skills for describing progress and challenges to stakeholders required Attention to detail, patience and a positive, customer-centric attitude required Strong technical presentation skills required Demonstrated ability to develop proficiency with unfamiliar toolsets preferred Familiarity with file formats, metadata, and data exchange and storage standards applicable in management of scientific and clinical research required The University of Rochester is committed to fostering, cultivating, and preserving an inclusive and welcoming culture to advance the University’s Mission to Learn, Discover, Heal, Create – and Make the World Ever Better. In support of our values and those of our society, the University is committed to not discriminating on the basis of age, color, disability, ethnicity, gender identity or expression, genetic information, marital status, military/veteran status, national origin, race, religion, creed, sex, sexual orientation, citizenship status, or any other characteristic protected by federal, state, or local law (Protected Characteristics). This commitment extends to non-discrimination in the administration of our policies, admissions, employment, access, and recruitment of candidates, for all persons consistent with our values and based on applicable law. Notice: If you are a Current Employee, please log into myURHR to search for and apply to jobs using the Jobs Hub. Your application, if submitted using this portal, cannot be moved forward. Learn. Discover. Heal. Create. Located in western New York, Rochester is our namesake and our home. One of the world’s leading research universities, Rochester has a long tradition of breaking boundaries—always pushing and questioning, learning and unlearning. We transform ideas into enterprises that create value and make the world ever better. If you’re looking for a career in higher education or health care, the University of Rochester may offer the perfect opportunity for your background and goals. At the University of Rochester, we are committed to fostering, cultivating, and preserving an inclusive and welcoming culture and are united by a strong commitment to be ever better—Meliora. It is an ideal that informs our shared mission to ensure all members of our community feel safe, respected, included, and valued."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,Data Engineer II (Onsite),RTX,"Date Posted: 2025-12-12 Country: United States of America Location: PW147: PW OKC Campus 8120 S. Air Depot Blvd , Oklahoma City, OK, 73135 USA Position Role Type: Onsite U.S. Citizen, U.S. Person, or Immigration Status Requirements: U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Security Clearance: None/Not Required Pratt & Whitney is working to once again transform the future of flight—designing, building and servicing engines unlike any the world has ever seen. And because transformation begins from within, we’re seeking the people to drive it. So, calling all curious. Come ready to explore and you’ll find a place where your talent takes flight—beyond the borders of title, a country or your comfort zone. Bring your passion and commitment and we’ll welcome you into a tight-knit team that takes our mission personally. Channel your drive to make a difference into shaping an organization and an industry that’s evolving fast to the future. At Pratt & Whitney, the difference you make is on display every day. Just look up. Are you ready to go beyond? You will be an integral part of Pratt & Whitney’s Sustainment Operational Excellence Data Engineering & Analytics team. This team supports the global aftermarket maintenance and overhaul of engines for the F117, F119, and F135 programs. We are looking for a Data Engineer II to advance the digital and data capability of the Military Engines Global Depot Network organization. You will be working on exciting new technologies like cloud and open-source tools among others, and be responsible for cleaning, standardizing, transforming, and configuring data products within our emerging data mesh. What You Will Do: Create and maintain scripts written in Spark SQL or Pyspark in Databricks Notebooks. Also, work with SMEs to understand complex datasets for next generation data products and data visualizations to create data mesh tables. Develop scalable and sustainable data product transformations that curate, clean and store data efficiently; perform statistical analysis to quantify completeness and validity; perform bug fixes and apply enhancements to the models when the need arises. Ensure high performance and reliability of data transformation processes and pipelines. Collaborate cross-functionally to gather insights, refine requirements, and ensure alignment between product goals and team efforts. Document data processes, logic, and data sources to ensure transparency and knowledge sharing as well as support the overall team with any ad-hoc data related tasks. Work to convert our existing data visualizations in Power BI to use Databricks instead of Azure Synapse. Keep up to date with technologies and use advanced cloud data warehouse and data transformation techniques to build innovative solutions. Qualifications You Must Have: A degree in Science, Technology, Engineering or Mathematics (STEM) with 2+ years of experience in the use of SQL and/or Python to transform, clean, and integrate data from a variety of source pipelines. U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Qualifications We Prefer: Experience with transformation tools such as dbt, Databricks pipelines, or relevant tools such as SSIS, ADF, or Matillion. Demonstrated experience with Git/GitHub; experience working in cloud data warehouses like Databricks. Familiarity with agile methodologies and Kanban boards. Self-motivated, team player with good communication skills. Ability to focus on results and successfully manage multiple tasks/projects. An astute individual, with the ability to build strong cross-functional relationships; excited at the prospect of developing and implementing new data products that add organizational value & improve decision making capabilities. Business experience with Aerospace or other heavy manufacturing industry. An understanding of ER Diagrams for data modeling. Demonstrated understanding of data mesh design principles and data engineering best practices. Learn More & Apply Now! What is my role type? In addition to transforming the future of flight, we are also transforming how and where we work. We’ve introduced role types to help you understand how you will operate in our blended work environment. This role is: Onsite: Employees who are working in Onsite roles will work primarily onsite. This includes all production and maintenance workers, as they are essential to the development of our engines. Candidates will learn more about role type and current site status throughout the recruiting process. For onsite and hybrid roles, commuting to and from the assigned site is the employee’s personal responsibility. As part of our commitment to maintaining a secure hiring process, candidates may be asked to attend select steps of the interview process in-person at one of our office locations, regardless of whether the role is designated as on-site, hybrid or remote. The salary range for this role is 66,000 USD - 130,000 USD. The salary range provided is a good faith estimate representative of all experience levels. RTX considers several factors when extending an offer, including but not limited to, the role, function and associated responsibilities, a candidate’s work experience, location, education/training, and key skills. Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement. Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company’s performance. This role is a U.S.-based role. If the successful candidate resides in a U.S. territory, the appropriate pay structure and benefits will apply. RTX anticipates the application window closing approximately 40 days from the date the notice was posted. However, factors such as candidate flow and business necessity may require RTX to shorten or extend the application window. RTX is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or veteran status, or any other applicable state or federal protected class. RTX provides affirmative action in employment for qualified Individuals with a Disability and Protected Veterans in compliance with Section 503 of the Rehabilitation Act and the Vietnam Era Veterans’ Readjustment Assistance Act. Privacy Policy and Terms: Click on this link to read the Policy and Terms RTX is an aerospace and defense company that provides advanced systems and services for commercial, military and government customers worldwide. It comprises three industry-leading businesses – Collins Aerospace, Pratt & Whitney, and Raytheon. Its 195,000 employees enable the company to operate at the edge of known science as they imagine and deliver solutions that push the boundaries in quantum physics, electric propulsion, directed energy, hypersonics, avionics and cybersecurity. The company, formed in 2020 through the combination of Raytheon Company and the United Technologies Corporation aerospace businesses, is headquartered in Arlington, Virginia."
2025-12-12T00:00:00,"Senior Engineer, BAW R&D Trimming and Data Infrastructure",Qorvo,"
                Qorvo (Nasdaq: QRVO) supplies innovative semiconductor solutions that make a better world possible. We combine product and technology leadership, systems-level expertise and global manufacturing scale to quickly solve our customers' most complex technical challenges. Qorvo serves multiple high-growth segments of large global markets, including consumer electronics, smart home/IoT, automotive, EVs, battery-powered appliances, network infrastructure, healthcare and aerospace/defense. Visit www.qorvo.com to learn how our innovative team is helping connect, protect and power our planet.

 
Summary:
 Qorvo’s BAW R&D Data Infrastructure team is seeking a talented engineer for semiconductor data infrastructure, frequency trimming and process automation. The candidate chosen for this role will develop data infrastructure and software tools to support efficient development and production of new Bulk Acoustic Wave (BAW) filter technologies. The candidate will use MATLAB, data analysis tools (SpotFire), databases and other software tools for process control improvements, faster design cycles, and general automation to efficiently develop and produce new technologies.
 
Key Roles and responsibilities:

Research, implement, deploy, and maintain internal software applications used by Manufacturing and R&D Engineering teams to process and trim BAW filters wafers.
Work closely with Process Integration and Process Engineering teams to understand new BAW technology needs to define requirements and implement.
Provide comprehensive support to internal customers: resolve outstanding issues for R&D engineers, designers, and production at Qorvo’s fabrication facility.
Own critical data infrastructure projects and successfully deliver results in a timely manner

 
Technical Knowledge/Skills/Abilities Required:

Excellent MATLAB or Python programming capabilities
Knowledge of semiconductor processing
Practical knowledge of software development and object-oriented programming
Excellent debugging and problem-solving skills


Strong data analysis and mathematical skills


Experience with version control utilizing Git and GitLab
Good knowledge of SQL database (Oracle is a plus)
Experience in the full life cycle of the software design process including requirement analysis, design, prototyping, coding, documentation, implementation, and maintenance

 
Personal Skills:

Self-motivated, independent, proactive, detail oriented, and responsible team-player
Excellent analytical skills
Comfortable working in a dynamic and fast paced environment
Passion for innovation and emerging technologies
Excellent communication and interpersonal skills
Able to handle multiple priorities
Proficient in English

 
Desired experiences:

Experience with software development for semiconductor processing 
Expertise in electromagnetics, physics, or material science
Expertise in Oracle PL/SQL databases
Experience with data analysis tools such as Spotfire or similar application
Experience with GitLab workflows and pipeline automation 
Experience with Visual Studio Code and GitHub Copilot
Experience with unit testing in past development projects

 
Qualifications:
Education & Experience:

BS or MS in Computer Science, Electrical Engineering, Physics or Material Science
5+ years of code development experience.(or if Master's degree 2+ years experience)

 
This position is not eligible for visa sponsorship by the Company.
 
#LI-KR1
 MAKE A DIFFERENCE AT QORVO   

 We are Qorvo. We do more than create innovative RF and Power solutions for the mobile, defense and infrastructure markets – we are a place to innovate and shape the future of wireless communications. It starts with our employees. As a unified global team, we bring a commitment to excellence, growth and a passion for creating what's next. Explore the possibilities with us.

We are an Equal Employment Opportunity (EEO) employer and welcome all qualified applicants. Applicants will receive fair and impartial consideration without regard to any characteristics protected by applicable law, including race, color, religion, sex (as defined by law), national origin, age, military or veteran status, genetic information, or disability.  
                
    "
2025-12-12T18:28:05.616,Sr Staff Engineer Software (Data Plane Applications),Palo Alto Networks,"Company Description
Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
Who We Are
We believe collaboration thrives in person. That’s why most of our teams work from the office full time, with flexibility when it’s needed. This model supports real-time problem-solving, stronger relationships, and the kind of precision that drives great outcomes.
Job Description
Your Career
Prisma Access™ (formally GlobalProtect Cloud Service) provides protection straight from the cloud to make access to the cloud secure. It combines the connectivity and security you need and delivers it everywhere you need it. Using cutting-edge public and private cloud technologies extending the next-generation security protection to all cloud services, customers on-premise remote networks and mobile users.
We are seeking an experienced Software Engineer to design, develop and deliver next-generation technologies within our Prisma Access team. We want passionate engineers who love to code and build great products. Engineers who bring new ideas in all facets of software development. We are looking for leaders who take ownership of their areas of focus and who are driven to solve problems at every level. Collaboration and teamwork are at the foundation of our culture and we need engineers who can communicate at a high level and work well with others towards achieving a common goal.
Your Impact
Design, develop and implement highly scalable software features and infrastructure on our next-generation security platform ready for cloud native deployment from inception to completion
Work with different development and quality assurance groups to achieve the best quality - You accomplish this by being hands-on, creating tools, processes, and systems that produce transparency, alignment, and direction
Profile, optimize and tune systems software (management/control/dataplane) for efficient cloud operation
Work with DevOps and the Technical Support teams to troubleshoot customer issues
Work with other software development team to apply PanOS features on Prisma Access
Interview, mentor and coach new team members 
Qualifications
Your Experience 
5+ years of experience in developing and troubleshooting dataplane applications
Required hands-on programming experience in Python and Go
Nice to have C/C++ Programming
Strong Data structures/Algorithms
Strong analytical skills, problem solving and debugging skills
Nice to have experience with LLMs and GenAI applications. Or Machine learning/Data science with experience in ETL, curating datasets, running evals. 
Experience with building applications in the cloud
In-depth understanding of Operating System principles and OS like Linux/Unix
In-depth understanding of networking concepts and TCP/IP stack, TLS
Exposure to building Microservices 
Enjoys working with many different teams with strong collaboration and communication skills
Solid foundation in design, data structures, and algorithms, and strong analytical and debugging skills
Education : M.S./B.S. degree in Computer Science or equivalent military experience required
Additional Information
The Team
Our engineering team is at the core of our products – connected directly to the mission of preventing cyberattacks. We are constantly innovating – challenging the way we, and the industry, think about cybersecurity. Our engineers don’t shy away from building products to solve problems no one has pursued before.
We define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment.
Compensation Disclosure
The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $170,000 - $190,000/YR. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.
Our Commitment

We’re problem solvers that take risks and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at [email protected].
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
Is role eligible for Immigration Sponsorship?: Yes"
2025-12-12T18:20:27,Data Engineer,Real Chemistry,"At Real Chemistry, making the world a healthier place isn’t just an aspiration—it’s our everyday reality. Our drive to transform healthcare is informed by our blend of deep scientific expertise, human-centred creativity, and AI-driven insights, fostering a unique environment where innovation thrives and our people are impact-obsessed. As a global agency, we provide a full suite of services across healthcare communications and marketing to our clients, including top players in the pharmaceutical and biotech industries.
Our #LifeatRealChem culture is rooted in our people—we believe we are best together and are committed to excellence for both our clients and colleagues. Whether you're a seasoned professional or just starting your career, if you share our passion for healthcare and connection, we invite you to explore our opportunities.
Discover your purpose. Embrace innovation. Experience #LifeatRealChem.
Job Summary 
We’re looking for a hands-on Data Engineer to help build and maintain the data infrastructure that powers our AI products and solutions. This role sits within our AI organization and focuses on designing, developing, and optimizing scalable data pipelines, data models, and cloud-based data systems. You’ll collaborate closely with data scientists, ML engineers, product teams, and other technical partners to ensure high-quality, reliable, and well-structured data is available across the organization. 
Key Responsibilities 
Data Pipeline Development 
Build, optimize, and maintain scalable ETL/ELT pipelines for structured and unstructured data. 
Implement reliable, fault-tolerant ingestion and transformation workflows. 
Automate routine data processes where possible. 
Data Architecture & Modeling 
Develop well-structured data models that support analytics, ML use cases, and downstream applications. 
Support the design and enhancement of AI-related data architecture across cloud environments. 
Data Quality & Governance 
Implement automated data validation, monitoring, and alerting. 
Ensure high data accuracy, completeness, and integrity across ingestion and transformation layers. 
Cross-Functional Collaboration 
Partner with data scientists, ML engineers, product managers, and IT teams to understand data requirements and translate them into technical solutions. 
Troubleshoot issues and support stakeholders with data access and pipeline improvements. 
Cloud & Infrastructure 
Work with modern cloud platforms (AWS, Azure, or GCP) and associated data storage, compute, and orchestration services. 
Support deployment, scaling, and operational health of data systems. 
Innovation & Continuous Improvement 
Stay current with emerging data engineering tools and best practices. 
Propose opportunities to improve performance, efficiency, or reliability within the data stack. 
Qualifications & Skills 
Education & Experience 
Bachelor’s degree in Computer Science, Data Engineering, or related technical field (or equivalent experience). 
3–7 years of hands-on experience in data engineering or data pipeline development. 
Technical Skills 
Strong SQL skills and proficiency in Python or Scala. 
Experience with data warehousing technologies such as Snowflake, BigQuery, Redshift, or Databricks. 
Hands-on experience with cloud services (AWS, Azure, or GCP). 
Knowledge of data modeling, schema design, and ETL/ELT principles. 
Familiarity with distributed computing frameworks such as Spark or Flink. 
Experience with workflow orchestration tools like Airflow, Prefect, or Dagster is a plus. 
Soft Skills 
Strong problem-solving skills and attention to detail. 
Ability to communicate technical concepts clearly to peers and cross-functional partners. 
Comfortable working in a fast-moving, collaborative environment. 
Preferred Qualifications 
Experience with streaming data tools such as Kafka or Kinesis. 
Experience building CI/CD pipelines for data workflows. 
Experience in healthcare, biotech, life sciences, or commercial/marketing data environments. 
Experience in agency or consulting settings. 
Posting Salary
$140,000—$175,000 USD
Real Chemistry is proud to be Great Place to Work® certified; check out what our people shared about our culture and workplace on our Great Places to Work Profile here.
We believe we can do our best when feeling our best, which is why we’ve put together a benefits program designed to give you the support you and your family need at every stage of life. Real Chemistry offers a comprehensive benefit program and perks, tailored to your region. Globally, this includes offices in our key markets with free snacks to keep you running all day long, generous holiday and paid time off, options for private medical, dental, and vison plans, and support in saving for the future. Other perks include mental wellness coaching and support and access to more than 13,000 online classes with LinkedIn Learning. Learn more about our great benefits and perks and search specific offerings in your region at: www.realchemistrybenefits.com.
Working with Real HART: Since the pandemic, we have adapted to how our people told us they want to work. We have office locations in cities in the US, UK, and Europe with many employees and clients that serve as hubs where and when they need us. For employees who are within an hour of one of our offices, we expect attendance in the office two days per week, either at a Real Chemistry office or onsite with clients. We are also actively opening new office locations, so if one opens near you, our Real HART policy will apply. We are not looking for attendance for the sake of attendance but believe that the opportunity to coordinate in-office team meetings, 1:1 meetings with managers, taking advantage of on-site learning, and connecting with client partners is a critical to delivering on our purpose of making healthcare what it should be. Outside of these offices, we have regions, where people work remotely but come together quarterly for collaboration, culture and learning opportunities. We call this our Real Hybrid and Regional Teams (Real HART) approach. Real Chemistry believes we are best together – and our workplace strategy fosters connection and collaboration in person – but also supports flexibility for our people.
Real Chemistry is an Equal Opportunity employer. We continually strive to build and sustain an inclusive and equitable work environment where our employees feel empowered to leverage all they bring from their personal lived experience and professional expertise, to make our team the best in the industry. We encourage motivated and qualified applicants to apply without regard to race, color, religion, sex (including pregnancy), sexual orientation, gender identity/expression, ethnic or national origin, age, physical or mental disability, genetic information, marital information, or any other characteristic protected by federal, state, or local employment discrimination laws where Real Chemistry operates. Should you require accommodations throughout the interview process please let your recruiter know.
*Notice: Real Chemistry and its affiliates' names are being misused by scammers through messaging services, fake websites, and apps. Do not share personal or financial information or make payments to any unverified sources claiming to be connected to Real Chemistry. We are working to stop these unauthorized activities and protect our community. Read more here."
2025-12-12T17:29:23,Senior Python Data Engineer - (Remote)  ,KBRA,"Position Title: Senior Python Data Engineer - (Remote) 
Entity: KBRA Holdings LLC
Employment Type: Full-Time
Location: Remote (Remote only in CA, CO, DC, FL, IL, MD, NJ, MA, NY, PA, SC, TX, VA)
Summary/Overview:
KBRA (KBRA Holdings, LLC) is seeking an engaged and proactive Senior Python Data Engineer to work on our financial analytical system. We want someone who loves solving difficult problems, digs deeply to understand the domain in which they’re working, and excels at creating high-quality software in a collaborative environment.
About the Team:
We believe that small, empowered teams can do amazing things. Across the engineering organization, we work hard to make the best systems for our customers using modern engineering practices. We are intentional in our investments in time and effort around creating a safe and successful workplace for our team members. We understand software engineering goes beyond the 1’s and 0’s and prioritize concrete value for our customers.
About the Job:

This role involves joining an existing team with a well-defined product vision. This team operates collaboratively, and there is an expectation to get involved in all aspects of design, delivery, and support of our systems.

This role emphasizes collaboration with our technical and non-technical counterparts to learn our domain and its unique challenges, while delivering value to our customers. It also requires collaboration with our other engineering, design, product, and platform teams to develop, build, run, and support the system.
About You:

You will be successful in this role if you:
Develop, test, and maintain scalable Python applications.
Collaborate with product managers, designers, and other engineers to deliver high-quality software.
Write clean, efficient, and reusable code following best practices.
Participate in code reviews to ensure code quality and share knowledge with the team.
Troubleshoot and debug issues in a timely manner.
Contribute to the design and architecture of new features and systems.
Have a sense of ownership and craftsmanship around the code base and your work.
Enjoy helping other developers grow and learn new technologies.
Display a strong track record of mentorship with engineers at various levels.
Are mindful of application security and performance.
Take pride in learning, and want opportunities to learn throughout your day-to-day.
Possess a pragmatic mindset. 
Familiarity with Generative AI tools such as ChatGPT for research, data insights, and general productivity is a plus.
Must have skills:
3–6 years of professional software engineering experience, with a strong portfolio of full stack development work.
Proficiency in Python, including experience with web frameworks such as Flask.
Cloud experience, particularly with AWS (Amazon Web Services).
Experience integrating frontend applications with RESTful APIs and backend services.
Relational and non-relational databases (SQL Server, Snowflake and MongoDB).
Debugging, issue resolution, and troubleshooting.
Nice to have skills:
Familiarity with UX design tools (Figma) and solid understanding of the design-engineering hand-off process
Containerized development and deployment (i.e. Docker, Docker swarm, Kubernetes)
Infrastructure as Code (Terraform)
Familiarity with deployment pipelines, CICD tools.
Exposure to financial systems or credit modeling is strongly preferred.
Salary Range:
The anticipated annual base salary range for this full-time position is $130,000 - $160,000. Offer amounts are determined by factors such as experience, skills, geography, and other job-related factors.
Benefits:
Competitive benefits and paid time off
Paid family and disability leave
401(k) plan, including employer match (100% vested)
Educational and professional development financial assistance
Employee referral bonus program
About Us:
KBRA is a full-service credit rating agency registered in the U.S., the EU and the UK, and is designated to provide structured finance ratings in Canada. KBRA’s ratings can be used by investors for regulatory capital purposes in multiple jurisdictions.
More Info:
KBRA encourages applications from all qualified individuals without regard to race, color, religion, gender, sexual orientation, gender identity or expression, age, national origin, marital status, citizenship, disability, and veteran status or any other basis prohibited by federal, state or local law.
#LI-KS1
#REMOTE"
2025-12-12T17:19:54,Data Platform Engineer,Dragonfli Group,"Dragonfli Group is a cybersecurity and IT consulting firm providing services to federal agencies and Fortune 100 enterprises. Headquartered in Washington, DC, Dragonfli supports clients in securing mission-critical systems across on-site, hybrid, and fully remote environments.

This contract Data Platform Engineer role supports a large federal agency in protecting security data platforms within a large-scale IT environment. The engineer will manage security data platforms such as Splunk and data lakes, ensuring effective data flows, integrations, and platform support. Key technologies include Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS. The role requires seasoned IT security expertise, hands-on technical skills, and strong communication and planning abilities. It's a high-impact opportunity to shape security analytics capabilities within a major federal agency.

This is a multi-year contract position involving a large US federal agency. Candidates with previous federal contracting experience are preferred. U.S. Citizenship or Permanent Residency required. If hired, all work related to this role must be performed within the continental U.S.

Responsibilities:
Manage security data platforms, such as Splunk and data lakes.
Ensure effective data flows, integrations, and platform support.
Support event ingestion, platform maintenance, and technical add-ons.
Troubleshoot to support operational and compliance reporting.
Optimize data use for security monitoring, incident response, and threat analysis.
Collaborate across teams to enhance security analytics capabilities.
Configure and maintain various event ingestion methods.
Create and maintain custom TAs for data parsing into Splunk CIM format.
Monitor and perform routine maintenance of data systems.
Drive process improvements and attention to detail.

Requirements
Four (4)+ years of experience supporting enterprise data platforms.
BS/BA in a cyber-related field or equivalent experience/certifications.
Experience with installing, updating, and maintaining ELM and SIEM.
Proficiency with Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS.
Experience configuring and maintaining event ingestion methods.
Ability to create and maintain custom TAs for Splunk.
Experience in troubleshooting, monitoring, and maintaining data systems.
Familiarity with enterprise security operations.
Strong cross-functional communication skills.

Skill(s)
Hands-on management of security data platforms.
Expertise in data flows and platform integrations.
Proficiency in Splunk and related technologies.
Strong troubleshooting and problem-solving skills.
Ability to optimize security monitoring and incident response.
Excellent cross-functional communication abilities.
Attention to detail and process improvement mindset.
Ability to work collaboratively across teams.
Strong planning and organizational skills.

Benefits
Insurance – health, dental, and vision
Paid Time Off (PTO) and 11 Federal Holidays
401(k) employer match

Travel
null"
2025-12-12T16:50:01,Staff Configuration Data Engineer,Archer,"Archer is an aerospace company based in San Jose, California building an all-electric vertical takeoff and landing aircraft with a mission to advance the benefits of sustainable air mobility. We are designing, manufacturing, and operating an all-electric aircraft that can carry four passengers while producing minimal noise.
Our sights are set high and our problems are hard, and we believe that diversity in the workplace is what makes us smarter, drives better insights, and will ultimately lift us all to success. We are dedicated to cultivating an equitable and inclusive environment that embraces our differences, and supports and celebrates all of our team members.
What you'll do:
As the Configuration Data Engineer, you will combine software development expertise with configuration management practices to safeguard product data integrity, traceability, and compliance. You will design tools, reports, and automations that enable engineering and product teams to make faster, more accurate configuration decisions.
Develop and maintain tools and reports to monitor bills of materials (BOMs), effectivity assignments, and configuration changes
Create automated quality checks to validate workflows and ensure compliance with configuration management standards
Integrate with Teamcenter APIs and background services to access, analyze, and validate engineering data
Build automation scripts to support NX, CATIA, and other CAD-driven workflows (NX Open, CATIA VB, Check-Mate, NX Check-Mate)
Support the definition, maintenance, and auditing of BOM structures, unit effectivity, and date-based effectivity for engineering changes
Develop dashboards and metrics reporting to provide visibility into change requests, change notices, and configuration status accounting
Collaborate with configuration management, engineering, and IT teams to streamline data flow across systems
Investigate data anomalies and provide corrective recommendations to maintain design and change integrity
Partner with project teams to ensure effectivity assignments are properly implemented and reflected in reports
Contribute to the improvement of enterprise configuration management processes through data-driven insights
Serve as a technical resource to CM specialists for reporting, automation, and API usage
What You Need
To be a self starter with a strong desire to learn new technologies
Ability to translate engineering/CM requirements into automated solutions
2+ years of experience developing tools and reports for a Product Lifecycle Management (PLM) tools (e.g., Teamcenter, Windchill, Enovia, 3DX) or equivalent engineering data environments
Experience with relational databases (SQL, PostgreSQL, Oracle) for reporting and automation
Ability to interpret engineering drawings, CAD data, and metadata
Understanding of BOM structures, unit effectivity, and date-based effectivity methods
Familiarity with engineering change processes, including Change Requests (CRs) and Change Notices (CNs)
Experience with scripting or automation in CAD/PLM environments (NX Open, CATIA VB, or similar)
Strong problem-solving skills and ability to analyze complex datasets for process improvements
Effective written communication skills to document procedures and produce clear reports
Ability to work in a collaborative environment across engineering, CM, and IT teams
Bonus Qualifications
Hands-on experience with Siemens Teamcenter APIs or integrations
Experience with Business Intelligence tools such as Power BI, Sigma, or SAP Hana
Experience with ITI CADIQ tools and CAD data validation workflows
Experience with Elysium CAD Translation tools
Familiarity with NX Check-Mate and automations
Familiarity with ASME Y14.5 Dimensioning and Tolerancing
Experience developing Adobe Forms with JavaScript and PDF publishing workflows
Exposure to aerospace, automotive, or other complex product development environments
Knowledge of configuration management standards and compliance practices (CMII, EIA-649, etc.)
This role is ideal for engineers who enjoy bridging software development with product lifecycle control. You will directly impact how engineering data is managed, ensuring accuracy, efficiency, and compliance across the enterprise
Archer is committed to working with and providing reasonable accommodations to job applicants with physical or mental disabilities, and those with sincerely held religious beliefs. Applicants who may require reasonable accommodation for any part of the application or hiring process should provide their name and contact information to Archer’s People Team at people@archer.com. Reasonable accommodations will be determined on a case-by-case basis.
Information collected and processed as part of any job applications you choose to submit is subject to Archer's Candidate Privacy Policy.
Archer is unable to provide work visa sponsorship for this position at the present time.
Archer is proud to be an Equal Opportunity employer committed to diversity and inclusivity in the workplace. All aspects of employment are decided on the basis of merit, qualifications, and business needs. We do not discriminate based upon race, color, religion, sex, sexual orientation, age, national origin, disability status, protected veteran status, gender identity or any other characteristic protected by federal, state or local laws.
Archer Aviation does not engage with external recruiting agencies/individual recruiters with whom it does not have a prior written agreement. Archer reserves the right to make use of any unsolicited resumes that it receives and bears no responsibility for payment of any fees asserted from the use of unsolicited resumes. If you are a recruiting agency or individual recruiter wishing to do business with Archer, please reach out to People@archer.com. All employment processes are managed by the Archer People Team."
2025-12-12T16:14:31,Data Engineer - Integrated Supply Chain,Textron,"Data Engineers build and maintain data systems in support of data analytics and data science activities. The Data Engineer will implement methods to improve data reliability, data quality, and ensure success in data-driven initiatives.
This position within Integrated Supply Chain Analytics is responsible for identifying, developing, and executing solutions that support reliable and efficient extraction of data from source systems and loading of that data into analytic platforms. The Data Engineer will help administer data platforms and consult with data analysts and data scientists on process optimization and data quality improvements.
At Textron Aviation, we are building a community of Data & Analytics professionals with an emphasis on collaboration and cross functional support. You will have the opportunity to work closely with your peers throughout the organization toward a vision of data driven strategy.


JOB RESPONSIBILITIES:
· Gain core business understanding of Textron Aviation and aircraft design, operation, and support
· Query, clean, transform, and stage data (ETL/ELT) across on-prem and cloud environments
· Support data analytics and data science activities by implementing, maintaining, and optimizing production ready data pipelines
· Install and update software to ensure data platform continuity
· Administer a CI/CD compliant code repository during development and update activities
· Research and help implement new technologies to support analytics function
· Interface with other data professionals throughout the organization to embrace cross functional growth in analytics capabilities
· Work to improve data quality by assisting data governance efforts in creating and maintaining data quality standards
· Plan and execute projects according to established milestones and schedules
· Train users in data & analytic tools and processes per best practices and compliance standards
· Contribute to the resolution of service tickets pertaining to data infrastructure
· Serve as an internal consultant to business leaders by advising on system capabilities
EDUCATION/ EXPERIENCE:
· Bachelor’s degree in Computer Science, Software Engineering, Data Science/Analytics, MIS, or other related technical field
· Minimum 2 years relevant technical experience required, focused on data collection, utilization, and analysis.
· Aviation experience preferred
Textron Aviation Inc. must comply with U.S export control laws and regulations. If a position requires access to sensitive information controlled under these laws and regulations, a successful applicant must be eligible to meet any requirements to access controlled information."
2025-12-12T16:07:56,Senior Data Engineer ,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:55,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:54,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T15:01:13.806,"Software Engineer III, Infrastructure, Audience Data Processing",Google,"MINIMUM QUALIFICATIONS:

 * Bachelor’s degree or equivalent practical experience.
   
 * 2 years of experience with software development in C++, SQL, Borg, Flume, or
   1 year of experience with an advanced degree.
 * 2 years of experience with developing large-scale infrastructure, distributed
   systems or networks, or experience with compute technologies, storage or
   hardware architecture.



PREFERRED QUALIFICATIONS:

 * Master's degree or PhD in Computer Science or related technical fields.
   
 * 2 years of experience with data structures and algorithms.
 * Experience with Flume and large scale data processing pipelines.
 * Experience developing accessible technologies.
   


ABOUT THE JOB:

Google's software engineers develop the next-generation technologies that change
how billions of users connect, explore, and interact with information and one
another. Our products need to handle information at massive scale, and extend
well beyond web search. We're looking for engineers who bring fresh ideas from
all areas, including information retrieval, distributed computing, large-scale
system design, networking and data storage, security, artificial intelligence,
natural language processing, UI design and mobile; the list goes on and is
growing every day. As a software engineer, you will work on a specific project
critical to Google’s needs with opportunities to switch teams and projects as
you and our fast-paced business grow and evolve. We need our engineers to be
versatile, display leadership qualities and be enthusiastic to take on new
problems across the full-stack as we continue to push technology forward.

As a Software Engineer on the Audience Data Processing Infrastructure team, you
will innovate and optimize planet-scale data processing flows to support Google
Ads.

While we're an infrastructure team, we operate in a fast-paced environment with
evolving requirements. Our focus is on supporting client data processing needs,
enhancing operational excellence and developer velocity, and significantly
improving resource efficiency.


Google Ads is helping power the open internet with the best technology that
connects and creates value for people, publishers, advertisers, and Google.
We’re made up of multiple teams, building Google’s Advertising products
including search, display, shopping, travel and video advertising, as well as
analytics. Our teams create trusted experiences between people and businesses
with useful ads. We help grow businesses of all sizes from small businesses, to
large brands, to YouTube creators, with effective advertiser tools that deliver
measurable results. We also enable Google to engage with customers at scale.

The US base salary range for this full-time position is $141,000-$202,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Write product or system development code in C++ for infrastructure
   responsible for managing and optimizing processing of planet-scale data
   processing.
 * Investigate data storage and processing use cases, techniques, and
   identifying opportunities for future innovation.
 * Review code developed by other developers and provide feedback to ensure best
   practices (e.g., style guidelines, checking code in, accuracy, testability,
   and efficiency).
 * Contribute to existing documentation or educational content and adapt content
   based on product/program updates and user feedback.
 * Triage product or system issues and debug/track/resolve by analyzing the
   sources of issues and the impact on hardware, network, or service operations
   and quality."
2025-12-12T13:26:27,Cleared On Site Data Engineer (4899),SMX,"SMX is seeking a Senior Data Architect to provide strategic and technical leadership for enterprise data architecture and analytics modernization efforts. This individual will design, optimize, and oversee data solutions that enable advanced analytics, business intelligence, and reporting capabilities across multiple secure environments. This role will focus on designing, developing, optimizing, and maintaining data pipelines and backend data engineering solutions that power critical analytical products used by senior FBI leadership. The ideal candidate brings deep technical expertise in ETL processes, SQL, Python, AWS data services, and enterprise-scale data warehousing, with strong familiarity in BI ecosystems such as MicroStrategy (Strategy), ThoughtSpot, and related tools used within the HR Reports program. The position requires close collaboration with government leads, senior data developers, BI engineers, and cross-functional analytics teams to ensure high reliability, performance, and security of data products supporting mission-critical operations. 
This is a full-time position requiring on-site work five days a week at a client’s office in Washington, D.C. An active Top Secret clearance is mandatory.
Essential Duties and Responsibilities: 
Design, build, and maintain scalable, secure ETL/ELT pipelines supporting HR Reports analytics and dashboard products.
Develop and optimize SQL-based transformations, stored procedures, and data models for high-volume enterprise datasets.
Implement data orchestration workflows using AWS services (e.g., Glue, Lambda, Step Functions, CloudWatch).
Ensure data quality, lineage, and integrity across multiple enterprise data sources.
Support and enhance cloud-based warehouse environments within AWS (e.g., Redshift, S3, IAM).
Collaborate with BI developers to ensure backend data structures meet MicroStrategy/Strategy and ThoughtSpot reporting needs.
Troubleshoot complex data pipeline or performance issues and implement long-term remediation solutions.
Translate government stakeholder requirements into technical specifications for new data sources and pipelines.
Partner with Data Analysts, Data Scientists, and BI Developers to support advanced analytics and ad-hoc data requests.
Apply data governance, security, and compliance best practices in alignment with FBI and SMX standards.
Recommend and implement improvements to automation, data architecture, pipeline reliability, and overall performance.
Maintain documentation for pipelines, logic, data flows, and system dependencies.
Stay current with modern data engineering practices and AWS service enhancements relevant to pipeline automation and warehousing.
Required Skills: 
10+ years of experience in data architecture, data warehousing, or enterprise analytics systems.
Expert-level proficiency in SQL and data modeling
Hands-on experience designing and implementing ETL/ELT frameworks (e.g., Apache Airflow, dbt, AWS Glue, Informatica).
Demonstrated success architecting and optimizing large-scale BI/reporting solutions (MicroStrategy, ThoughtSpot, Power BI, Tableau).
Strong knowledge of AWS data ecosystem (Redshift, Athena, S3, Glue, Lambda) or similar cloud environments.
Experience defining and enforcing data governance, quality, and security standards.
Ability to design and document end-to-end data flows and integrations between transactional and analytical systems.
Excellent communication, analytical, and problem-solving skills.
Desired Skills/Experience:
Bachelor’s or Master’s degree in Computer Science, Information Systems, Data Engineering, or related technical field.
10+ years of experience in data engineering, backend data development, or enterprise-scale ETL development.
Experience supporting federal government IT systems or analytics programs.
Familiarity with Agile methodologies and Jira-based workload management.
Experience supporting or modernizing enterprise BI ecosystems.
**This position requires five days a week on site at customer location in Washington DC.
Application deadline 1-16-2026
#LI-SA
#cjpost
The SMX salary determination process takes into account a number of factors, including but not limited to, geographic location, Federal Government contract labor categories, relevant prior work experience, specific skills, education and certifications. At SMX, one of our Core Values is to Invest in Our People so we offer a competitive mix of compensation, learning & development opportunities, and benefits. Some key components of our robust benefits include health insurance, paid leave, and retirement.
The proposed salary for this position is:
$114,600—$192,500 USD
At SMX®, we are a team of technical and domain experts dedicated to enabling your mission. From priority national security initiatives for the DoD to highly assured and compliant solutions for healthcare, we understand that digital transformation is key to your future success.
We share your vision for the future and strive to accelerate your impact on the world. We bring both cutting edge technology and an expansive view of what’s possible to every engagement. Our delivery model and unique approaches harness our deep technical and domain knowledge, providing forward-looking insights and practical solutions to power secure mission acceleration.
SMX is an Equal Opportunity employer including disabilities and veterans.
Selected applicant may be subject to a background investigation and/or education verification.
SMX does not sponsor a new applicant for employment authorization or immigration related support for this position (i.e. H1B, F-1 OPT, F-1 STEM OPT, F-1 CPT, J-1, TN, E-2, E-3, L-1 and O-1, or any EADs or other forms of work authorization that require immigration support from an employer)."
2025-12-12T12:29:19.508,"Data Center Plant Engineer, Mechanical, Electrical",Google,"MINIMUM QUALIFICATIONS:

 * Associate's degree, trade school certification, or other certified training
   in a related technical field, or equivalent practical experience.
 * 7 years of experience in electrical, mechanical/HVAC, or controls/automation
   experience in an industrial or commercial environment.



PREFERRED QUALIFICATIONS:

 * Experience working in data centers, hospitals, or power plants.
 * Knowledge of electrical and mechanical systems used in a data center
   environment (e.g., Feeders, Transformers, Generators, Switchgear, UPS
   systems, ATS/STS units, PDU/PMM units, Chillers, Air handling units, and CRAC
   units).
   
 * Knowledge of meters, devices, sensors, and troubleshooting utilizing standard
   hand tools, digital metering, or calibration/diagnostic equipment.
   
 * Ability to communicate with contractors who perform maintenance or upgrade
   work on the data center systems.
   


ABOUT THE JOB:

The Data Center team designs and operates some of the most sophisticated
electrical engineering, mechanical engineering and HVAC systems in the world.
Facilities Technicians at Google data centers operate, monitor and support
physical facilities conditions. Some of these duties will include heating and
cooling of air and water, power supply, generators, UPS systems, electrical
distribution and control and monitoring systems. You regularly help inspect,
maintain and repair various data center systems such as piping and non-critical
electrical or mechanical system components). You provide daily assistance to
senior technicians as you read blueprints/schematics, conduct tours of systems
and assess their working order.

As a master of exceptional practices, you develop creative approaches to
reducing operational costs while improving overall data center efficiency. You
ensure that environmental and safety standards are consistently met, identifying
problems and making repairs quickly In emergency situations or abnormal
conditions, you manage data center performance issues and outages to minimize
the recovery time from failures.The AI and Infrastructure team is redefining
what’s possible. We empower Google customers with breakthrough capabilities and
insights by delivering AI and Infrastructure at unparalleled scale, efficiency,
reliability and velocity. Our customers include Googlers, Google Cloud
customers, and billions of Google users worldwide.

We're the driving force behind Google's groundbreaking innovations, empowering
the development of our cutting-edge AI models, delivering unparalleled computing
power to global services, and providing the essential platforms that enable
developers to build the future. From software to hardware our teams are shaping
the future of world-leading hyperscale computing, with key teams working on the
development of our TPUs, Vertex AI for Google Cloud, Google Global Networking,
Data Center operations, systems research, and much more.

The US base salary range for this full-time position is $105,000-$151,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Inspect, maintain, and repair various data center systems such as piping and
   non-critical electrical or mechanical system components.
   
 * Provide daily assistance to technicians as you read blueprints/schematics,
   conduct tours of systems, and assess their working order.
   
 * Manage the uptime and maintenance of water pumps and treatment systems, HVAC,
   UPS, generators, electrical distribution, and control and monitoring systems.
   
 * Operate, monitor, maintain, and respond to abnormal conditions in the data
   center facilities systems and equipment.
   
 * Support startup, commissioning, and integration of new equipment and systems
   into facilities infrastructure.
   "
2025-12-12T09:01:55.769,Data Engineer II,Microsoft,"Overview
With continued growth in digital data and the desire to leverage data to measure in-production quality and address problems that touch all aspects of our lives, Microsoft’s Windows Servicing & Delivery Org is looking for an equally data- and quality-minded engineer to meet these challenges! Join the Update Platform team for the chance to have an impact on billions of customers every day. The Update Platform Team is responsible for ensuring the seamless delivery and integration of software updates and keeping our customers up-to-date and secure at all times.
As a Data Engineer II member of the Update Platform Insights team, you will be at the forefront of leveraging data to assess the quality of the product, detect issues before they reach broad customer application to assure top product quality for partners and customers alike while keeping billions of devices secure and up-2-date.

In this exciting role, you'll work with a diverse group of talented professionals, innovate for greater platform efficiency as well as leveraging the latest technologies and best practices to streamline our update processes with timely in-depth insights and intelligent features.

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.


Responsibilities
Data Management and Transformation: With guidance, you will apply modification techniques to transform raw data into compatible formats for downstream systems. Utilize software and computing tools to ensure data quality and completeness. Implement code to extract and validate raw data from upstream sources, ensuring accuracy and reliability.
Drive Customer Success: Through Data and Business Insight: You will play a pivotal role in building a metrics-driven culture that directly impacts product quality and customer outcomes. This role goes beyond technical execution—you will design and implement measurement frameworks from the ground up while applying a strategic, top-down perspective to ensure the right metrics are in place. Your ability to translate data into actionable insights, aligned with business priorities and rhythm of business, will enable informed decisions that drive high-quality product outcomes and measurable customer success.

Data Requirements and Modeling: Collaborate with stakeholders to document and understand data requirements. Evaluate project plans to assess data costs, access, and availability. Draft design specifications to model data flow and storage, ensuring data is easy to connect and manage.
Compliance: You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams. You’ll also learn about permissions and approvals for data access within a data pipeline.

Validation and Quality Mindset: Apply and use operational fundamentals to validate and ensure quality of the product as well as the underlying data pipeline and assets to secure trustworthiness in your data daily.

Customer Focus: Be driven by a focus on customer happiness and success. We as a team only succeed if our customers are secure and protected via the updates we deliver.


Qualifications
Required Qualifications:
Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 1+ year(s) experience in business analytics, data science, software development, data modeling, or data engineering
OR Bachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 2+ years experience in business analytics, data science, software development, data modeling, or data engineering
OR equivalent experience.
Other Requirements:
Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include but are not limited to the following specialized security screenings:
Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.
Preferred Qualifications:
3+ years with scripting and coding languages with a focus on data engineering, like SQL, KQL, python, Scope, C# (or similar object-oriented languages) and others.
1+ years of experience with building large data processing frameworks using technologies like Azure Data Factory, Azure Data Explorer, PowerBI and/or other public and Microsoft internal tools.
1+ years of experience in analytics to define, monitor, and optimize key performance indicators (KPIs) and connected business metrics that ensure measurable customer success.
1+ years of proven ability to orchestrate and sustain a data-driven rhythm of business, transforming insights into actionable strategies that align with organizational priorities and deliver impactful outcomes.
A solid quality mindset with the ability to deliver end-to-end data solutions that build partner and customer confidence, ensuring alignment with business objectives and measurable outcomes.
Experience with Git, ADO or equivalent Source Control Systems.
Experience with data visualization tools and how to effectively communicate Insights to consumers of varying types of audiences.
Experience leveraging AI to define and evaluate quality standards


Data Engineering IC3 - The typical base pay range for this role across the U.S. is USD $100,600 - $199,000 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $131,400 - $215,400 per year. 
Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:
https://careers.microsoft.com/us/en/us-corporate-pay

This position will be open for a minimum of 5 days, with applications accepted on an ongoing basis until the position is filled.


Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance with religious accommodations and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations."
2025-12-12T01:54:02.588,"Data Science Engineer, New College Grad- Master's/PhD (Santa Clara, CA)",Applied Materials,"Assist in developing data science software prototypes and interfaces for monitoring semiconductor process tools Develop Python scripts to implement key concepts Collaborate closely with algorithm developers to characterize the algorithms and benchmark their performance, collecting quantitative data assessing effectiveness Evaluate the effectiveness and accuracy of the algorithms by working closely with process and equipment experts, providing feedback to algorithm developers Provide solutions which can be implemented by engineers without a deep statistical or mathematical background Deploy and maintain solutions at service sites Troubleshoot solutions, provide workarounds, and assist users in using solutions Assess effectiveness of solutions and provide data science insight Communicate well with algorithm developers and process experts Train field engineers to use solutions Present work and conclusions clearly and succinctly to peers Work well in team, providing and receiving constructive input with team members Monitor and quantify the results of complex algorithms in a production environment. Train a variety of individuals on the operation of these algorithms. Experience with various Artificial Intelligence Solutions, including Large Language Models, Computer Vision and Generative AI applications. Python, MATLAB Familiarity with common data science techniques, including regression, decision trees, Principle components, PLS, various Neural networks, time-series techniques, Bayesian techniques, etc. Ability to troubleshoot software applications and perform basic DevOps for deployment Ability to interact with Process and Customer Engineers Semiconductor process or equipment experience preferred. Demonstrates depth and/or breadth of expertise in own specialized discipline or field May lead small functional teams or projects with moderate resource requirements, risk, and/or complexity Communicates difficult concepts and negotiates with others to adopt a different point of view Master's or PhD in Computer Science, Data Science, Software Engineering, Mechanical Engineering, or related field. Preferred GPA of 3.0 or above"
2025-12-12T01:52:09.253,"Vice President, Data Engineer",BNY,"Bachelor's or master's degree in computer science or a related discipline, or equivalent work experience is required. 10+ years of data modeling, database design and development or related experience is required. Prior experience in managing DB development team Experience modeling Financial data Prior experience modeling Client and Entitlement Data Good knowledge of Financial Accounts, Transactions and Positions data Hands-on experience with any RDBMS, preferably MS SQL Server or Oracle Good SQL knowledge Excellent communication skills Good Problem Solving & Analytical Skills Work experience in Financial Services Work experience on any data modeling tool, viz. Erwin, DBArtisan etc. Experience with writing ANSI SQL code Prior Experience with a scripting language, preferably Python Experience working with Cloud native databases Bachelor's or Master's degree in Computer Science or a related discipline, or equivalent work experience is required. Advanced degree is preferred. Experience in the Securities or Financial Services industry."
2025-12-12T01:08:33,Data Analytics Engineer,Masimo,"The Data Analytics Engineer will support Masimo’s Quality organization by developing dashboards, performing data analysis, and transforming large datasets into meaningful insights. This role partners closely with Quality Compliance, Product Assurance, Engineering, Operations and cross-functional stakeholders to enhance data visibility, drive data-informed decisions, and support continuous improvement across the organization. The ideal candidate is technically strong in analytics tools, comfortable working with structured and unstructured data, and eager to grow in a fast-paced and evolving environment.
Duties & Responsibilities
Develop and maintain Power BI dashboards and reports that translate complex data sets into clear, actionable information.
Perform data transformation and modeling using SQL, Power Query (M), and DAX to support quality metrics, KPIs, and trend analysis.
Support routine and ad-hoc data analytics requests related to customer feedback, failure analysis, operations, and compliance activities.
Analyze large datasets to identify trends and process improvement opportunities.
Collaborate with Quality Compliance, Product Assurance, and cross-functional engineering teams to ensure data accuracy, consistency, and alignment with business needs.
Communicate findings through effective data storytelling, written summaries, and monthly presentations to cross functional leaders across the organization.
Contribute to continuous improvement efforts in reporting automation, dashboard optimization, and analytics best practices.
Minimum & Preferred Qualifications and Experience
Experience
0–2+ years of experience in data analytics, business intelligence, or engineering analytics; internship or project experience considered.
Hands-on experience with SQL and Power BI (including Power Query/M and DAX).
Experience using Python or R for data manipulation, modeling, or visualization preferred.
Familiarity with data visualization tools (Power BI highly preferred; Tableau or Looker a plus).
Understanding of statistics, data modeling, or quantitative analysis techniques.
Skills & Competencies
Strong analytical and problem-solving skills with high attention to detail.
Ability to translate data into clear insights for technical and non-technical partners.
Strong verbal, written, and visual communication skills, with the ability to present confidently and engage diverse audiences.
Ability to work independently and in a team environment.
Curiosity and willingness to learn new tools, systems, and techniques.
Education
Bachelor’s degree in Data Analytics, Data Science, Business Intelligence, Computer Science, Engineering, or a related field required.
Master’s degree in a relevant field is a plus but not required.
Compensation:
The anticipated salary range for this position is $90,000 - $110,000 plus benefits. Actual placement within the range is dependent on multiple factors, including but not limited to skills, education, and experience. 
This position also qualifies for up to 10% annual bonus based on Company, department, and individual performance. 
Masimo offers benefits such as Medical, Dental, Vision, Life/AD&D, Disability Insurance, 401(k), Vacation, Sick, Holiday, Paid Maternity Leave, Flexible Spending Accounts, Voluntary Accident, Critical Illness, Hospital, Long-Term Care, Employee Assistance Program, Pet Insurance, On-site wellness clinic, fitness center, and cafe. All benefits are subject to eligibility requirements."
2025-12-12T00:39:10,Data Engineer,HealthPartners/GHI,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:39:10,Data Engineer,HealthPartners,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:14:05.56,Sr. Data Engineer,Apple,"As a Data Engineer on the Capacity Engineering team, you will help design,
build, and operate the data foundation that drives capacity, cost, and
power-related decisions across Apple’s infrastructure footprint. In this role,
you will: Architect, implement, and maintain large-scale batch and streaming
pipelines that ingest, process, and model infrastructure telemetry, cost,
metering, utilization, forecasting, and power metrics from multiple clouds and
bare metal environments. Design and evolve robust data models (with a strong
focus on dimensional modeling) and storage patterns that support analytics,
internal billing, and efficiency use-cases. Treat data as a product: define
quality checks, SLAs, and observability to ensure data is accurate, timely, and
trusted by stakeholders across Apple. Integrate and enrich raw signals with
metadata and attribution to power use cases such as internal billing/showback,
usage understanding, efficiency and optimization, clawbacks, planning, and
procurement. Collaborate closely with data scientists, software engineers,
platform teams, finance partners, program managers, and leadership to translate
requirements into scalable, reliable data solutions and services. Implement
standard methodologies for data governance, lineage, metadata management, and
security, in alignment with Apple’s standards for data protection and privacy.
Build end-to-end data solutions that include logging, anomaly detection, data
validation, cleaning, and transformation, with strong emphasis on monitoring,
debuggability, and continuous improvement. Contribute to the evolution of our
data and platform stack, including tooling, frameworks, and standards for
development, testing, deployment, and operations (CI/CD, infrastructure as code,
etc.).


DESCRIPTION


Apple’s Capacity data engineering team, within the Apple Services Engineering
organization, is building the centralized data backbone that powers how Apple
understands, plans, and optimizes its cloud and data center infrastructure. We
engineer a unified, trusted data lake that consolidates cost, metering,
utilization, forecasting, and power metrics produced by Apple platforms and
systems (including bare metal) across both third-party and Apple internal
clouds. Enriched with metadata and attribution, this becomes the single source
of truth for internal billing, understanding usage and utilization, clawbacks,
planning, procurement, and efficiency initiatives. We collaborate with platform
engineering, finance, capacity engineering, and leadership teams to build
large-scale data pipelines, enable descriptive and predictive analytics, and
power dashboards and products that support critical business decisions. This is
your opportunity to help design and operate highly visible, global-scale systems
processing petabytes of data and supporting hundreds of users across Apple. Come
join us to help deliver the next generation of infrastructure insights at Apple.


MINIMUM QUALIFICATIONS


Bachelors degree or equivalent experience in Computer Science, Information
systems, Software Engineering, Data Science or related field. Advanced degree in
a related field a plus. 5+ years of experience in data engineering (or
equivalent practical experience), including: Building and maintaining
large-scale ETL/ELT data pipelines Distributed computing (e.g., Spark / PySpark)
for data processing and automation Query performance optimization and tuning at
scale Hands-on experience with: Apache Spark and Airflow (or similar
workflow/orchestration tools) for efficient large-scale data pipelines Data
modeling, especially dimensional modeling, and designing schemas optimized for
analytics and reporting Big data platforms and/or data lake architectures


PREFERRED QUALIFICATIONS


Experience with cloud technologies, specifically AWS (e.g., S3, EMR, Lambda,
Glue, RDS/Redshift, or similar services) Tooling & ecosystem: Experience with
CI/CD tooling such as Jenkins (or similar tools) Experience with data
visualization / BI tools, such as Superset or Tableau (other tools like
QuickSight, QlikView, Cognos, or Business Objects are a plus) Experience with
containerization and orchestration, such as Docker and Kubernetes/EKS is a plus
Understanding of authentication and authorization (AuthN/AuthZ) patterns
Knowledge of data governance principles, data security best practices, and data
privacy regulations"
2025-12-12T00:00:00,Lead Data Engineer,Nuna,"At Nuna, our mission is to make high-quality healthcare affordable for everyone. We are dedicated to tackling one of our nation’s biggest problems with ingenuity, creativity, and a keen moral compass.
Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why.
Nuna has established its brand in the B2B space over the last decade by shifting the US healthcare system towards an incentive model that rewards healthcare providers for positive outcomes. Marshalling our collective backgrounds and insights, we are now crafting an innovative, consumer app - a clinically driven healthcare companion experience that leverages AI, gamification and social support techniques to improve outcomes for people with chronic conditions.
As a sign of the impact Nuna has already made in this space, Nuna was recently selected to join the Centers for Medicare & Medicaid Services (CMS) Health Tech Ecosystem, a landmark public-private initiative designed to transform healthcare for Americans.
YOUR TEAM
The Data org at Nuna is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research.
The Data Engineer team is a core part of the broader Data organization, which is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research. The Data Engineer team acts as the technical backbone for data architecture, platform development, and data operations, empowering the organization to deliver impactful data-driven solutions in healthcare.
YOUR OPPORTUNITIES
We are looking for someone who is excited to use their creativity and engineering skills to make a difference in healthcare. You will have a foundational role on a team building a consumer product that incentivizes healthy behavior. You will be responsible for the data architecture and direction of the data platform that powers our data operations and data science initiatives.
Own the architecture and evolution of the data platform, based on business needs and considering trade-offs in timelines, cost, and resources
Define and enforce standards for code development, contribution, and deployment for data engineering workflows.
Oversee integrations with external services, including data ingestion, distribution, and service-to-service data flows.
Contribute hands-on to data transformations and optimizations
Establish security, governance, and operational best practices for the data platform in collaboration with security and enterprise data engineering teams.
Curate and develop datasets needed to support Data org project deliverables
Collaborate with cross-functional partners in engineering, design, and product to develop solutions
Generate and prioritize new opportunities for improvements
Provide build vs buy assessments and recommendations as the platform expands
QUALIFICATIONS
Required Qualifications
Deep hands-on expertise in designing, coding, developing, and maintaining data platforms that support data analytics and data science use cases
Proven ability to design, develop and implement robust data ingestion pipelines (ETL) from external sources into a data platform.
Experience establishing standards for code development, deployment, and contributions in a data engineering environment.
Ability to solicit and translate customer and business needs into requirements and an evaluation framework
Interest in improving healthcare and working with interdisciplinary project teams
Clear communication and presentation skills
Experience with Databricks
Expertise in data platform languages such as python, pyspark and SQL
+ 5-10 years of industry experience with technical lead experience of running a data platform for business operations
Preferred Qualifications
MS in quantitative field (e.g. Data Science, Economics, Statistics, Engineering)
Experience building a data platform from zero to one
Experience working with healthcare data
Experience with SDLC and management of machine learning models (MLOps)
Bonus points if experience with MLOps on LLM/GenAi features (evals, context building, …)
We take into account an individual’s qualifications, skillset, and experience in determining final salary. This role is eligible for health insurance, life insurance, retirement benefits, participation in the company’s equity program, paid time off, including vacation and sick leave. The expected salary range for this position is $208,000 - $260,000. The actual offer will be at the company’s sole discretion and determined by relevant business considerations, including the final candidate’s qualifications, years of experience, and skillset.
Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status.
#LI-FK1"
2025-12-12T00:00:00,Development Project Engineer (Data Center Construction),QTS Data Centers,"Who we are: It's pretty exciting to find yourself standing in a pivotal moment in time. It’s even more exciting to be out front leading it. At QTS, our world-class data centers are supporting our customers’ most strategic growth initiatives, positioning us at the forefront of today’s dynamic digital transformation. As AI and cloud drive the demand for increased speed, capacity and capability, QTS has emerged as the global digital infrastructure leader, committed to connecting the world for good. Driven by purpose and fueled by a spirit of innovation, QTS designs, builds and operates some of the world’s most advanced, forward-thinking data centers. QTS is a portfolio company of Blackstone. QTS is Powered by People. People who play a vital role in our company’s culture, innovation and growth. People who are committed to contributing to the communities where we operate and work. People who are knowledgeable, resourceful and mission driven. Together, we do great things. Who You Are: The Development Project Engineer (Data Center Construction) is primarily responsible for assisting with the design, preconstruction and construction activities on a given project(s). The Development Project Engineer will interact on a daily basis with Facilities, Contractors, Designers, Engineers, Commissioning Agents, Vendors, and Data Center Operations & Corporate real estate staff and should have both written and oral communication skills commensurate with this level of regular communication. What You Will Do: Assist Development leadership and Project Manager with day to day activities and responsibilities Assist with multiple projects on a campus(es) and maintain updated budgets, schedules, and status reports for each Assist with updates on development program & project status on a monthly basis suitable for executive level reviews. Work with QTS stakeholders, design, and construction teams to help with master development program for site(s), including a complete campus design solution and capital budget. Assist with entitlement and permitting needs for each assigned site project(s) Assist with scopes of work for design, construction, commissioning services & participate in procurement and project cost estimates Evaluate and level pricing proposals for design, construction, and commissioning services Work closely with strategic procurement team on equipment procurement and delivery process Ensure appropriate submittals are coordinated with site stakeholders Assist with monitoring project budget / cost-to-date against overall project budget. Review project schedules and manage teams to on-time completion Review change order requests from contractors and negotiate pricing Assist with establishing site construction security procedures in conjunction with site security team Establish and maintain relationships serving as liaison with key QTS stakeholders Represent QTS Interests in OAC meetings Create & build relationships that enhance QTS’s ability to be a leader in creating the World’s Most Valuable Data Center Real Estate Aid in due diligence efforts on an as-needed basis by participating with real estate efforts on potential or new land banks and properties, including: Evaluate opportunities to design & build new data centers by working with key stakeholders: Corporate Real Estate, Connectivity, Power & Construction teams. Assist with establishing and monitoring entitlement and permit processes for individual projects as needed Work with the internal development team to enhance project management processes and protocols What You Will Need to be Successful (basic qualifications): Bachelor’s degree in Engineering or Construction Management field or equivalent professional experience Experience with Microsoft Office suite, specifically PowerPoint for use in communicating program updates to executive level, and Excel to create and maintain site program & individual project budgets Excellent interpersonal skills with the ability to interface with all levels of the organization Must be a capable, proven team player that both fosters and operates well within internal and external team environments. Able to solve problems at a tactical and functional level Strong Verbal and Written Communication Skills Ability to manage multiple projects simultaneously Other Key Skills: One or more years of professional experience in commercial construction practices and procedures, including management of Lump Sum, Construction Management @ Risk, and Design Build project delivery methods from conceptual development through procurement to close out Documented experience using AutoCAD, BlueBeam, P6, and CxAlloy Experience or exposure in mission critical data center facilities Experience with management of MEP trades Experience managing document control for active data center build sites The Perks (and these are just a few!): Q-Rest Sabbatical Employee Stock Purchase Plan QTS scholarship for dependents Eagle Club Award Trip Eligibility Paid Volunteer and Floating days Tuition Assistance, Parental Leave and Military Leave Assistance We conform to all the laws, statutes, and regulations concerning equal employment opportunities and affirmative action. We strongly encourage women, minorities, individuals with disabilities and veterans to apply to all of our job openings. We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, gender identity, or national origin, age, disability status, Genetic Information & Testing, Family & Medical Leave, protected veteran status, or any other characteristic protected by law. We prohibit retaliation against individuals who bring forth any complaint, orally or in writing, to the employer or the government, or against any individuals who assist or participate in the investigation of any complaint or discrimination claim. The ""Know Your Rights"" Poster is included here: Know Your Rights (English) Know Your Rights (Spanish) The pay transparency policy is available here: Pay Transparency Nondiscrimination Poster-Formatted QTS is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please send an e-mail to talentacquisition@qtsdatacenters.com and let us know the nature of your request and your contact information. It’s exhilarating to find yourself at a pivotal moment in history— and even more so to be leading the way. At QTS Data Centers, we are proud to stand at the forefront of today’s dynamic digital transformation. Our world-class data centers empower our customers’ most strategic growth initiatives, positioning us as a global leader in digital infrastructure. As AI and cloud technologies fuel the demand for increased speed, capacity, and innovation, QTS has emerged as the global digital infrastructure leader. We are committed to connecting the globe for good. Driven by purpose and a spirit of innovation, we design, build, and operate some of the most advanced data centers worldwide. In addition to our cutting-edge technology, we are dedicated to sustainability, incorporating renewable energy solutions to minimize our environmental footprint and drive meaningful impact. As a proud portfolio company of Blackstone, QTS is uniquely positioned to achieve ambitious growth and innovation goals. At QTS, we are Powered by People. Our team members are the cornerstone of our culture, innovation, and growth. They are mission-driven, resourceful, and committed to making a positive impact in the communities where we live and work. Together, we’re achieving remarkable things and shaping the future of digital infrastructure. And we’d like to invite you to join us. In addition to a variety of benefit packages, QTS goes above and beyond for our employees: Roth and Traditional 401(k) matching contributions with immediate vesting Every employee is bonus or commission eligible Generous PTO, Paid Volunteer Days Plus Floating Holidays Stock Purchase Plan (SPP) 11 paid Holidays Annually/Holiday compensation when worked Pet and Legal Insurance Q-Rest Sabbatical Program Q-Anniversary Service Award Program Parental Leave for primary and secondary caregivers Military Benefits Package QTS Charitable Matching Gift Program QTS Scholarship for Employee Dependents QTS Crisis Fund Wellness Program Tuition Reimbursement Program"
2025-12-12T00:00:00,"Data Engineer I, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $109,300.00 - $180,200.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data across the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape by designing, building, and deploying data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning, and business intelligence initiatives. You will work closely with Data Science and Decision Science teams to build, test, and maintain data pipelines and model workflows that support both analytical research and production use cases in our Databricks/AWS/Snowflake environment. In addition to your strong analytical mind, you will bring an inquisitive attitude and the ability to translate the stories found in data into actionable insights while contributing to technical discussions and process improvements. Applicants must be authorized to work for ANY employer in the U.S. The company does not sponsor/support H-1B petitions, TN, or Forms I-983/STEM OPT, for this role. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions. Design data solutions. Analyze sources to determine value and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Collaborate within and across teams to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate. Test data movement, transformation code, and data components. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent. Six years of related experience. Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions. Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on. Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems. Strong verbal and written communication skills with the ability to interact with team members and business partners. Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Four years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,"Senior Data Engineer, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $139,400.00 - $230,000.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions. Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies. Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate. Collaborate across team to support delivery and educate end users on complex data products/analytic environment. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent Ten years of related experience Primary Job Requirements: Architect and design scalable, secure data solutions using AWS, Databricks, and Ab Initio. Lead technical direction for data engineering initiatives across cloud and on-premises infrastructure. Hands-on development: build ETL pipelines, optimize Spark jobs, and create Ab Initio graphs. Troubleshoot production issues and provide technical guidance to junior engineers. Conduct mentoring sessions and offer technical guidance to the 20-person admin team. Collaborate with DBA teams, business analysts, and QA teams to ensure data governance and quality. Manage infrastructure deployment and optimize cloud resources. Lead technical design reviews and architecture discussions. Implement data integration solutions and ensure compliance with data protection regulations. Establish and enforce coding standards, best practices, and data governance policies. Technical Skills: AbInitio: Expert proficiency with GDE, Co>Operating System, EME, BRE, Express>It, metaprogramming (PDL) Programming: Python, PySpark, SQL Cloud: AWS architecture and services Databricks: Workspace management, cluster configuration, Delta Lake, Unity Catalog Data Warehousing: Strong understanding of data modeling, dimensional modeling (star/snowflake schemas) ETL/ELT: End-to-end ETL development lifecycle Version Control: Git, CI/CD pipelines Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices. Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems. Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers. Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize. Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas. Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Five years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,Data Flow Engineer,Scientific Research Corporation,"Description
The Data Flow Engineer will be a member of a Cryptologic Carry-On Program (CCOP) and Ship’s Signals Exploitation Equipment (SSEE) Systems Engineering team primarily responsible for ensuring the processing and distribution of data to and from intelligence community networks. The ideal candidate will have a history of direct involvement with successful NiFi data flow engineering and resolving Navy hardware and software functionality problems by providing a high degree of timely customer service and technical expertise in support of the US Navy information warfare community.
Installing, configuring, integrating, and maintaining NiFi servers and processors into new or existing system architectures
Verifying and maintaining all NiFi processors and flows to and from deployed (and test) systems, from the field system through customer back-end repositories
Assisting end users with the operational readiness and configuration of deployed systems for optimal data flow to satisfy customer requirements
Designing and developing NiFi processors and flows for deployed systems, containing multiple subsystems and requiring integration with external networks
Implementing expression language in NiFi processors in response to emerging customer requirements
Exhibiting developed verbal and written communication skills and the ability to express concepts and ideas in a clear and concise manner; employing technical writing techniques
Performing as a team player, dedicated to the endeavors of the mission, the customer, and the team itself
Being a self-starter who is accountable and requires minimal direction and supervision; capable of multitasking and working several complex and diverse tasks with simultaneous or near simultaneous deadlines
#LI-LL1
Requirements
Must possess an active TS/SCI clearance and be able to obtain a CI Polygraph
Requires a bachelor’s degree in related technical field or equivalent work experience
Intermediate Linux Command Line Interface (CLI) experience
1-3 years of Apache Niagara Files (NiFi) experience (negotiable with other qualifications)
Strong background in using and troubleshooting Software Defined Radio (SDR) systems
Fundamental knowledge of wireless protocols in common use
Experience providing technical support to customers over Internet Relay Chat (IRC) or similar applications
Familiarity with back-end databases and repositories
Must be willing to travel up to 10% of the year
Must currently be DoD 8570-compliant with the equivalent of an IAT II certification or have the ability to do so within 6 months of employment
Desired Skills
Current Linux+/LPIC 1 and/or Network+ certification
Familiarity with Regular Expression (REGEX), Cisco Networking, and Amazon Web Services (AWS)
Expert-level SDR knowledge and experience
Experience with strategic-level intelligence processes
Basic computer programing experience (i.e. Python, JavaScript, bash)
Prior Navy CTR/CTM/CTN with shipborne, expeditionary, or other comparable experience 
Clearance Information
SRC IS A CONTRACTOR FOR THE U.S. GOVERNMENT. THIS POSITION WILL REQUIRE U.S. CITIZENSHIP AS WELL AS A U.S. GOVERNMENT SECURITY CLEARANCE AT THE TOP SECRET / SCI LEVEL with CI POLY ELIGIBILITY
Travel Requirements
up to 10% travel may be required
About Us
Scientific Research Corporation is an advanced information technology and engineering company that provides innovative products and services to government and private industry, as well as independent institutions. At the core of our capabilities is a seasoned team of highly skilled engineers and scientists with multidisciplinary backgrounds. This team is challenged daily to provide cutting edge technology solutions to our clients.
SRC offers a generous benefit package, including medical, dental, and vision plans, 401(k) with a company match, life insurance, vacation and sick paid time off accruals starting at 10 days of vacation and 5 days of sick leave annually, 11 paid holidays, tuition reimbursement, and a work environment that encourages excellence and more. For positions requiring a security clearance, selected applicants will be subject to a government security investigation and must meet eligibility requirements for access to classified information.
EEO
Scientific Research Corporation is an equal opportunity employer that does not discriminate in employment.
All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other protected characteristic under federal, state or local law.
Scientific Research Corporation endeavors to make www.scires.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact jobs@scires.com for assistance. This contact information is for accommodation requests only and cannot be used to inquire about the status of applications."
2025-12-12T00:00:00,"Research Data Engineer II, CHeT Analytics",University of Rochester,"As a community, the University of Rochester is defined by a deep commitment to Meliora - Ever Better. Embedded in that ideal are the values we share: equity, leadership, integrity, openness, respect, and accountability. Together, we will set the highest standards for how we treat each other to ensure our community is welcoming to all and is a place where all can thrive. Job Location (Full Address): 265 Crittenden Blvd, Rochester, New York, United States of America, 14642 Opening: Worker Subtype: Regular Time Type: Full time Scheduled Weekly Hours: 40 Department: 400980 Neuro-Ctr Health & Tech/Admin Work Shift: UR - Day (United States of America) Range: UR URG 113 Compensation Range: $77,216.00 - $115,824.00 The referenced pay range represents the minimum and maximum compensation for this job. Individual annual salaries/hourly rates will be set within the job's compensation range, and will be determined by considering factors including, but not limited to, market data, education, experience, qualifications, expertise of the individual, and internal equity considerations. Responsibilities: GENERAL PURPOSE Participates in the design, implementation and maintenance of analytical and data science-based software and data pipelines to support scientific workflows. Focuses on developing and supporting data collection frameworks that integrate structured and unstructured data from multiple sources and systems to support specific research study teams. Supports the development and maintenance of infrastructure systems (e.g., data warehouses, data lakes), including data access Application Programming Interface(s) (APIs). Works in partnership with team members to provide robust, scalable software solutions to the research enterprise. ESSENTIAL FUNCTIONS Builds, maintains and evolves general Extract, Transform and Load (ETL) data pipelines and overall data architecture to accommodate a growing amount of data from a variety of large research data sources. Works with research team members to convert business and technical requirements into professional software solutions. Ensures timely completion of tasks while managing multiple assignments, project timelines and business user expectations. Designs and implements custom research project-specific data workflow solutions for data collection, management, reporting and analytics. Contributes to the scientific research. Adheres to defined application development life-cycle practices, including but not limited to, requirements gathering, writing test plans, source code management, peer code review and quality assurance through unit/system/user acceptance testing. Participates in specification, implementation and execution of testing procedures to ensure quality of deliverables, system and data workflow reliability. Produces and maintains comprehensive technical documentation for all systems under the Engineer's responsibilities. Keeps abreast of current application developments through continuing education, professional reading, online forums, conferences, workshops and professional groups. Other duties as assigned. MINIMUM EDUCATION & EXPERIENCE Bachelor's degree in Data Science, Biomedical Science, Computer Science, Mathematics, Statistics or similar discipline and 2 years of experience in technology and data intensive roles and environments required Or equivalent combination of education and experience Programming experience in Structured Query Language (SQL) and one other applicable language (Java, Python, and/or R) required Experience with Change Management solutions required Experience with Version Control solutions (e.g. Git) required Experience implementing and supporting data management systems in a scientific, research context (e.g. biospecimen software, electronic laboratory notebooks, REDCap) preferred Experience with Linux, container and cloud technologies (e.g. HPC, IaaS and PaaS) preferred KNOWLEDGE, SKILLS AND ABILITIES Understanding of data analytics and statistical methods required Expertise of software engineering best practices such as version control and software release management required Strong analytical and problem-solving skills required Strong organizational skills required Ability to work with others in a matrix management environment required Excellent communication skills for describing progress and challenges to stakeholders required Attention to detail, patience and a positive, customer-centric attitude required Strong technical presentation skills required Demonstrated ability to develop proficiency with unfamiliar toolsets preferred Familiarity with file formats, metadata, and data exchange and storage standards applicable in management of scientific and clinical research required The University of Rochester is committed to fostering, cultivating, and preserving an inclusive and welcoming culture to advance the University’s Mission to Learn, Discover, Heal, Create – and Make the World Ever Better. In support of our values and those of our society, the University is committed to not discriminating on the basis of age, color, disability, ethnicity, gender identity or expression, genetic information, marital status, military/veteran status, national origin, race, religion, creed, sex, sexual orientation, citizenship status, or any other characteristic protected by federal, state, or local law (Protected Characteristics). This commitment extends to non-discrimination in the administration of our policies, admissions, employment, access, and recruitment of candidates, for all persons consistent with our values and based on applicable law. Notice: If you are a Current Employee, please log into myURHR to search for and apply to jobs using the Jobs Hub. Your application, if submitted using this portal, cannot be moved forward. Learn. Discover. Heal. Create. Located in western New York, Rochester is our namesake and our home. One of the world’s leading research universities, Rochester has a long tradition of breaking boundaries—always pushing and questioning, learning and unlearning. We transform ideas into enterprises that create value and make the world ever better. If you’re looking for a career in higher education or health care, the University of Rochester may offer the perfect opportunity for your background and goals. At the University of Rochester, we are committed to fostering, cultivating, and preserving an inclusive and welcoming culture and are united by a strong commitment to be ever better—Meliora. It is an ideal that informs our shared mission to ensure all members of our community feel safe, respected, included, and valued."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,Data Engineer II (Onsite),RTX,"Date Posted: 2025-12-12 Country: United States of America Location: PW147: PW OKC Campus 8120 S. Air Depot Blvd , Oklahoma City, OK, 73135 USA Position Role Type: Onsite U.S. Citizen, U.S. Person, or Immigration Status Requirements: U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Security Clearance: None/Not Required Pratt & Whitney is working to once again transform the future of flight—designing, building and servicing engines unlike any the world has ever seen. And because transformation begins from within, we’re seeking the people to drive it. So, calling all curious. Come ready to explore and you’ll find a place where your talent takes flight—beyond the borders of title, a country or your comfort zone. Bring your passion and commitment and we’ll welcome you into a tight-knit team that takes our mission personally. Channel your drive to make a difference into shaping an organization and an industry that’s evolving fast to the future. At Pratt & Whitney, the difference you make is on display every day. Just look up. Are you ready to go beyond? You will be an integral part of Pratt & Whitney’s Sustainment Operational Excellence Data Engineering & Analytics team. This team supports the global aftermarket maintenance and overhaul of engines for the F117, F119, and F135 programs. We are looking for a Data Engineer II to advance the digital and data capability of the Military Engines Global Depot Network organization. You will be working on exciting new technologies like cloud and open-source tools among others, and be responsible for cleaning, standardizing, transforming, and configuring data products within our emerging data mesh. What You Will Do: Create and maintain scripts written in Spark SQL or Pyspark in Databricks Notebooks. Also, work with SMEs to understand complex datasets for next generation data products and data visualizations to create data mesh tables. Develop scalable and sustainable data product transformations that curate, clean and store data efficiently; perform statistical analysis to quantify completeness and validity; perform bug fixes and apply enhancements to the models when the need arises. Ensure high performance and reliability of data transformation processes and pipelines. Collaborate cross-functionally to gather insights, refine requirements, and ensure alignment between product goals and team efforts. Document data processes, logic, and data sources to ensure transparency and knowledge sharing as well as support the overall team with any ad-hoc data related tasks. Work to convert our existing data visualizations in Power BI to use Databricks instead of Azure Synapse. Keep up to date with technologies and use advanced cloud data warehouse and data transformation techniques to build innovative solutions. Qualifications You Must Have: A degree in Science, Technology, Engineering or Mathematics (STEM) with 2+ years of experience in the use of SQL and/or Python to transform, clean, and integrate data from a variety of source pipelines. U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Qualifications We Prefer: Experience with transformation tools such as dbt, Databricks pipelines, or relevant tools such as SSIS, ADF, or Matillion. Demonstrated experience with Git/GitHub; experience working in cloud data warehouses like Databricks. Familiarity with agile methodologies and Kanban boards. Self-motivated, team player with good communication skills. Ability to focus on results and successfully manage multiple tasks/projects. An astute individual, with the ability to build strong cross-functional relationships; excited at the prospect of developing and implementing new data products that add organizational value & improve decision making capabilities. Business experience with Aerospace or other heavy manufacturing industry. An understanding of ER Diagrams for data modeling. Demonstrated understanding of data mesh design principles and data engineering best practices. Learn More & Apply Now! What is my role type? In addition to transforming the future of flight, we are also transforming how and where we work. We’ve introduced role types to help you understand how you will operate in our blended work environment. This role is: Onsite: Employees who are working in Onsite roles will work primarily onsite. This includes all production and maintenance workers, as they are essential to the development of our engines. Candidates will learn more about role type and current site status throughout the recruiting process. For onsite and hybrid roles, commuting to and from the assigned site is the employee’s personal responsibility. As part of our commitment to maintaining a secure hiring process, candidates may be asked to attend select steps of the interview process in-person at one of our office locations, regardless of whether the role is designated as on-site, hybrid or remote. The salary range for this role is 66,000 USD - 130,000 USD. The salary range provided is a good faith estimate representative of all experience levels. RTX considers several factors when extending an offer, including but not limited to, the role, function and associated responsibilities, a candidate’s work experience, location, education/training, and key skills. Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement. Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company’s performance. This role is a U.S.-based role. If the successful candidate resides in a U.S. territory, the appropriate pay structure and benefits will apply. RTX anticipates the application window closing approximately 40 days from the date the notice was posted. However, factors such as candidate flow and business necessity may require RTX to shorten or extend the application window. RTX is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or veteran status, or any other applicable state or federal protected class. RTX provides affirmative action in employment for qualified Individuals with a Disability and Protected Veterans in compliance with Section 503 of the Rehabilitation Act and the Vietnam Era Veterans’ Readjustment Assistance Act. Privacy Policy and Terms: Click on this link to read the Policy and Terms RTX is an aerospace and defense company that provides advanced systems and services for commercial, military and government customers worldwide. It comprises three industry-leading businesses – Collins Aerospace, Pratt & Whitney, and Raytheon. Its 195,000 employees enable the company to operate at the edge of known science as they imagine and deliver solutions that push the boundaries in quantum physics, electric propulsion, directed energy, hypersonics, avionics and cybersecurity. The company, formed in 2020 through the combination of Raytheon Company and the United Technologies Corporation aerospace businesses, is headquartered in Arlington, Virginia."
2025-12-12T00:00:00,"Senior Engineer, BAW R&D Trimming and Data Infrastructure",Qorvo,"
                Qorvo (Nasdaq: QRVO) supplies innovative semiconductor solutions that make a better world possible. We combine product and technology leadership, systems-level expertise and global manufacturing scale to quickly solve our customers' most complex technical challenges. Qorvo serves multiple high-growth segments of large global markets, including consumer electronics, smart home/IoT, automotive, EVs, battery-powered appliances, network infrastructure, healthcare and aerospace/defense. Visit www.qorvo.com to learn how our innovative team is helping connect, protect and power our planet.

 
Summary:
 Qorvo’s BAW R&D Data Infrastructure team is seeking a talented engineer for semiconductor data infrastructure, frequency trimming and process automation. The candidate chosen for this role will develop data infrastructure and software tools to support efficient development and production of new Bulk Acoustic Wave (BAW) filter technologies. The candidate will use MATLAB, data analysis tools (SpotFire), databases and other software tools for process control improvements, faster design cycles, and general automation to efficiently develop and produce new technologies.
 
Key Roles and responsibilities:

Research, implement, deploy, and maintain internal software applications used by Manufacturing and R&D Engineering teams to process and trim BAW filters wafers.
Work closely with Process Integration and Process Engineering teams to understand new BAW technology needs to define requirements and implement.
Provide comprehensive support to internal customers: resolve outstanding issues for R&D engineers, designers, and production at Qorvo’s fabrication facility.
Own critical data infrastructure projects and successfully deliver results in a timely manner

 
Technical Knowledge/Skills/Abilities Required:

Excellent MATLAB or Python programming capabilities
Knowledge of semiconductor processing
Practical knowledge of software development and object-oriented programming
Excellent debugging and problem-solving skills


Strong data analysis and mathematical skills


Experience with version control utilizing Git and GitLab
Good knowledge of SQL database (Oracle is a plus)
Experience in the full life cycle of the software design process including requirement analysis, design, prototyping, coding, documentation, implementation, and maintenance

 
Personal Skills:

Self-motivated, independent, proactive, detail oriented, and responsible team-player
Excellent analytical skills
Comfortable working in a dynamic and fast paced environment
Passion for innovation and emerging technologies
Excellent communication and interpersonal skills
Able to handle multiple priorities
Proficient in English

 
Desired experiences:

Experience with software development for semiconductor processing 
Expertise in electromagnetics, physics, or material science
Expertise in Oracle PL/SQL databases
Experience with data analysis tools such as Spotfire or similar application
Experience with GitLab workflows and pipeline automation 
Experience with Visual Studio Code and GitHub Copilot
Experience with unit testing in past development projects

 
Qualifications:
Education & Experience:

BS or MS in Computer Science, Electrical Engineering, Physics or Material Science
5+ years of code development experience.(or if Master's degree 2+ years experience)

 
This position is not eligible for visa sponsorship by the Company.
 
#LI-KR1
 MAKE A DIFFERENCE AT QORVO   

 We are Qorvo. We do more than create innovative RF and Power solutions for the mobile, defense and infrastructure markets – we are a place to innovate and shape the future of wireless communications. It starts with our employees. As a unified global team, we bring a commitment to excellence, growth and a passion for creating what's next. Explore the possibilities with us.

We are an Equal Employment Opportunity (EEO) employer and welcome all qualified applicants. Applicants will receive fair and impartial consideration without regard to any characteristics protected by applicable law, including race, color, religion, sex (as defined by law), national origin, age, military or veteran status, genetic information, or disability.  
                
    "
2025-12-12T18:28:05.616,Sr Staff Engineer Software (Data Plane Applications),Palo Alto Networks,"Company Description
Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
Who We Are
We believe collaboration thrives in person. That’s why most of our teams work from the office full time, with flexibility when it’s needed. This model supports real-time problem-solving, stronger relationships, and the kind of precision that drives great outcomes.
Job Description
Your Career
Prisma Access™ (formally GlobalProtect Cloud Service) provides protection straight from the cloud to make access to the cloud secure. It combines the connectivity and security you need and delivers it everywhere you need it. Using cutting-edge public and private cloud technologies extending the next-generation security protection to all cloud services, customers on-premise remote networks and mobile users.
We are seeking an experienced Software Engineer to design, develop and deliver next-generation technologies within our Prisma Access team. We want passionate engineers who love to code and build great products. Engineers who bring new ideas in all facets of software development. We are looking for leaders who take ownership of their areas of focus and who are driven to solve problems at every level. Collaboration and teamwork are at the foundation of our culture and we need engineers who can communicate at a high level and work well with others towards achieving a common goal.
Your Impact
Design, develop and implement highly scalable software features and infrastructure on our next-generation security platform ready for cloud native deployment from inception to completion
Work with different development and quality assurance groups to achieve the best quality - You accomplish this by being hands-on, creating tools, processes, and systems that produce transparency, alignment, and direction
Profile, optimize and tune systems software (management/control/dataplane) for efficient cloud operation
Work with DevOps and the Technical Support teams to troubleshoot customer issues
Work with other software development team to apply PanOS features on Prisma Access
Interview, mentor and coach new team members 
Qualifications
Your Experience 
5+ years of experience in developing and troubleshooting dataplane applications
Required hands-on programming experience in Python and Go
Nice to have C/C++ Programming
Strong Data structures/Algorithms
Strong analytical skills, problem solving and debugging skills
Nice to have experience with LLMs and GenAI applications. Or Machine learning/Data science with experience in ETL, curating datasets, running evals. 
Experience with building applications in the cloud
In-depth understanding of Operating System principles and OS like Linux/Unix
In-depth understanding of networking concepts and TCP/IP stack, TLS
Exposure to building Microservices 
Enjoys working with many different teams with strong collaboration and communication skills
Solid foundation in design, data structures, and algorithms, and strong analytical and debugging skills
Education : M.S./B.S. degree in Computer Science or equivalent military experience required
Additional Information
The Team
Our engineering team is at the core of our products – connected directly to the mission of preventing cyberattacks. We are constantly innovating – challenging the way we, and the industry, think about cybersecurity. Our engineers don’t shy away from building products to solve problems no one has pursued before.
We define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment.
Compensation Disclosure
The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $170,000 - $190,000/YR. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.
Our Commitment

We’re problem solvers that take risks and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at [email protected].
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
Is role eligible for Immigration Sponsorship?: Yes"
2025-12-12T18:20:27,Data Engineer,Real Chemistry,"At Real Chemistry, making the world a healthier place isn’t just an aspiration—it’s our everyday reality. Our drive to transform healthcare is informed by our blend of deep scientific expertise, human-centred creativity, and AI-driven insights, fostering a unique environment where innovation thrives and our people are impact-obsessed. As a global agency, we provide a full suite of services across healthcare communications and marketing to our clients, including top players in the pharmaceutical and biotech industries.
Our #LifeatRealChem culture is rooted in our people—we believe we are best together and are committed to excellence for both our clients and colleagues. Whether you're a seasoned professional or just starting your career, if you share our passion for healthcare and connection, we invite you to explore our opportunities.
Discover your purpose. Embrace innovation. Experience #LifeatRealChem.
Job Summary 
We’re looking for a hands-on Data Engineer to help build and maintain the data infrastructure that powers our AI products and solutions. This role sits within our AI organization and focuses on designing, developing, and optimizing scalable data pipelines, data models, and cloud-based data systems. You’ll collaborate closely with data scientists, ML engineers, product teams, and other technical partners to ensure high-quality, reliable, and well-structured data is available across the organization. 
Key Responsibilities 
Data Pipeline Development 
Build, optimize, and maintain scalable ETL/ELT pipelines for structured and unstructured data. 
Implement reliable, fault-tolerant ingestion and transformation workflows. 
Automate routine data processes where possible. 
Data Architecture & Modeling 
Develop well-structured data models that support analytics, ML use cases, and downstream applications. 
Support the design and enhancement of AI-related data architecture across cloud environments. 
Data Quality & Governance 
Implement automated data validation, monitoring, and alerting. 
Ensure high data accuracy, completeness, and integrity across ingestion and transformation layers. 
Cross-Functional Collaboration 
Partner with data scientists, ML engineers, product managers, and IT teams to understand data requirements and translate them into technical solutions. 
Troubleshoot issues and support stakeholders with data access and pipeline improvements. 
Cloud & Infrastructure 
Work with modern cloud platforms (AWS, Azure, or GCP) and associated data storage, compute, and orchestration services. 
Support deployment, scaling, and operational health of data systems. 
Innovation & Continuous Improvement 
Stay current with emerging data engineering tools and best practices. 
Propose opportunities to improve performance, efficiency, or reliability within the data stack. 
Qualifications & Skills 
Education & Experience 
Bachelor’s degree in Computer Science, Data Engineering, or related technical field (or equivalent experience). 
3–7 years of hands-on experience in data engineering or data pipeline development. 
Technical Skills 
Strong SQL skills and proficiency in Python or Scala. 
Experience with data warehousing technologies such as Snowflake, BigQuery, Redshift, or Databricks. 
Hands-on experience with cloud services (AWS, Azure, or GCP). 
Knowledge of data modeling, schema design, and ETL/ELT principles. 
Familiarity with distributed computing frameworks such as Spark or Flink. 
Experience with workflow orchestration tools like Airflow, Prefect, or Dagster is a plus. 
Soft Skills 
Strong problem-solving skills and attention to detail. 
Ability to communicate technical concepts clearly to peers and cross-functional partners. 
Comfortable working in a fast-moving, collaborative environment. 
Preferred Qualifications 
Experience with streaming data tools such as Kafka or Kinesis. 
Experience building CI/CD pipelines for data workflows. 
Experience in healthcare, biotech, life sciences, or commercial/marketing data environments. 
Experience in agency or consulting settings. 
Posting Salary
$140,000—$175,000 USD
Real Chemistry is proud to be Great Place to Work® certified; check out what our people shared about our culture and workplace on our Great Places to Work Profile here.
We believe we can do our best when feeling our best, which is why we’ve put together a benefits program designed to give you the support you and your family need at every stage of life. Real Chemistry offers a comprehensive benefit program and perks, tailored to your region. Globally, this includes offices in our key markets with free snacks to keep you running all day long, generous holiday and paid time off, options for private medical, dental, and vison plans, and support in saving for the future. Other perks include mental wellness coaching and support and access to more than 13,000 online classes with LinkedIn Learning. Learn more about our great benefits and perks and search specific offerings in your region at: www.realchemistrybenefits.com.
Working with Real HART: Since the pandemic, we have adapted to how our people told us they want to work. We have office locations in cities in the US, UK, and Europe with many employees and clients that serve as hubs where and when they need us. For employees who are within an hour of one of our offices, we expect attendance in the office two days per week, either at a Real Chemistry office or onsite with clients. We are also actively opening new office locations, so if one opens near you, our Real HART policy will apply. We are not looking for attendance for the sake of attendance but believe that the opportunity to coordinate in-office team meetings, 1:1 meetings with managers, taking advantage of on-site learning, and connecting with client partners is a critical to delivering on our purpose of making healthcare what it should be. Outside of these offices, we have regions, where people work remotely but come together quarterly for collaboration, culture and learning opportunities. We call this our Real Hybrid and Regional Teams (Real HART) approach. Real Chemistry believes we are best together – and our workplace strategy fosters connection and collaboration in person – but also supports flexibility for our people.
Real Chemistry is an Equal Opportunity employer. We continually strive to build and sustain an inclusive and equitable work environment where our employees feel empowered to leverage all they bring from their personal lived experience and professional expertise, to make our team the best in the industry. We encourage motivated and qualified applicants to apply without regard to race, color, religion, sex (including pregnancy), sexual orientation, gender identity/expression, ethnic or national origin, age, physical or mental disability, genetic information, marital information, or any other characteristic protected by federal, state, or local employment discrimination laws where Real Chemistry operates. Should you require accommodations throughout the interview process please let your recruiter know.
*Notice: Real Chemistry and its affiliates' names are being misused by scammers through messaging services, fake websites, and apps. Do not share personal or financial information or make payments to any unverified sources claiming to be connected to Real Chemistry. We are working to stop these unauthorized activities and protect our community. Read more here."
2025-12-12T17:29:23,Senior Python Data Engineer - (Remote)  ,KBRA,"Position Title: Senior Python Data Engineer - (Remote) 
Entity: KBRA Holdings LLC
Employment Type: Full-Time
Location: Remote (Remote only in CA, CO, DC, FL, IL, MD, NJ, MA, NY, PA, SC, TX, VA)
Summary/Overview:
KBRA (KBRA Holdings, LLC) is seeking an engaged and proactive Senior Python Data Engineer to work on our financial analytical system. We want someone who loves solving difficult problems, digs deeply to understand the domain in which they’re working, and excels at creating high-quality software in a collaborative environment.
About the Team:
We believe that small, empowered teams can do amazing things. Across the engineering organization, we work hard to make the best systems for our customers using modern engineering practices. We are intentional in our investments in time and effort around creating a safe and successful workplace for our team members. We understand software engineering goes beyond the 1’s and 0’s and prioritize concrete value for our customers.
About the Job:

This role involves joining an existing team with a well-defined product vision. This team operates collaboratively, and there is an expectation to get involved in all aspects of design, delivery, and support of our systems.

This role emphasizes collaboration with our technical and non-technical counterparts to learn our domain and its unique challenges, while delivering value to our customers. It also requires collaboration with our other engineering, design, product, and platform teams to develop, build, run, and support the system.
About You:

You will be successful in this role if you:
Develop, test, and maintain scalable Python applications.
Collaborate with product managers, designers, and other engineers to deliver high-quality software.
Write clean, efficient, and reusable code following best practices.
Participate in code reviews to ensure code quality and share knowledge with the team.
Troubleshoot and debug issues in a timely manner.
Contribute to the design and architecture of new features and systems.
Have a sense of ownership and craftsmanship around the code base and your work.
Enjoy helping other developers grow and learn new technologies.
Display a strong track record of mentorship with engineers at various levels.
Are mindful of application security and performance.
Take pride in learning, and want opportunities to learn throughout your day-to-day.
Possess a pragmatic mindset. 
Familiarity with Generative AI tools such as ChatGPT for research, data insights, and general productivity is a plus.
Must have skills:
3–6 years of professional software engineering experience, with a strong portfolio of full stack development work.
Proficiency in Python, including experience with web frameworks such as Flask.
Cloud experience, particularly with AWS (Amazon Web Services).
Experience integrating frontend applications with RESTful APIs and backend services.
Relational and non-relational databases (SQL Server, Snowflake and MongoDB).
Debugging, issue resolution, and troubleshooting.
Nice to have skills:
Familiarity with UX design tools (Figma) and solid understanding of the design-engineering hand-off process
Containerized development and deployment (i.e. Docker, Docker swarm, Kubernetes)
Infrastructure as Code (Terraform)
Familiarity with deployment pipelines, CICD tools.
Exposure to financial systems or credit modeling is strongly preferred.
Salary Range:
The anticipated annual base salary range for this full-time position is $130,000 - $160,000. Offer amounts are determined by factors such as experience, skills, geography, and other job-related factors.
Benefits:
Competitive benefits and paid time off
Paid family and disability leave
401(k) plan, including employer match (100% vested)
Educational and professional development financial assistance
Employee referral bonus program
About Us:
KBRA is a full-service credit rating agency registered in the U.S., the EU and the UK, and is designated to provide structured finance ratings in Canada. KBRA’s ratings can be used by investors for regulatory capital purposes in multiple jurisdictions.
More Info:
KBRA encourages applications from all qualified individuals without regard to race, color, religion, gender, sexual orientation, gender identity or expression, age, national origin, marital status, citizenship, disability, and veteran status or any other basis prohibited by federal, state or local law.
#LI-KS1
#REMOTE"
2025-12-12T17:19:54,Data Platform Engineer,Dragonfli Group,"Dragonfli Group is a cybersecurity and IT consulting firm providing services to federal agencies and Fortune 100 enterprises. Headquartered in Washington, DC, Dragonfli supports clients in securing mission-critical systems across on-site, hybrid, and fully remote environments.

This contract Data Platform Engineer role supports a large federal agency in protecting security data platforms within a large-scale IT environment. The engineer will manage security data platforms such as Splunk and data lakes, ensuring effective data flows, integrations, and platform support. Key technologies include Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS. The role requires seasoned IT security expertise, hands-on technical skills, and strong communication and planning abilities. It's a high-impact opportunity to shape security analytics capabilities within a major federal agency.

This is a multi-year contract position involving a large US federal agency. Candidates with previous federal contracting experience are preferred. U.S. Citizenship or Permanent Residency required. If hired, all work related to this role must be performed within the continental U.S.

Responsibilities:
Manage security data platforms, such as Splunk and data lakes.
Ensure effective data flows, integrations, and platform support.
Support event ingestion, platform maintenance, and technical add-ons.
Troubleshoot to support operational and compliance reporting.
Optimize data use for security monitoring, incident response, and threat analysis.
Collaborate across teams to enhance security analytics capabilities.
Configure and maintain various event ingestion methods.
Create and maintain custom TAs for data parsing into Splunk CIM format.
Monitor and perform routine maintenance of data systems.
Drive process improvements and attention to detail.

Requirements
Four (4)+ years of experience supporting enterprise data platforms.
BS/BA in a cyber-related field or equivalent experience/certifications.
Experience with installing, updating, and maintaining ELM and SIEM.
Proficiency with Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS.
Experience configuring and maintaining event ingestion methods.
Ability to create and maintain custom TAs for Splunk.
Experience in troubleshooting, monitoring, and maintaining data systems.
Familiarity with enterprise security operations.
Strong cross-functional communication skills.

Skill(s)
Hands-on management of security data platforms.
Expertise in data flows and platform integrations.
Proficiency in Splunk and related technologies.
Strong troubleshooting and problem-solving skills.
Ability to optimize security monitoring and incident response.
Excellent cross-functional communication abilities.
Attention to detail and process improvement mindset.
Ability to work collaboratively across teams.
Strong planning and organizational skills.

Benefits
Insurance – health, dental, and vision
Paid Time Off (PTO) and 11 Federal Holidays
401(k) employer match

Travel
null"
2025-12-12T16:50:01,Staff Configuration Data Engineer,Archer,"Archer is an aerospace company based in San Jose, California building an all-electric vertical takeoff and landing aircraft with a mission to advance the benefits of sustainable air mobility. We are designing, manufacturing, and operating an all-electric aircraft that can carry four passengers while producing minimal noise.
Our sights are set high and our problems are hard, and we believe that diversity in the workplace is what makes us smarter, drives better insights, and will ultimately lift us all to success. We are dedicated to cultivating an equitable and inclusive environment that embraces our differences, and supports and celebrates all of our team members.
What you'll do:
As the Configuration Data Engineer, you will combine software development expertise with configuration management practices to safeguard product data integrity, traceability, and compliance. You will design tools, reports, and automations that enable engineering and product teams to make faster, more accurate configuration decisions.
Develop and maintain tools and reports to monitor bills of materials (BOMs), effectivity assignments, and configuration changes
Create automated quality checks to validate workflows and ensure compliance with configuration management standards
Integrate with Teamcenter APIs and background services to access, analyze, and validate engineering data
Build automation scripts to support NX, CATIA, and other CAD-driven workflows (NX Open, CATIA VB, Check-Mate, NX Check-Mate)
Support the definition, maintenance, and auditing of BOM structures, unit effectivity, and date-based effectivity for engineering changes
Develop dashboards and metrics reporting to provide visibility into change requests, change notices, and configuration status accounting
Collaborate with configuration management, engineering, and IT teams to streamline data flow across systems
Investigate data anomalies and provide corrective recommendations to maintain design and change integrity
Partner with project teams to ensure effectivity assignments are properly implemented and reflected in reports
Contribute to the improvement of enterprise configuration management processes through data-driven insights
Serve as a technical resource to CM specialists for reporting, automation, and API usage
What You Need
To be a self starter with a strong desire to learn new technologies
Ability to translate engineering/CM requirements into automated solutions
2+ years of experience developing tools and reports for a Product Lifecycle Management (PLM) tools (e.g., Teamcenter, Windchill, Enovia, 3DX) or equivalent engineering data environments
Experience with relational databases (SQL, PostgreSQL, Oracle) for reporting and automation
Ability to interpret engineering drawings, CAD data, and metadata
Understanding of BOM structures, unit effectivity, and date-based effectivity methods
Familiarity with engineering change processes, including Change Requests (CRs) and Change Notices (CNs)
Experience with scripting or automation in CAD/PLM environments (NX Open, CATIA VB, or similar)
Strong problem-solving skills and ability to analyze complex datasets for process improvements
Effective written communication skills to document procedures and produce clear reports
Ability to work in a collaborative environment across engineering, CM, and IT teams
Bonus Qualifications
Hands-on experience with Siemens Teamcenter APIs or integrations
Experience with Business Intelligence tools such as Power BI, Sigma, or SAP Hana
Experience with ITI CADIQ tools and CAD data validation workflows
Experience with Elysium CAD Translation tools
Familiarity with NX Check-Mate and automations
Familiarity with ASME Y14.5 Dimensioning and Tolerancing
Experience developing Adobe Forms with JavaScript and PDF publishing workflows
Exposure to aerospace, automotive, or other complex product development environments
Knowledge of configuration management standards and compliance practices (CMII, EIA-649, etc.)
This role is ideal for engineers who enjoy bridging software development with product lifecycle control. You will directly impact how engineering data is managed, ensuring accuracy, efficiency, and compliance across the enterprise
Archer is committed to working with and providing reasonable accommodations to job applicants with physical or mental disabilities, and those with sincerely held religious beliefs. Applicants who may require reasonable accommodation for any part of the application or hiring process should provide their name and contact information to Archer’s People Team at people@archer.com. Reasonable accommodations will be determined on a case-by-case basis.
Information collected and processed as part of any job applications you choose to submit is subject to Archer's Candidate Privacy Policy.
Archer is unable to provide work visa sponsorship for this position at the present time.
Archer is proud to be an Equal Opportunity employer committed to diversity and inclusivity in the workplace. All aspects of employment are decided on the basis of merit, qualifications, and business needs. We do not discriminate based upon race, color, religion, sex, sexual orientation, age, national origin, disability status, protected veteran status, gender identity or any other characteristic protected by federal, state or local laws.
Archer Aviation does not engage with external recruiting agencies/individual recruiters with whom it does not have a prior written agreement. Archer reserves the right to make use of any unsolicited resumes that it receives and bears no responsibility for payment of any fees asserted from the use of unsolicited resumes. If you are a recruiting agency or individual recruiter wishing to do business with Archer, please reach out to People@archer.com. All employment processes are managed by the Archer People Team."
2025-12-12T16:14:31,Data Engineer - Integrated Supply Chain,Textron,"Data Engineers build and maintain data systems in support of data analytics and data science activities. The Data Engineer will implement methods to improve data reliability, data quality, and ensure success in data-driven initiatives.
This position within Integrated Supply Chain Analytics is responsible for identifying, developing, and executing solutions that support reliable and efficient extraction of data from source systems and loading of that data into analytic platforms. The Data Engineer will help administer data platforms and consult with data analysts and data scientists on process optimization and data quality improvements.
At Textron Aviation, we are building a community of Data & Analytics professionals with an emphasis on collaboration and cross functional support. You will have the opportunity to work closely with your peers throughout the organization toward a vision of data driven strategy.


JOB RESPONSIBILITIES:
· Gain core business understanding of Textron Aviation and aircraft design, operation, and support
· Query, clean, transform, and stage data (ETL/ELT) across on-prem and cloud environments
· Support data analytics and data science activities by implementing, maintaining, and optimizing production ready data pipelines
· Install and update software to ensure data platform continuity
· Administer a CI/CD compliant code repository during development and update activities
· Research and help implement new technologies to support analytics function
· Interface with other data professionals throughout the organization to embrace cross functional growth in analytics capabilities
· Work to improve data quality by assisting data governance efforts in creating and maintaining data quality standards
· Plan and execute projects according to established milestones and schedules
· Train users in data & analytic tools and processes per best practices and compliance standards
· Contribute to the resolution of service tickets pertaining to data infrastructure
· Serve as an internal consultant to business leaders by advising on system capabilities
EDUCATION/ EXPERIENCE:
· Bachelor’s degree in Computer Science, Software Engineering, Data Science/Analytics, MIS, or other related technical field
· Minimum 2 years relevant technical experience required, focused on data collection, utilization, and analysis.
· Aviation experience preferred
Textron Aviation Inc. must comply with U.S export control laws and regulations. If a position requires access to sensitive information controlled under these laws and regulations, a successful applicant must be eligible to meet any requirements to access controlled information."
2025-12-12T16:07:56,Senior Data Engineer ,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:55,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:54,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T15:01:13.806,"Software Engineer III, Infrastructure, Audience Data Processing",Google,"MINIMUM QUALIFICATIONS:

 * Bachelor’s degree or equivalent practical experience.
   
 * 2 years of experience with software development in C++, SQL, Borg, Flume, or
   1 year of experience with an advanced degree.
 * 2 years of experience with developing large-scale infrastructure, distributed
   systems or networks, or experience with compute technologies, storage or
   hardware architecture.



PREFERRED QUALIFICATIONS:

 * Master's degree or PhD in Computer Science or related technical fields.
   
 * 2 years of experience with data structures and algorithms.
 * Experience with Flume and large scale data processing pipelines.
 * Experience developing accessible technologies.
   


ABOUT THE JOB:

Google's software engineers develop the next-generation technologies that change
how billions of users connect, explore, and interact with information and one
another. Our products need to handle information at massive scale, and extend
well beyond web search. We're looking for engineers who bring fresh ideas from
all areas, including information retrieval, distributed computing, large-scale
system design, networking and data storage, security, artificial intelligence,
natural language processing, UI design and mobile; the list goes on and is
growing every day. As a software engineer, you will work on a specific project
critical to Google’s needs with opportunities to switch teams and projects as
you and our fast-paced business grow and evolve. We need our engineers to be
versatile, display leadership qualities and be enthusiastic to take on new
problems across the full-stack as we continue to push technology forward.

As a Software Engineer on the Audience Data Processing Infrastructure team, you
will innovate and optimize planet-scale data processing flows to support Google
Ads.

While we're an infrastructure team, we operate in a fast-paced environment with
evolving requirements. Our focus is on supporting client data processing needs,
enhancing operational excellence and developer velocity, and significantly
improving resource efficiency.


Google Ads is helping power the open internet with the best technology that
connects and creates value for people, publishers, advertisers, and Google.
We’re made up of multiple teams, building Google’s Advertising products
including search, display, shopping, travel and video advertising, as well as
analytics. Our teams create trusted experiences between people and businesses
with useful ads. We help grow businesses of all sizes from small businesses, to
large brands, to YouTube creators, with effective advertiser tools that deliver
measurable results. We also enable Google to engage with customers at scale.

The US base salary range for this full-time position is $141,000-$202,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Write product or system development code in C++ for infrastructure
   responsible for managing and optimizing processing of planet-scale data
   processing.
 * Investigate data storage and processing use cases, techniques, and
   identifying opportunities for future innovation.
 * Review code developed by other developers and provide feedback to ensure best
   practices (e.g., style guidelines, checking code in, accuracy, testability,
   and efficiency).
 * Contribute to existing documentation or educational content and adapt content
   based on product/program updates and user feedback.
 * Triage product or system issues and debug/track/resolve by analyzing the
   sources of issues and the impact on hardware, network, or service operations
   and quality."
2025-12-12T13:26:27,Cleared On Site Data Engineer (4899),SMX,"SMX is seeking a Senior Data Architect to provide strategic and technical leadership for enterprise data architecture and analytics modernization efforts. This individual will design, optimize, and oversee data solutions that enable advanced analytics, business intelligence, and reporting capabilities across multiple secure environments. This role will focus on designing, developing, optimizing, and maintaining data pipelines and backend data engineering solutions that power critical analytical products used by senior FBI leadership. The ideal candidate brings deep technical expertise in ETL processes, SQL, Python, AWS data services, and enterprise-scale data warehousing, with strong familiarity in BI ecosystems such as MicroStrategy (Strategy), ThoughtSpot, and related tools used within the HR Reports program. The position requires close collaboration with government leads, senior data developers, BI engineers, and cross-functional analytics teams to ensure high reliability, performance, and security of data products supporting mission-critical operations. 
This is a full-time position requiring on-site work five days a week at a client’s office in Washington, D.C. An active Top Secret clearance is mandatory.
Essential Duties and Responsibilities: 
Design, build, and maintain scalable, secure ETL/ELT pipelines supporting HR Reports analytics and dashboard products.
Develop and optimize SQL-based transformations, stored procedures, and data models for high-volume enterprise datasets.
Implement data orchestration workflows using AWS services (e.g., Glue, Lambda, Step Functions, CloudWatch).
Ensure data quality, lineage, and integrity across multiple enterprise data sources.
Support and enhance cloud-based warehouse environments within AWS (e.g., Redshift, S3, IAM).
Collaborate with BI developers to ensure backend data structures meet MicroStrategy/Strategy and ThoughtSpot reporting needs.
Troubleshoot complex data pipeline or performance issues and implement long-term remediation solutions.
Translate government stakeholder requirements into technical specifications for new data sources and pipelines.
Partner with Data Analysts, Data Scientists, and BI Developers to support advanced analytics and ad-hoc data requests.
Apply data governance, security, and compliance best practices in alignment with FBI and SMX standards.
Recommend and implement improvements to automation, data architecture, pipeline reliability, and overall performance.
Maintain documentation for pipelines, logic, data flows, and system dependencies.
Stay current with modern data engineering practices and AWS service enhancements relevant to pipeline automation and warehousing.
Required Skills: 
10+ years of experience in data architecture, data warehousing, or enterprise analytics systems.
Expert-level proficiency in SQL and data modeling
Hands-on experience designing and implementing ETL/ELT frameworks (e.g., Apache Airflow, dbt, AWS Glue, Informatica).
Demonstrated success architecting and optimizing large-scale BI/reporting solutions (MicroStrategy, ThoughtSpot, Power BI, Tableau).
Strong knowledge of AWS data ecosystem (Redshift, Athena, S3, Glue, Lambda) or similar cloud environments.
Experience defining and enforcing data governance, quality, and security standards.
Ability to design and document end-to-end data flows and integrations between transactional and analytical systems.
Excellent communication, analytical, and problem-solving skills.
Desired Skills/Experience:
Bachelor’s or Master’s degree in Computer Science, Information Systems, Data Engineering, or related technical field.
10+ years of experience in data engineering, backend data development, or enterprise-scale ETL development.
Experience supporting federal government IT systems or analytics programs.
Familiarity with Agile methodologies and Jira-based workload management.
Experience supporting or modernizing enterprise BI ecosystems.
**This position requires five days a week on site at customer location in Washington DC.
Application deadline 1-16-2026
#LI-SA
#cjpost
The SMX salary determination process takes into account a number of factors, including but not limited to, geographic location, Federal Government contract labor categories, relevant prior work experience, specific skills, education and certifications. At SMX, one of our Core Values is to Invest in Our People so we offer a competitive mix of compensation, learning & development opportunities, and benefits. Some key components of our robust benefits include health insurance, paid leave, and retirement.
The proposed salary for this position is:
$114,600—$192,500 USD
At SMX®, we are a team of technical and domain experts dedicated to enabling your mission. From priority national security initiatives for the DoD to highly assured and compliant solutions for healthcare, we understand that digital transformation is key to your future success.
We share your vision for the future and strive to accelerate your impact on the world. We bring both cutting edge technology and an expansive view of what’s possible to every engagement. Our delivery model and unique approaches harness our deep technical and domain knowledge, providing forward-looking insights and practical solutions to power secure mission acceleration.
SMX is an Equal Opportunity employer including disabilities and veterans.
Selected applicant may be subject to a background investigation and/or education verification.
SMX does not sponsor a new applicant for employment authorization or immigration related support for this position (i.e. H1B, F-1 OPT, F-1 STEM OPT, F-1 CPT, J-1, TN, E-2, E-3, L-1 and O-1, or any EADs or other forms of work authorization that require immigration support from an employer)."
2025-12-12T12:29:19.508,"Data Center Plant Engineer, Mechanical, Electrical",Google,"MINIMUM QUALIFICATIONS:

 * Associate's degree, trade school certification, or other certified training
   in a related technical field, or equivalent practical experience.
 * 7 years of experience in electrical, mechanical/HVAC, or controls/automation
   experience in an industrial or commercial environment.



PREFERRED QUALIFICATIONS:

 * Experience working in data centers, hospitals, or power plants.
 * Knowledge of electrical and mechanical systems used in a data center
   environment (e.g., Feeders, Transformers, Generators, Switchgear, UPS
   systems, ATS/STS units, PDU/PMM units, Chillers, Air handling units, and CRAC
   units).
   
 * Knowledge of meters, devices, sensors, and troubleshooting utilizing standard
   hand tools, digital metering, or calibration/diagnostic equipment.
   
 * Ability to communicate with contractors who perform maintenance or upgrade
   work on the data center systems.
   


ABOUT THE JOB:

The Data Center team designs and operates some of the most sophisticated
electrical engineering, mechanical engineering and HVAC systems in the world.
Facilities Technicians at Google data centers operate, monitor and support
physical facilities conditions. Some of these duties will include heating and
cooling of air and water, power supply, generators, UPS systems, electrical
distribution and control and monitoring systems. You regularly help inspect,
maintain and repair various data center systems such as piping and non-critical
electrical or mechanical system components). You provide daily assistance to
senior technicians as you read blueprints/schematics, conduct tours of systems
and assess their working order.

As a master of exceptional practices, you develop creative approaches to
reducing operational costs while improving overall data center efficiency. You
ensure that environmental and safety standards are consistently met, identifying
problems and making repairs quickly In emergency situations or abnormal
conditions, you manage data center performance issues and outages to minimize
the recovery time from failures.The AI and Infrastructure team is redefining
what’s possible. We empower Google customers with breakthrough capabilities and
insights by delivering AI and Infrastructure at unparalleled scale, efficiency,
reliability and velocity. Our customers include Googlers, Google Cloud
customers, and billions of Google users worldwide.

We're the driving force behind Google's groundbreaking innovations, empowering
the development of our cutting-edge AI models, delivering unparalleled computing
power to global services, and providing the essential platforms that enable
developers to build the future. From software to hardware our teams are shaping
the future of world-leading hyperscale computing, with key teams working on the
development of our TPUs, Vertex AI for Google Cloud, Google Global Networking,
Data Center operations, systems research, and much more.

The US base salary range for this full-time position is $105,000-$151,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Inspect, maintain, and repair various data center systems such as piping and
   non-critical electrical or mechanical system components.
   
 * Provide daily assistance to technicians as you read blueprints/schematics,
   conduct tours of systems, and assess their working order.
   
 * Manage the uptime and maintenance of water pumps and treatment systems, HVAC,
   UPS, generators, electrical distribution, and control and monitoring systems.
   
 * Operate, monitor, maintain, and respond to abnormal conditions in the data
   center facilities systems and equipment.
   
 * Support startup, commissioning, and integration of new equipment and systems
   into facilities infrastructure.
   "
2025-12-12T09:01:55.769,Data Engineer II,Microsoft,"Overview
With continued growth in digital data and the desire to leverage data to measure in-production quality and address problems that touch all aspects of our lives, Microsoft’s Windows Servicing & Delivery Org is looking for an equally data- and quality-minded engineer to meet these challenges! Join the Update Platform team for the chance to have an impact on billions of customers every day. The Update Platform Team is responsible for ensuring the seamless delivery and integration of software updates and keeping our customers up-to-date and secure at all times.
As a Data Engineer II member of the Update Platform Insights team, you will be at the forefront of leveraging data to assess the quality of the product, detect issues before they reach broad customer application to assure top product quality for partners and customers alike while keeping billions of devices secure and up-2-date.

In this exciting role, you'll work with a diverse group of talented professionals, innovate for greater platform efficiency as well as leveraging the latest technologies and best practices to streamline our update processes with timely in-depth insights and intelligent features.

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.


Responsibilities
Data Management and Transformation: With guidance, you will apply modification techniques to transform raw data into compatible formats for downstream systems. Utilize software and computing tools to ensure data quality and completeness. Implement code to extract and validate raw data from upstream sources, ensuring accuracy and reliability.
Drive Customer Success: Through Data and Business Insight: You will play a pivotal role in building a metrics-driven culture that directly impacts product quality and customer outcomes. This role goes beyond technical execution—you will design and implement measurement frameworks from the ground up while applying a strategic, top-down perspective to ensure the right metrics are in place. Your ability to translate data into actionable insights, aligned with business priorities and rhythm of business, will enable informed decisions that drive high-quality product outcomes and measurable customer success.

Data Requirements and Modeling: Collaborate with stakeholders to document and understand data requirements. Evaluate project plans to assess data costs, access, and availability. Draft design specifications to model data flow and storage, ensuring data is easy to connect and manage.
Compliance: You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams. You’ll also learn about permissions and approvals for data access within a data pipeline.

Validation and Quality Mindset: Apply and use operational fundamentals to validate and ensure quality of the product as well as the underlying data pipeline and assets to secure trustworthiness in your data daily.

Customer Focus: Be driven by a focus on customer happiness and success. We as a team only succeed if our customers are secure and protected via the updates we deliver.


Qualifications
Required Qualifications:
Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 1+ year(s) experience in business analytics, data science, software development, data modeling, or data engineering
OR Bachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 2+ years experience in business analytics, data science, software development, data modeling, or data engineering
OR equivalent experience.
Other Requirements:
Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include but are not limited to the following specialized security screenings:
Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.
Preferred Qualifications:
3+ years with scripting and coding languages with a focus on data engineering, like SQL, KQL, python, Scope, C# (or similar object-oriented languages) and others.
1+ years of experience with building large data processing frameworks using technologies like Azure Data Factory, Azure Data Explorer, PowerBI and/or other public and Microsoft internal tools.
1+ years of experience in analytics to define, monitor, and optimize key performance indicators (KPIs) and connected business metrics that ensure measurable customer success.
1+ years of proven ability to orchestrate and sustain a data-driven rhythm of business, transforming insights into actionable strategies that align with organizational priorities and deliver impactful outcomes.
A solid quality mindset with the ability to deliver end-to-end data solutions that build partner and customer confidence, ensuring alignment with business objectives and measurable outcomes.
Experience with Git, ADO or equivalent Source Control Systems.
Experience with data visualization tools and how to effectively communicate Insights to consumers of varying types of audiences.
Experience leveraging AI to define and evaluate quality standards


Data Engineering IC3 - The typical base pay range for this role across the U.S. is USD $100,600 - $199,000 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $131,400 - $215,400 per year. 
Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:
https://careers.microsoft.com/us/en/us-corporate-pay

This position will be open for a minimum of 5 days, with applications accepted on an ongoing basis until the position is filled.


Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance with religious accommodations and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations."
2025-12-12T01:54:02.588,"Data Science Engineer, New College Grad- Master's/PhD (Santa Clara, CA)",Applied Materials,"Assist in developing data science software prototypes and interfaces for monitoring semiconductor process tools Develop Python scripts to implement key concepts Collaborate closely with algorithm developers to characterize the algorithms and benchmark their performance, collecting quantitative data assessing effectiveness Evaluate the effectiveness and accuracy of the algorithms by working closely with process and equipment experts, providing feedback to algorithm developers Provide solutions which can be implemented by engineers without a deep statistical or mathematical background Deploy and maintain solutions at service sites Troubleshoot solutions, provide workarounds, and assist users in using solutions Assess effectiveness of solutions and provide data science insight Communicate well with algorithm developers and process experts Train field engineers to use solutions Present work and conclusions clearly and succinctly to peers Work well in team, providing and receiving constructive input with team members Monitor and quantify the results of complex algorithms in a production environment. Train a variety of individuals on the operation of these algorithms. Experience with various Artificial Intelligence Solutions, including Large Language Models, Computer Vision and Generative AI applications. Python, MATLAB Familiarity with common data science techniques, including regression, decision trees, Principle components, PLS, various Neural networks, time-series techniques, Bayesian techniques, etc. Ability to troubleshoot software applications and perform basic DevOps for deployment Ability to interact with Process and Customer Engineers Semiconductor process or equipment experience preferred. Demonstrates depth and/or breadth of expertise in own specialized discipline or field May lead small functional teams or projects with moderate resource requirements, risk, and/or complexity Communicates difficult concepts and negotiates with others to adopt a different point of view Master's or PhD in Computer Science, Data Science, Software Engineering, Mechanical Engineering, or related field. Preferred GPA of 3.0 or above"
2025-12-12T01:52:09.253,"Vice President, Data Engineer",BNY,"Bachelor's or master's degree in computer science or a related discipline, or equivalent work experience is required. 10+ years of data modeling, database design and development or related experience is required. Prior experience in managing DB development team Experience modeling Financial data Prior experience modeling Client and Entitlement Data Good knowledge of Financial Accounts, Transactions and Positions data Hands-on experience with any RDBMS, preferably MS SQL Server or Oracle Good SQL knowledge Excellent communication skills Good Problem Solving & Analytical Skills Work experience in Financial Services Work experience on any data modeling tool, viz. Erwin, DBArtisan etc. Experience with writing ANSI SQL code Prior Experience with a scripting language, preferably Python Experience working with Cloud native databases Bachelor's or Master's degree in Computer Science or a related discipline, or equivalent work experience is required. Advanced degree is preferred. Experience in the Securities or Financial Services industry."
2025-12-12T01:08:33,Data Analytics Engineer,Masimo,"The Data Analytics Engineer will support Masimo’s Quality organization by developing dashboards, performing data analysis, and transforming large datasets into meaningful insights. This role partners closely with Quality Compliance, Product Assurance, Engineering, Operations and cross-functional stakeholders to enhance data visibility, drive data-informed decisions, and support continuous improvement across the organization. The ideal candidate is technically strong in analytics tools, comfortable working with structured and unstructured data, and eager to grow in a fast-paced and evolving environment.
Duties & Responsibilities
Develop and maintain Power BI dashboards and reports that translate complex data sets into clear, actionable information.
Perform data transformation and modeling using SQL, Power Query (M), and DAX to support quality metrics, KPIs, and trend analysis.
Support routine and ad-hoc data analytics requests related to customer feedback, failure analysis, operations, and compliance activities.
Analyze large datasets to identify trends and process improvement opportunities.
Collaborate with Quality Compliance, Product Assurance, and cross-functional engineering teams to ensure data accuracy, consistency, and alignment with business needs.
Communicate findings through effective data storytelling, written summaries, and monthly presentations to cross functional leaders across the organization.
Contribute to continuous improvement efforts in reporting automation, dashboard optimization, and analytics best practices.
Minimum & Preferred Qualifications and Experience
Experience
0–2+ years of experience in data analytics, business intelligence, or engineering analytics; internship or project experience considered.
Hands-on experience with SQL and Power BI (including Power Query/M and DAX).
Experience using Python or R for data manipulation, modeling, or visualization preferred.
Familiarity with data visualization tools (Power BI highly preferred; Tableau or Looker a plus).
Understanding of statistics, data modeling, or quantitative analysis techniques.
Skills & Competencies
Strong analytical and problem-solving skills with high attention to detail.
Ability to translate data into clear insights for technical and non-technical partners.
Strong verbal, written, and visual communication skills, with the ability to present confidently and engage diverse audiences.
Ability to work independently and in a team environment.
Curiosity and willingness to learn new tools, systems, and techniques.
Education
Bachelor’s degree in Data Analytics, Data Science, Business Intelligence, Computer Science, Engineering, or a related field required.
Master’s degree in a relevant field is a plus but not required.
Compensation:
The anticipated salary range for this position is $90,000 - $110,000 plus benefits. Actual placement within the range is dependent on multiple factors, including but not limited to skills, education, and experience. 
This position also qualifies for up to 10% annual bonus based on Company, department, and individual performance. 
Masimo offers benefits such as Medical, Dental, Vision, Life/AD&D, Disability Insurance, 401(k), Vacation, Sick, Holiday, Paid Maternity Leave, Flexible Spending Accounts, Voluntary Accident, Critical Illness, Hospital, Long-Term Care, Employee Assistance Program, Pet Insurance, On-site wellness clinic, fitness center, and cafe. All benefits are subject to eligibility requirements."
2025-12-12T00:39:10,Data Engineer,HealthPartners/GHI,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:39:10,Data Engineer,HealthPartners,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:14:05.56,Sr. Data Engineer,Apple,"As a Data Engineer on the Capacity Engineering team, you will help design,
build, and operate the data foundation that drives capacity, cost, and
power-related decisions across Apple’s infrastructure footprint. In this role,
you will: Architect, implement, and maintain large-scale batch and streaming
pipelines that ingest, process, and model infrastructure telemetry, cost,
metering, utilization, forecasting, and power metrics from multiple clouds and
bare metal environments. Design and evolve robust data models (with a strong
focus on dimensional modeling) and storage patterns that support analytics,
internal billing, and efficiency use-cases. Treat data as a product: define
quality checks, SLAs, and observability to ensure data is accurate, timely, and
trusted by stakeholders across Apple. Integrate and enrich raw signals with
metadata and attribution to power use cases such as internal billing/showback,
usage understanding, efficiency and optimization, clawbacks, planning, and
procurement. Collaborate closely with data scientists, software engineers,
platform teams, finance partners, program managers, and leadership to translate
requirements into scalable, reliable data solutions and services. Implement
standard methodologies for data governance, lineage, metadata management, and
security, in alignment with Apple’s standards for data protection and privacy.
Build end-to-end data solutions that include logging, anomaly detection, data
validation, cleaning, and transformation, with strong emphasis on monitoring,
debuggability, and continuous improvement. Contribute to the evolution of our
data and platform stack, including tooling, frameworks, and standards for
development, testing, deployment, and operations (CI/CD, infrastructure as code,
etc.).


DESCRIPTION


Apple’s Capacity data engineering team, within the Apple Services Engineering
organization, is building the centralized data backbone that powers how Apple
understands, plans, and optimizes its cloud and data center infrastructure. We
engineer a unified, trusted data lake that consolidates cost, metering,
utilization, forecasting, and power metrics produced by Apple platforms and
systems (including bare metal) across both third-party and Apple internal
clouds. Enriched with metadata and attribution, this becomes the single source
of truth for internal billing, understanding usage and utilization, clawbacks,
planning, procurement, and efficiency initiatives. We collaborate with platform
engineering, finance, capacity engineering, and leadership teams to build
large-scale data pipelines, enable descriptive and predictive analytics, and
power dashboards and products that support critical business decisions. This is
your opportunity to help design and operate highly visible, global-scale systems
processing petabytes of data and supporting hundreds of users across Apple. Come
join us to help deliver the next generation of infrastructure insights at Apple.


MINIMUM QUALIFICATIONS


Bachelors degree or equivalent experience in Computer Science, Information
systems, Software Engineering, Data Science or related field. Advanced degree in
a related field a plus. 5+ years of experience in data engineering (or
equivalent practical experience), including: Building and maintaining
large-scale ETL/ELT data pipelines Distributed computing (e.g., Spark / PySpark)
for data processing and automation Query performance optimization and tuning at
scale Hands-on experience with: Apache Spark and Airflow (or similar
workflow/orchestration tools) for efficient large-scale data pipelines Data
modeling, especially dimensional modeling, and designing schemas optimized for
analytics and reporting Big data platforms and/or data lake architectures


PREFERRED QUALIFICATIONS


Experience with cloud technologies, specifically AWS (e.g., S3, EMR, Lambda,
Glue, RDS/Redshift, or similar services) Tooling & ecosystem: Experience with
CI/CD tooling such as Jenkins (or similar tools) Experience with data
visualization / BI tools, such as Superset or Tableau (other tools like
QuickSight, QlikView, Cognos, or Business Objects are a plus) Experience with
containerization and orchestration, such as Docker and Kubernetes/EKS is a plus
Understanding of authentication and authorization (AuthN/AuthZ) patterns
Knowledge of data governance principles, data security best practices, and data
privacy regulations"
2025-12-12T00:00:00,Lead Data Engineer,Nuna,"At Nuna, our mission is to make high-quality healthcare affordable for everyone. We are dedicated to tackling one of our nation’s biggest problems with ingenuity, creativity, and a keen moral compass.
Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why.
Nuna has established its brand in the B2B space over the last decade by shifting the US healthcare system towards an incentive model that rewards healthcare providers for positive outcomes. Marshalling our collective backgrounds and insights, we are now crafting an innovative, consumer app - a clinically driven healthcare companion experience that leverages AI, gamification and social support techniques to improve outcomes for people with chronic conditions.
As a sign of the impact Nuna has already made in this space, Nuna was recently selected to join the Centers for Medicare & Medicaid Services (CMS) Health Tech Ecosystem, a landmark public-private initiative designed to transform healthcare for Americans.
YOUR TEAM
The Data org at Nuna is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research.
The Data Engineer team is a core part of the broader Data organization, which is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research. The Data Engineer team acts as the technical backbone for data architecture, platform development, and data operations, empowering the organization to deliver impactful data-driven solutions in healthcare.
YOUR OPPORTUNITIES
We are looking for someone who is excited to use their creativity and engineering skills to make a difference in healthcare. You will have a foundational role on a team building a consumer product that incentivizes healthy behavior. You will be responsible for the data architecture and direction of the data platform that powers our data operations and data science initiatives.
Own the architecture and evolution of the data platform, based on business needs and considering trade-offs in timelines, cost, and resources
Define and enforce standards for code development, contribution, and deployment for data engineering workflows.
Oversee integrations with external services, including data ingestion, distribution, and service-to-service data flows.
Contribute hands-on to data transformations and optimizations
Establish security, governance, and operational best practices for the data platform in collaboration with security and enterprise data engineering teams.
Curate and develop datasets needed to support Data org project deliverables
Collaborate with cross-functional partners in engineering, design, and product to develop solutions
Generate and prioritize new opportunities for improvements
Provide build vs buy assessments and recommendations as the platform expands
QUALIFICATIONS
Required Qualifications
Deep hands-on expertise in designing, coding, developing, and maintaining data platforms that support data analytics and data science use cases
Proven ability to design, develop and implement robust data ingestion pipelines (ETL) from external sources into a data platform.
Experience establishing standards for code development, deployment, and contributions in a data engineering environment.
Ability to solicit and translate customer and business needs into requirements and an evaluation framework
Interest in improving healthcare and working with interdisciplinary project teams
Clear communication and presentation skills
Experience with Databricks
Expertise in data platform languages such as python, pyspark and SQL
+ 5-10 years of industry experience with technical lead experience of running a data platform for business operations
Preferred Qualifications
MS in quantitative field (e.g. Data Science, Economics, Statistics, Engineering)
Experience building a data platform from zero to one
Experience working with healthcare data
Experience with SDLC and management of machine learning models (MLOps)
Bonus points if experience with MLOps on LLM/GenAi features (evals, context building, …)
We take into account an individual’s qualifications, skillset, and experience in determining final salary. This role is eligible for health insurance, life insurance, retirement benefits, participation in the company’s equity program, paid time off, including vacation and sick leave. The expected salary range for this position is $208,000 - $260,000. The actual offer will be at the company’s sole discretion and determined by relevant business considerations, including the final candidate’s qualifications, years of experience, and skillset.
Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status.
#LI-FK1"
2025-12-12T00:00:00,Development Project Engineer (Data Center Construction),QTS Data Centers,"Who we are: It's pretty exciting to find yourself standing in a pivotal moment in time. It’s even more exciting to be out front leading it. At QTS, our world-class data centers are supporting our customers’ most strategic growth initiatives, positioning us at the forefront of today’s dynamic digital transformation. As AI and cloud drive the demand for increased speed, capacity and capability, QTS has emerged as the global digital infrastructure leader, committed to connecting the world for good. Driven by purpose and fueled by a spirit of innovation, QTS designs, builds and operates some of the world’s most advanced, forward-thinking data centers. QTS is a portfolio company of Blackstone. QTS is Powered by People. People who play a vital role in our company’s culture, innovation and growth. People who are committed to contributing to the communities where we operate and work. People who are knowledgeable, resourceful and mission driven. Together, we do great things. Who You Are: The Development Project Engineer (Data Center Construction) is primarily responsible for assisting with the design, preconstruction and construction activities on a given project(s). The Development Project Engineer will interact on a daily basis with Facilities, Contractors, Designers, Engineers, Commissioning Agents, Vendors, and Data Center Operations & Corporate real estate staff and should have both written and oral communication skills commensurate with this level of regular communication. What You Will Do: Assist Development leadership and Project Manager with day to day activities and responsibilities Assist with multiple projects on a campus(es) and maintain updated budgets, schedules, and status reports for each Assist with updates on development program & project status on a monthly basis suitable for executive level reviews. Work with QTS stakeholders, design, and construction teams to help with master development program for site(s), including a complete campus design solution and capital budget. Assist with entitlement and permitting needs for each assigned site project(s) Assist with scopes of work for design, construction, commissioning services & participate in procurement and project cost estimates Evaluate and level pricing proposals for design, construction, and commissioning services Work closely with strategic procurement team on equipment procurement and delivery process Ensure appropriate submittals are coordinated with site stakeholders Assist with monitoring project budget / cost-to-date against overall project budget. Review project schedules and manage teams to on-time completion Review change order requests from contractors and negotiate pricing Assist with establishing site construction security procedures in conjunction with site security team Establish and maintain relationships serving as liaison with key QTS stakeholders Represent QTS Interests in OAC meetings Create & build relationships that enhance QTS’s ability to be a leader in creating the World’s Most Valuable Data Center Real Estate Aid in due diligence efforts on an as-needed basis by participating with real estate efforts on potential or new land banks and properties, including: Evaluate opportunities to design & build new data centers by working with key stakeholders: Corporate Real Estate, Connectivity, Power & Construction teams. Assist with establishing and monitoring entitlement and permit processes for individual projects as needed Work with the internal development team to enhance project management processes and protocols What You Will Need to be Successful (basic qualifications): Bachelor’s degree in Engineering or Construction Management field or equivalent professional experience Experience with Microsoft Office suite, specifically PowerPoint for use in communicating program updates to executive level, and Excel to create and maintain site program & individual project budgets Excellent interpersonal skills with the ability to interface with all levels of the organization Must be a capable, proven team player that both fosters and operates well within internal and external team environments. Able to solve problems at a tactical and functional level Strong Verbal and Written Communication Skills Ability to manage multiple projects simultaneously Other Key Skills: One or more years of professional experience in commercial construction practices and procedures, including management of Lump Sum, Construction Management @ Risk, and Design Build project delivery methods from conceptual development through procurement to close out Documented experience using AutoCAD, BlueBeam, P6, and CxAlloy Experience or exposure in mission critical data center facilities Experience with management of MEP trades Experience managing document control for active data center build sites The Perks (and these are just a few!): Q-Rest Sabbatical Employee Stock Purchase Plan QTS scholarship for dependents Eagle Club Award Trip Eligibility Paid Volunteer and Floating days Tuition Assistance, Parental Leave and Military Leave Assistance We conform to all the laws, statutes, and regulations concerning equal employment opportunities and affirmative action. We strongly encourage women, minorities, individuals with disabilities and veterans to apply to all of our job openings. We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, gender identity, or national origin, age, disability status, Genetic Information & Testing, Family & Medical Leave, protected veteran status, or any other characteristic protected by law. We prohibit retaliation against individuals who bring forth any complaint, orally or in writing, to the employer or the government, or against any individuals who assist or participate in the investigation of any complaint or discrimination claim. The ""Know Your Rights"" Poster is included here: Know Your Rights (English) Know Your Rights (Spanish) The pay transparency policy is available here: Pay Transparency Nondiscrimination Poster-Formatted QTS is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please send an e-mail to talentacquisition@qtsdatacenters.com and let us know the nature of your request and your contact information. It’s exhilarating to find yourself at a pivotal moment in history— and even more so to be leading the way. At QTS Data Centers, we are proud to stand at the forefront of today’s dynamic digital transformation. Our world-class data centers empower our customers’ most strategic growth initiatives, positioning us as a global leader in digital infrastructure. As AI and cloud technologies fuel the demand for increased speed, capacity, and innovation, QTS has emerged as the global digital infrastructure leader. We are committed to connecting the globe for good. Driven by purpose and a spirit of innovation, we design, build, and operate some of the most advanced data centers worldwide. In addition to our cutting-edge technology, we are dedicated to sustainability, incorporating renewable energy solutions to minimize our environmental footprint and drive meaningful impact. As a proud portfolio company of Blackstone, QTS is uniquely positioned to achieve ambitious growth and innovation goals. At QTS, we are Powered by People. Our team members are the cornerstone of our culture, innovation, and growth. They are mission-driven, resourceful, and committed to making a positive impact in the communities where we live and work. Together, we’re achieving remarkable things and shaping the future of digital infrastructure. And we’d like to invite you to join us. In addition to a variety of benefit packages, QTS goes above and beyond for our employees: Roth and Traditional 401(k) matching contributions with immediate vesting Every employee is bonus or commission eligible Generous PTO, Paid Volunteer Days Plus Floating Holidays Stock Purchase Plan (SPP) 11 paid Holidays Annually/Holiday compensation when worked Pet and Legal Insurance Q-Rest Sabbatical Program Q-Anniversary Service Award Program Parental Leave for primary and secondary caregivers Military Benefits Package QTS Charitable Matching Gift Program QTS Scholarship for Employee Dependents QTS Crisis Fund Wellness Program Tuition Reimbursement Program"
2025-12-12T00:00:00,"Data Engineer I, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $109,300.00 - $180,200.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data across the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape by designing, building, and deploying data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning, and business intelligence initiatives. You will work closely with Data Science and Decision Science teams to build, test, and maintain data pipelines and model workflows that support both analytical research and production use cases in our Databricks/AWS/Snowflake environment. In addition to your strong analytical mind, you will bring an inquisitive attitude and the ability to translate the stories found in data into actionable insights while contributing to technical discussions and process improvements. Applicants must be authorized to work for ANY employer in the U.S. The company does not sponsor/support H-1B petitions, TN, or Forms I-983/STEM OPT, for this role. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions. Design data solutions. Analyze sources to determine value and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Collaborate within and across teams to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate. Test data movement, transformation code, and data components. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent. Six years of related experience. Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions. Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on. Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems. Strong verbal and written communication skills with the ability to interact with team members and business partners. Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Four years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,"Senior Data Engineer, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $139,400.00 - $230,000.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions. Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies. Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate. Collaborate across team to support delivery and educate end users on complex data products/analytic environment. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent Ten years of related experience Primary Job Requirements: Architect and design scalable, secure data solutions using AWS, Databricks, and Ab Initio. Lead technical direction for data engineering initiatives across cloud and on-premises infrastructure. Hands-on development: build ETL pipelines, optimize Spark jobs, and create Ab Initio graphs. Troubleshoot production issues and provide technical guidance to junior engineers. Conduct mentoring sessions and offer technical guidance to the 20-person admin team. Collaborate with DBA teams, business analysts, and QA teams to ensure data governance and quality. Manage infrastructure deployment and optimize cloud resources. Lead technical design reviews and architecture discussions. Implement data integration solutions and ensure compliance with data protection regulations. Establish and enforce coding standards, best practices, and data governance policies. Technical Skills: AbInitio: Expert proficiency with GDE, Co>Operating System, EME, BRE, Express>It, metaprogramming (PDL) Programming: Python, PySpark, SQL Cloud: AWS architecture and services Databricks: Workspace management, cluster configuration, Delta Lake, Unity Catalog Data Warehousing: Strong understanding of data modeling, dimensional modeling (star/snowflake schemas) ETL/ELT: End-to-end ETL development lifecycle Version Control: Git, CI/CD pipelines Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices. Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems. Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers. Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize. Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas. Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Five years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,Data Flow Engineer,Scientific Research Corporation,"Description
The Data Flow Engineer will be a member of a Cryptologic Carry-On Program (CCOP) and Ship’s Signals Exploitation Equipment (SSEE) Systems Engineering team primarily responsible for ensuring the processing and distribution of data to and from intelligence community networks. The ideal candidate will have a history of direct involvement with successful NiFi data flow engineering and resolving Navy hardware and software functionality problems by providing a high degree of timely customer service and technical expertise in support of the US Navy information warfare community.
Installing, configuring, integrating, and maintaining NiFi servers and processors into new or existing system architectures
Verifying and maintaining all NiFi processors and flows to and from deployed (and test) systems, from the field system through customer back-end repositories
Assisting end users with the operational readiness and configuration of deployed systems for optimal data flow to satisfy customer requirements
Designing and developing NiFi processors and flows for deployed systems, containing multiple subsystems and requiring integration with external networks
Implementing expression language in NiFi processors in response to emerging customer requirements
Exhibiting developed verbal and written communication skills and the ability to express concepts and ideas in a clear and concise manner; employing technical writing techniques
Performing as a team player, dedicated to the endeavors of the mission, the customer, and the team itself
Being a self-starter who is accountable and requires minimal direction and supervision; capable of multitasking and working several complex and diverse tasks with simultaneous or near simultaneous deadlines
#LI-LL1
Requirements
Must possess an active TS/SCI clearance and be able to obtain a CI Polygraph
Requires a bachelor’s degree in related technical field or equivalent work experience
Intermediate Linux Command Line Interface (CLI) experience
1-3 years of Apache Niagara Files (NiFi) experience (negotiable with other qualifications)
Strong background in using and troubleshooting Software Defined Radio (SDR) systems
Fundamental knowledge of wireless protocols in common use
Experience providing technical support to customers over Internet Relay Chat (IRC) or similar applications
Familiarity with back-end databases and repositories
Must be willing to travel up to 10% of the year
Must currently be DoD 8570-compliant with the equivalent of an IAT II certification or have the ability to do so within 6 months of employment
Desired Skills
Current Linux+/LPIC 1 and/or Network+ certification
Familiarity with Regular Expression (REGEX), Cisco Networking, and Amazon Web Services (AWS)
Expert-level SDR knowledge and experience
Experience with strategic-level intelligence processes
Basic computer programing experience (i.e. Python, JavaScript, bash)
Prior Navy CTR/CTM/CTN with shipborne, expeditionary, or other comparable experience 
Clearance Information
SRC IS A CONTRACTOR FOR THE U.S. GOVERNMENT. THIS POSITION WILL REQUIRE U.S. CITIZENSHIP AS WELL AS A U.S. GOVERNMENT SECURITY CLEARANCE AT THE TOP SECRET / SCI LEVEL with CI POLY ELIGIBILITY
Travel Requirements
up to 10% travel may be required
About Us
Scientific Research Corporation is an advanced information technology and engineering company that provides innovative products and services to government and private industry, as well as independent institutions. At the core of our capabilities is a seasoned team of highly skilled engineers and scientists with multidisciplinary backgrounds. This team is challenged daily to provide cutting edge technology solutions to our clients.
SRC offers a generous benefit package, including medical, dental, and vision plans, 401(k) with a company match, life insurance, vacation and sick paid time off accruals starting at 10 days of vacation and 5 days of sick leave annually, 11 paid holidays, tuition reimbursement, and a work environment that encourages excellence and more. For positions requiring a security clearance, selected applicants will be subject to a government security investigation and must meet eligibility requirements for access to classified information.
EEO
Scientific Research Corporation is an equal opportunity employer that does not discriminate in employment.
All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other protected characteristic under federal, state or local law.
Scientific Research Corporation endeavors to make www.scires.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact jobs@scires.com for assistance. This contact information is for accommodation requests only and cannot be used to inquire about the status of applications."
2025-12-12T00:00:00,"Research Data Engineer II, CHeT Analytics",University of Rochester,"As a community, the University of Rochester is defined by a deep commitment to Meliora - Ever Better. Embedded in that ideal are the values we share: equity, leadership, integrity, openness, respect, and accountability. Together, we will set the highest standards for how we treat each other to ensure our community is welcoming to all and is a place where all can thrive. Job Location (Full Address): 265 Crittenden Blvd, Rochester, New York, United States of America, 14642 Opening: Worker Subtype: Regular Time Type: Full time Scheduled Weekly Hours: 40 Department: 400980 Neuro-Ctr Health & Tech/Admin Work Shift: UR - Day (United States of America) Range: UR URG 113 Compensation Range: $77,216.00 - $115,824.00 The referenced pay range represents the minimum and maximum compensation for this job. Individual annual salaries/hourly rates will be set within the job's compensation range, and will be determined by considering factors including, but not limited to, market data, education, experience, qualifications, expertise of the individual, and internal equity considerations. Responsibilities: GENERAL PURPOSE Participates in the design, implementation and maintenance of analytical and data science-based software and data pipelines to support scientific workflows. Focuses on developing and supporting data collection frameworks that integrate structured and unstructured data from multiple sources and systems to support specific research study teams. Supports the development and maintenance of infrastructure systems (e.g., data warehouses, data lakes), including data access Application Programming Interface(s) (APIs). Works in partnership with team members to provide robust, scalable software solutions to the research enterprise. ESSENTIAL FUNCTIONS Builds, maintains and evolves general Extract, Transform and Load (ETL) data pipelines and overall data architecture to accommodate a growing amount of data from a variety of large research data sources. Works with research team members to convert business and technical requirements into professional software solutions. Ensures timely completion of tasks while managing multiple assignments, project timelines and business user expectations. Designs and implements custom research project-specific data workflow solutions for data collection, management, reporting and analytics. Contributes to the scientific research. Adheres to defined application development life-cycle practices, including but not limited to, requirements gathering, writing test plans, source code management, peer code review and quality assurance through unit/system/user acceptance testing. Participates in specification, implementation and execution of testing procedures to ensure quality of deliverables, system and data workflow reliability. Produces and maintains comprehensive technical documentation for all systems under the Engineer's responsibilities. Keeps abreast of current application developments through continuing education, professional reading, online forums, conferences, workshops and professional groups. Other duties as assigned. MINIMUM EDUCATION & EXPERIENCE Bachelor's degree in Data Science, Biomedical Science, Computer Science, Mathematics, Statistics or similar discipline and 2 years of experience in technology and data intensive roles and environments required Or equivalent combination of education and experience Programming experience in Structured Query Language (SQL) and one other applicable language (Java, Python, and/or R) required Experience with Change Management solutions required Experience with Version Control solutions (e.g. Git) required Experience implementing and supporting data management systems in a scientific, research context (e.g. biospecimen software, electronic laboratory notebooks, REDCap) preferred Experience with Linux, container and cloud technologies (e.g. HPC, IaaS and PaaS) preferred KNOWLEDGE, SKILLS AND ABILITIES Understanding of data analytics and statistical methods required Expertise of software engineering best practices such as version control and software release management required Strong analytical and problem-solving skills required Strong organizational skills required Ability to work with others in a matrix management environment required Excellent communication skills for describing progress and challenges to stakeholders required Attention to detail, patience and a positive, customer-centric attitude required Strong technical presentation skills required Demonstrated ability to develop proficiency with unfamiliar toolsets preferred Familiarity with file formats, metadata, and data exchange and storage standards applicable in management of scientific and clinical research required The University of Rochester is committed to fostering, cultivating, and preserving an inclusive and welcoming culture to advance the University’s Mission to Learn, Discover, Heal, Create – and Make the World Ever Better. In support of our values and those of our society, the University is committed to not discriminating on the basis of age, color, disability, ethnicity, gender identity or expression, genetic information, marital status, military/veteran status, national origin, race, religion, creed, sex, sexual orientation, citizenship status, or any other characteristic protected by federal, state, or local law (Protected Characteristics). This commitment extends to non-discrimination in the administration of our policies, admissions, employment, access, and recruitment of candidates, for all persons consistent with our values and based on applicable law. Notice: If you are a Current Employee, please log into myURHR to search for and apply to jobs using the Jobs Hub. Your application, if submitted using this portal, cannot be moved forward. Learn. Discover. Heal. Create. Located in western New York, Rochester is our namesake and our home. One of the world’s leading research universities, Rochester has a long tradition of breaking boundaries—always pushing and questioning, learning and unlearning. We transform ideas into enterprises that create value and make the world ever better. If you’re looking for a career in higher education or health care, the University of Rochester may offer the perfect opportunity for your background and goals. At the University of Rochester, we are committed to fostering, cultivating, and preserving an inclusive and welcoming culture and are united by a strong commitment to be ever better—Meliora. It is an ideal that informs our shared mission to ensure all members of our community feel safe, respected, included, and valued."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,Data Engineer II (Onsite),RTX,"Date Posted: 2025-12-12 Country: United States of America Location: PW147: PW OKC Campus 8120 S. Air Depot Blvd , Oklahoma City, OK, 73135 USA Position Role Type: Onsite U.S. Citizen, U.S. Person, or Immigration Status Requirements: U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Security Clearance: None/Not Required Pratt & Whitney is working to once again transform the future of flight—designing, building and servicing engines unlike any the world has ever seen. And because transformation begins from within, we’re seeking the people to drive it. So, calling all curious. Come ready to explore and you’ll find a place where your talent takes flight—beyond the borders of title, a country or your comfort zone. Bring your passion and commitment and we’ll welcome you into a tight-knit team that takes our mission personally. Channel your drive to make a difference into shaping an organization and an industry that’s evolving fast to the future. At Pratt & Whitney, the difference you make is on display every day. Just look up. Are you ready to go beyond? You will be an integral part of Pratt & Whitney’s Sustainment Operational Excellence Data Engineering & Analytics team. This team supports the global aftermarket maintenance and overhaul of engines for the F117, F119, and F135 programs. We are looking for a Data Engineer II to advance the digital and data capability of the Military Engines Global Depot Network organization. You will be working on exciting new technologies like cloud and open-source tools among others, and be responsible for cleaning, standardizing, transforming, and configuring data products within our emerging data mesh. What You Will Do: Create and maintain scripts written in Spark SQL or Pyspark in Databricks Notebooks. Also, work with SMEs to understand complex datasets for next generation data products and data visualizations to create data mesh tables. Develop scalable and sustainable data product transformations that curate, clean and store data efficiently; perform statistical analysis to quantify completeness and validity; perform bug fixes and apply enhancements to the models when the need arises. Ensure high performance and reliability of data transformation processes and pipelines. Collaborate cross-functionally to gather insights, refine requirements, and ensure alignment between product goals and team efforts. Document data processes, logic, and data sources to ensure transparency and knowledge sharing as well as support the overall team with any ad-hoc data related tasks. Work to convert our existing data visualizations in Power BI to use Databricks instead of Azure Synapse. Keep up to date with technologies and use advanced cloud data warehouse and data transformation techniques to build innovative solutions. Qualifications You Must Have: A degree in Science, Technology, Engineering or Mathematics (STEM) with 2+ years of experience in the use of SQL and/or Python to transform, clean, and integrate data from a variety of source pipelines. U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Qualifications We Prefer: Experience with transformation tools such as dbt, Databricks pipelines, or relevant tools such as SSIS, ADF, or Matillion. Demonstrated experience with Git/GitHub; experience working in cloud data warehouses like Databricks. Familiarity with agile methodologies and Kanban boards. Self-motivated, team player with good communication skills. Ability to focus on results and successfully manage multiple tasks/projects. An astute individual, with the ability to build strong cross-functional relationships; excited at the prospect of developing and implementing new data products that add organizational value & improve decision making capabilities. Business experience with Aerospace or other heavy manufacturing industry. An understanding of ER Diagrams for data modeling. Demonstrated understanding of data mesh design principles and data engineering best practices. Learn More & Apply Now! What is my role type? In addition to transforming the future of flight, we are also transforming how and where we work. We’ve introduced role types to help you understand how you will operate in our blended work environment. This role is: Onsite: Employees who are working in Onsite roles will work primarily onsite. This includes all production and maintenance workers, as they are essential to the development of our engines. Candidates will learn more about role type and current site status throughout the recruiting process. For onsite and hybrid roles, commuting to and from the assigned site is the employee’s personal responsibility. As part of our commitment to maintaining a secure hiring process, candidates may be asked to attend select steps of the interview process in-person at one of our office locations, regardless of whether the role is designated as on-site, hybrid or remote. The salary range for this role is 66,000 USD - 130,000 USD. The salary range provided is a good faith estimate representative of all experience levels. RTX considers several factors when extending an offer, including but not limited to, the role, function and associated responsibilities, a candidate’s work experience, location, education/training, and key skills. Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement. Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company’s performance. This role is a U.S.-based role. If the successful candidate resides in a U.S. territory, the appropriate pay structure and benefits will apply. RTX anticipates the application window closing approximately 40 days from the date the notice was posted. However, factors such as candidate flow and business necessity may require RTX to shorten or extend the application window. RTX is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or veteran status, or any other applicable state or federal protected class. RTX provides affirmative action in employment for qualified Individuals with a Disability and Protected Veterans in compliance with Section 503 of the Rehabilitation Act and the Vietnam Era Veterans’ Readjustment Assistance Act. Privacy Policy and Terms: Click on this link to read the Policy and Terms RTX is an aerospace and defense company that provides advanced systems and services for commercial, military and government customers worldwide. It comprises three industry-leading businesses – Collins Aerospace, Pratt & Whitney, and Raytheon. Its 195,000 employees enable the company to operate at the edge of known science as they imagine and deliver solutions that push the boundaries in quantum physics, electric propulsion, directed energy, hypersonics, avionics and cybersecurity. The company, formed in 2020 through the combination of Raytheon Company and the United Technologies Corporation aerospace businesses, is headquartered in Arlington, Virginia."
2025-12-12T00:00:00,"Senior Engineer, BAW R&D Trimming and Data Infrastructure",Qorvo,"
                Qorvo (Nasdaq: QRVO) supplies innovative semiconductor solutions that make a better world possible. We combine product and technology leadership, systems-level expertise and global manufacturing scale to quickly solve our customers' most complex technical challenges. Qorvo serves multiple high-growth segments of large global markets, including consumer electronics, smart home/IoT, automotive, EVs, battery-powered appliances, network infrastructure, healthcare and aerospace/defense. Visit www.qorvo.com to learn how our innovative team is helping connect, protect and power our planet.

 
Summary:
 Qorvo’s BAW R&D Data Infrastructure team is seeking a talented engineer for semiconductor data infrastructure, frequency trimming and process automation. The candidate chosen for this role will develop data infrastructure and software tools to support efficient development and production of new Bulk Acoustic Wave (BAW) filter technologies. The candidate will use MATLAB, data analysis tools (SpotFire), databases and other software tools for process control improvements, faster design cycles, and general automation to efficiently develop and produce new technologies.
 
Key Roles and responsibilities:

Research, implement, deploy, and maintain internal software applications used by Manufacturing and R&D Engineering teams to process and trim BAW filters wafers.
Work closely with Process Integration and Process Engineering teams to understand new BAW technology needs to define requirements and implement.
Provide comprehensive support to internal customers: resolve outstanding issues for R&D engineers, designers, and production at Qorvo’s fabrication facility.
Own critical data infrastructure projects and successfully deliver results in a timely manner

 
Technical Knowledge/Skills/Abilities Required:

Excellent MATLAB or Python programming capabilities
Knowledge of semiconductor processing
Practical knowledge of software development and object-oriented programming
Excellent debugging and problem-solving skills


Strong data analysis and mathematical skills


Experience with version control utilizing Git and GitLab
Good knowledge of SQL database (Oracle is a plus)
Experience in the full life cycle of the software design process including requirement analysis, design, prototyping, coding, documentation, implementation, and maintenance

 
Personal Skills:

Self-motivated, independent, proactive, detail oriented, and responsible team-player
Excellent analytical skills
Comfortable working in a dynamic and fast paced environment
Passion for innovation and emerging technologies
Excellent communication and interpersonal skills
Able to handle multiple priorities
Proficient in English

 
Desired experiences:

Experience with software development for semiconductor processing 
Expertise in electromagnetics, physics, or material science
Expertise in Oracle PL/SQL databases
Experience with data analysis tools such as Spotfire or similar application
Experience with GitLab workflows and pipeline automation 
Experience with Visual Studio Code and GitHub Copilot
Experience with unit testing in past development projects

 
Qualifications:
Education & Experience:

BS or MS in Computer Science, Electrical Engineering, Physics or Material Science
5+ years of code development experience.(or if Master's degree 2+ years experience)

 
This position is not eligible for visa sponsorship by the Company.
 
#LI-KR1
 MAKE A DIFFERENCE AT QORVO   

 We are Qorvo. We do more than create innovative RF and Power solutions for the mobile, defense and infrastructure markets – we are a place to innovate and shape the future of wireless communications. It starts with our employees. As a unified global team, we bring a commitment to excellence, growth and a passion for creating what's next. Explore the possibilities with us.

We are an Equal Employment Opportunity (EEO) employer and welcome all qualified applicants. Applicants will receive fair and impartial consideration without regard to any characteristics protected by applicable law, including race, color, religion, sex (as defined by law), national origin, age, military or veteran status, genetic information, or disability.  
                
    "
2025-12-12T18:28:05.616,Sr Staff Engineer Software (Data Plane Applications),Palo Alto Networks,"Company Description
Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
Who We Are
We believe collaboration thrives in person. That’s why most of our teams work from the office full time, with flexibility when it’s needed. This model supports real-time problem-solving, stronger relationships, and the kind of precision that drives great outcomes.
Job Description
Your Career
Prisma Access™ (formally GlobalProtect Cloud Service) provides protection straight from the cloud to make access to the cloud secure. It combines the connectivity and security you need and delivers it everywhere you need it. Using cutting-edge public and private cloud technologies extending the next-generation security protection to all cloud services, customers on-premise remote networks and mobile users.
We are seeking an experienced Software Engineer to design, develop and deliver next-generation technologies within our Prisma Access team. We want passionate engineers who love to code and build great products. Engineers who bring new ideas in all facets of software development. We are looking for leaders who take ownership of their areas of focus and who are driven to solve problems at every level. Collaboration and teamwork are at the foundation of our culture and we need engineers who can communicate at a high level and work well with others towards achieving a common goal.
Your Impact
Design, develop and implement highly scalable software features and infrastructure on our next-generation security platform ready for cloud native deployment from inception to completion
Work with different development and quality assurance groups to achieve the best quality - You accomplish this by being hands-on, creating tools, processes, and systems that produce transparency, alignment, and direction
Profile, optimize and tune systems software (management/control/dataplane) for efficient cloud operation
Work with DevOps and the Technical Support teams to troubleshoot customer issues
Work with other software development team to apply PanOS features on Prisma Access
Interview, mentor and coach new team members 
Qualifications
Your Experience 
5+ years of experience in developing and troubleshooting dataplane applications
Required hands-on programming experience in Python and Go
Nice to have C/C++ Programming
Strong Data structures/Algorithms
Strong analytical skills, problem solving and debugging skills
Nice to have experience with LLMs and GenAI applications. Or Machine learning/Data science with experience in ETL, curating datasets, running evals. 
Experience with building applications in the cloud
In-depth understanding of Operating System principles and OS like Linux/Unix
In-depth understanding of networking concepts and TCP/IP stack, TLS
Exposure to building Microservices 
Enjoys working with many different teams with strong collaboration and communication skills
Solid foundation in design, data structures, and algorithms, and strong analytical and debugging skills
Education : M.S./B.S. degree in Computer Science or equivalent military experience required
Additional Information
The Team
Our engineering team is at the core of our products – connected directly to the mission of preventing cyberattacks. We are constantly innovating – challenging the way we, and the industry, think about cybersecurity. Our engineers don’t shy away from building products to solve problems no one has pursued before.
We define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment.
Compensation Disclosure
The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $170,000 - $190,000/YR. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.
Our Commitment

We’re problem solvers that take risks and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at [email protected].
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
Is role eligible for Immigration Sponsorship?: Yes"
2025-12-12T18:20:27,Data Engineer,Real Chemistry,"At Real Chemistry, making the world a healthier place isn’t just an aspiration—it’s our everyday reality. Our drive to transform healthcare is informed by our blend of deep scientific expertise, human-centred creativity, and AI-driven insights, fostering a unique environment where innovation thrives and our people are impact-obsessed. As a global agency, we provide a full suite of services across healthcare communications and marketing to our clients, including top players in the pharmaceutical and biotech industries.
Our #LifeatRealChem culture is rooted in our people—we believe we are best together and are committed to excellence for both our clients and colleagues. Whether you're a seasoned professional or just starting your career, if you share our passion for healthcare and connection, we invite you to explore our opportunities.
Discover your purpose. Embrace innovation. Experience #LifeatRealChem.
Job Summary 
We’re looking for a hands-on Data Engineer to help build and maintain the data infrastructure that powers our AI products and solutions. This role sits within our AI organization and focuses on designing, developing, and optimizing scalable data pipelines, data models, and cloud-based data systems. You’ll collaborate closely with data scientists, ML engineers, product teams, and other technical partners to ensure high-quality, reliable, and well-structured data is available across the organization. 
Key Responsibilities 
Data Pipeline Development 
Build, optimize, and maintain scalable ETL/ELT pipelines for structured and unstructured data. 
Implement reliable, fault-tolerant ingestion and transformation workflows. 
Automate routine data processes where possible. 
Data Architecture & Modeling 
Develop well-structured data models that support analytics, ML use cases, and downstream applications. 
Support the design and enhancement of AI-related data architecture across cloud environments. 
Data Quality & Governance 
Implement automated data validation, monitoring, and alerting. 
Ensure high data accuracy, completeness, and integrity across ingestion and transformation layers. 
Cross-Functional Collaboration 
Partner with data scientists, ML engineers, product managers, and IT teams to understand data requirements and translate them into technical solutions. 
Troubleshoot issues and support stakeholders with data access and pipeline improvements. 
Cloud & Infrastructure 
Work with modern cloud platforms (AWS, Azure, or GCP) and associated data storage, compute, and orchestration services. 
Support deployment, scaling, and operational health of data systems. 
Innovation & Continuous Improvement 
Stay current with emerging data engineering tools and best practices. 
Propose opportunities to improve performance, efficiency, or reliability within the data stack. 
Qualifications & Skills 
Education & Experience 
Bachelor’s degree in Computer Science, Data Engineering, or related technical field (or equivalent experience). 
3–7 years of hands-on experience in data engineering or data pipeline development. 
Technical Skills 
Strong SQL skills and proficiency in Python or Scala. 
Experience with data warehousing technologies such as Snowflake, BigQuery, Redshift, or Databricks. 
Hands-on experience with cloud services (AWS, Azure, or GCP). 
Knowledge of data modeling, schema design, and ETL/ELT principles. 
Familiarity with distributed computing frameworks such as Spark or Flink. 
Experience with workflow orchestration tools like Airflow, Prefect, or Dagster is a plus. 
Soft Skills 
Strong problem-solving skills and attention to detail. 
Ability to communicate technical concepts clearly to peers and cross-functional partners. 
Comfortable working in a fast-moving, collaborative environment. 
Preferred Qualifications 
Experience with streaming data tools such as Kafka or Kinesis. 
Experience building CI/CD pipelines for data workflows. 
Experience in healthcare, biotech, life sciences, or commercial/marketing data environments. 
Experience in agency or consulting settings. 
Posting Salary
$140,000—$175,000 USD
Real Chemistry is proud to be Great Place to Work® certified; check out what our people shared about our culture and workplace on our Great Places to Work Profile here.
We believe we can do our best when feeling our best, which is why we’ve put together a benefits program designed to give you the support you and your family need at every stage of life. Real Chemistry offers a comprehensive benefit program and perks, tailored to your region. Globally, this includes offices in our key markets with free snacks to keep you running all day long, generous holiday and paid time off, options for private medical, dental, and vison plans, and support in saving for the future. Other perks include mental wellness coaching and support and access to more than 13,000 online classes with LinkedIn Learning. Learn more about our great benefits and perks and search specific offerings in your region at: www.realchemistrybenefits.com.
Working with Real HART: Since the pandemic, we have adapted to how our people told us they want to work. We have office locations in cities in the US, UK, and Europe with many employees and clients that serve as hubs where and when they need us. For employees who are within an hour of one of our offices, we expect attendance in the office two days per week, either at a Real Chemistry office or onsite with clients. We are also actively opening new office locations, so if one opens near you, our Real HART policy will apply. We are not looking for attendance for the sake of attendance but believe that the opportunity to coordinate in-office team meetings, 1:1 meetings with managers, taking advantage of on-site learning, and connecting with client partners is a critical to delivering on our purpose of making healthcare what it should be. Outside of these offices, we have regions, where people work remotely but come together quarterly for collaboration, culture and learning opportunities. We call this our Real Hybrid and Regional Teams (Real HART) approach. Real Chemistry believes we are best together – and our workplace strategy fosters connection and collaboration in person – but also supports flexibility for our people.
Real Chemistry is an Equal Opportunity employer. We continually strive to build and sustain an inclusive and equitable work environment where our employees feel empowered to leverage all they bring from their personal lived experience and professional expertise, to make our team the best in the industry. We encourage motivated and qualified applicants to apply without regard to race, color, religion, sex (including pregnancy), sexual orientation, gender identity/expression, ethnic or national origin, age, physical or mental disability, genetic information, marital information, or any other characteristic protected by federal, state, or local employment discrimination laws where Real Chemistry operates. Should you require accommodations throughout the interview process please let your recruiter know.
*Notice: Real Chemistry and its affiliates' names are being misused by scammers through messaging services, fake websites, and apps. Do not share personal or financial information or make payments to any unverified sources claiming to be connected to Real Chemistry. We are working to stop these unauthorized activities and protect our community. Read more here."
2025-12-12T17:29:23,Senior Python Data Engineer - (Remote)  ,KBRA,"Position Title: Senior Python Data Engineer - (Remote) 
Entity: KBRA Holdings LLC
Employment Type: Full-Time
Location: Remote (Remote only in CA, CO, DC, FL, IL, MD, NJ, MA, NY, PA, SC, TX, VA)
Summary/Overview:
KBRA (KBRA Holdings, LLC) is seeking an engaged and proactive Senior Python Data Engineer to work on our financial analytical system. We want someone who loves solving difficult problems, digs deeply to understand the domain in which they’re working, and excels at creating high-quality software in a collaborative environment.
About the Team:
We believe that small, empowered teams can do amazing things. Across the engineering organization, we work hard to make the best systems for our customers using modern engineering practices. We are intentional in our investments in time and effort around creating a safe and successful workplace for our team members. We understand software engineering goes beyond the 1’s and 0’s and prioritize concrete value for our customers.
About the Job:

This role involves joining an existing team with a well-defined product vision. This team operates collaboratively, and there is an expectation to get involved in all aspects of design, delivery, and support of our systems.

This role emphasizes collaboration with our technical and non-technical counterparts to learn our domain and its unique challenges, while delivering value to our customers. It also requires collaboration with our other engineering, design, product, and platform teams to develop, build, run, and support the system.
About You:

You will be successful in this role if you:
Develop, test, and maintain scalable Python applications.
Collaborate with product managers, designers, and other engineers to deliver high-quality software.
Write clean, efficient, and reusable code following best practices.
Participate in code reviews to ensure code quality and share knowledge with the team.
Troubleshoot and debug issues in a timely manner.
Contribute to the design and architecture of new features and systems.
Have a sense of ownership and craftsmanship around the code base and your work.
Enjoy helping other developers grow and learn new technologies.
Display a strong track record of mentorship with engineers at various levels.
Are mindful of application security and performance.
Take pride in learning, and want opportunities to learn throughout your day-to-day.
Possess a pragmatic mindset. 
Familiarity with Generative AI tools such as ChatGPT for research, data insights, and general productivity is a plus.
Must have skills:
3–6 years of professional software engineering experience, with a strong portfolio of full stack development work.
Proficiency in Python, including experience with web frameworks such as Flask.
Cloud experience, particularly with AWS (Amazon Web Services).
Experience integrating frontend applications with RESTful APIs and backend services.
Relational and non-relational databases (SQL Server, Snowflake and MongoDB).
Debugging, issue resolution, and troubleshooting.
Nice to have skills:
Familiarity with UX design tools (Figma) and solid understanding of the design-engineering hand-off process
Containerized development and deployment (i.e. Docker, Docker swarm, Kubernetes)
Infrastructure as Code (Terraform)
Familiarity with deployment pipelines, CICD tools.
Exposure to financial systems or credit modeling is strongly preferred.
Salary Range:
The anticipated annual base salary range for this full-time position is $130,000 - $160,000. Offer amounts are determined by factors such as experience, skills, geography, and other job-related factors.
Benefits:
Competitive benefits and paid time off
Paid family and disability leave
401(k) plan, including employer match (100% vested)
Educational and professional development financial assistance
Employee referral bonus program
About Us:
KBRA is a full-service credit rating agency registered in the U.S., the EU and the UK, and is designated to provide structured finance ratings in Canada. KBRA’s ratings can be used by investors for regulatory capital purposes in multiple jurisdictions.
More Info:
KBRA encourages applications from all qualified individuals without regard to race, color, religion, gender, sexual orientation, gender identity or expression, age, national origin, marital status, citizenship, disability, and veteran status or any other basis prohibited by federal, state or local law.
#LI-KS1
#REMOTE"
2025-12-12T17:19:54,Data Platform Engineer,Dragonfli Group,"Dragonfli Group is a cybersecurity and IT consulting firm providing services to federal agencies and Fortune 100 enterprises. Headquartered in Washington, DC, Dragonfli supports clients in securing mission-critical systems across on-site, hybrid, and fully remote environments.

This contract Data Platform Engineer role supports a large federal agency in protecting security data platforms within a large-scale IT environment. The engineer will manage security data platforms such as Splunk and data lakes, ensuring effective data flows, integrations, and platform support. Key technologies include Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS. The role requires seasoned IT security expertise, hands-on technical skills, and strong communication and planning abilities. It's a high-impact opportunity to shape security analytics capabilities within a major federal agency.

This is a multi-year contract position involving a large US federal agency. Candidates with previous federal contracting experience are preferred. U.S. Citizenship or Permanent Residency required. If hired, all work related to this role must be performed within the continental U.S.

Responsibilities:
Manage security data platforms, such as Splunk and data lakes.
Ensure effective data flows, integrations, and platform support.
Support event ingestion, platform maintenance, and technical add-ons.
Troubleshoot to support operational and compliance reporting.
Optimize data use for security monitoring, incident response, and threat analysis.
Collaborate across teams to enhance security analytics capabilities.
Configure and maintain various event ingestion methods.
Create and maintain custom TAs for data parsing into Splunk CIM format.
Monitor and perform routine maintenance of data systems.
Drive process improvements and attention to detail.

Requirements
Four (4)+ years of experience supporting enterprise data platforms.
BS/BA in a cyber-related field or equivalent experience/certifications.
Experience with installing, updating, and maintaining ELM and SIEM.
Proficiency with Splunk (ES, UBA, CORE), Crib, Red Hat OS, and VMware OS.
Experience configuring and maintaining event ingestion methods.
Ability to create and maintain custom TAs for Splunk.
Experience in troubleshooting, monitoring, and maintaining data systems.
Familiarity with enterprise security operations.
Strong cross-functional communication skills.

Skill(s)
Hands-on management of security data platforms.
Expertise in data flows and platform integrations.
Proficiency in Splunk and related technologies.
Strong troubleshooting and problem-solving skills.
Ability to optimize security monitoring and incident response.
Excellent cross-functional communication abilities.
Attention to detail and process improvement mindset.
Ability to work collaboratively across teams.
Strong planning and organizational skills.

Benefits
Insurance – health, dental, and vision
Paid Time Off (PTO) and 11 Federal Holidays
401(k) employer match

Travel
null"
2025-12-12T16:50:01,Staff Configuration Data Engineer,Archer,"Archer is an aerospace company based in San Jose, California building an all-electric vertical takeoff and landing aircraft with a mission to advance the benefits of sustainable air mobility. We are designing, manufacturing, and operating an all-electric aircraft that can carry four passengers while producing minimal noise.
Our sights are set high and our problems are hard, and we believe that diversity in the workplace is what makes us smarter, drives better insights, and will ultimately lift us all to success. We are dedicated to cultivating an equitable and inclusive environment that embraces our differences, and supports and celebrates all of our team members.
What you'll do:
As the Configuration Data Engineer, you will combine software development expertise with configuration management practices to safeguard product data integrity, traceability, and compliance. You will design tools, reports, and automations that enable engineering and product teams to make faster, more accurate configuration decisions.
Develop and maintain tools and reports to monitor bills of materials (BOMs), effectivity assignments, and configuration changes
Create automated quality checks to validate workflows and ensure compliance with configuration management standards
Integrate with Teamcenter APIs and background services to access, analyze, and validate engineering data
Build automation scripts to support NX, CATIA, and other CAD-driven workflows (NX Open, CATIA VB, Check-Mate, NX Check-Mate)
Support the definition, maintenance, and auditing of BOM structures, unit effectivity, and date-based effectivity for engineering changes
Develop dashboards and metrics reporting to provide visibility into change requests, change notices, and configuration status accounting
Collaborate with configuration management, engineering, and IT teams to streamline data flow across systems
Investigate data anomalies and provide corrective recommendations to maintain design and change integrity
Partner with project teams to ensure effectivity assignments are properly implemented and reflected in reports
Contribute to the improvement of enterprise configuration management processes through data-driven insights
Serve as a technical resource to CM specialists for reporting, automation, and API usage
What You Need
To be a self starter with a strong desire to learn new technologies
Ability to translate engineering/CM requirements into automated solutions
2+ years of experience developing tools and reports for a Product Lifecycle Management (PLM) tools (e.g., Teamcenter, Windchill, Enovia, 3DX) or equivalent engineering data environments
Experience with relational databases (SQL, PostgreSQL, Oracle) for reporting and automation
Ability to interpret engineering drawings, CAD data, and metadata
Understanding of BOM structures, unit effectivity, and date-based effectivity methods
Familiarity with engineering change processes, including Change Requests (CRs) and Change Notices (CNs)
Experience with scripting or automation in CAD/PLM environments (NX Open, CATIA VB, or similar)
Strong problem-solving skills and ability to analyze complex datasets for process improvements
Effective written communication skills to document procedures and produce clear reports
Ability to work in a collaborative environment across engineering, CM, and IT teams
Bonus Qualifications
Hands-on experience with Siemens Teamcenter APIs or integrations
Experience with Business Intelligence tools such as Power BI, Sigma, or SAP Hana
Experience with ITI CADIQ tools and CAD data validation workflows
Experience with Elysium CAD Translation tools
Familiarity with NX Check-Mate and automations
Familiarity with ASME Y14.5 Dimensioning and Tolerancing
Experience developing Adobe Forms with JavaScript and PDF publishing workflows
Exposure to aerospace, automotive, or other complex product development environments
Knowledge of configuration management standards and compliance practices (CMII, EIA-649, etc.)
This role is ideal for engineers who enjoy bridging software development with product lifecycle control. You will directly impact how engineering data is managed, ensuring accuracy, efficiency, and compliance across the enterprise
Archer is committed to working with and providing reasonable accommodations to job applicants with physical or mental disabilities, and those with sincerely held religious beliefs. Applicants who may require reasonable accommodation for any part of the application or hiring process should provide their name and contact information to Archer’s People Team at people@archer.com. Reasonable accommodations will be determined on a case-by-case basis.
Information collected and processed as part of any job applications you choose to submit is subject to Archer's Candidate Privacy Policy.
Archer is unable to provide work visa sponsorship for this position at the present time.
Archer is proud to be an Equal Opportunity employer committed to diversity and inclusivity in the workplace. All aspects of employment are decided on the basis of merit, qualifications, and business needs. We do not discriminate based upon race, color, religion, sex, sexual orientation, age, national origin, disability status, protected veteran status, gender identity or any other characteristic protected by federal, state or local laws.
Archer Aviation does not engage with external recruiting agencies/individual recruiters with whom it does not have a prior written agreement. Archer reserves the right to make use of any unsolicited resumes that it receives and bears no responsibility for payment of any fees asserted from the use of unsolicited resumes. If you are a recruiting agency or individual recruiter wishing to do business with Archer, please reach out to People@archer.com. All employment processes are managed by the Archer People Team."
2025-12-12T16:14:31,Data Engineer - Integrated Supply Chain,Textron,"Data Engineers build and maintain data systems in support of data analytics and data science activities. The Data Engineer will implement methods to improve data reliability, data quality, and ensure success in data-driven initiatives.
This position within Integrated Supply Chain Analytics is responsible for identifying, developing, and executing solutions that support reliable and efficient extraction of data from source systems and loading of that data into analytic platforms. The Data Engineer will help administer data platforms and consult with data analysts and data scientists on process optimization and data quality improvements.
At Textron Aviation, we are building a community of Data & Analytics professionals with an emphasis on collaboration and cross functional support. You will have the opportunity to work closely with your peers throughout the organization toward a vision of data driven strategy.


JOB RESPONSIBILITIES:
· Gain core business understanding of Textron Aviation and aircraft design, operation, and support
· Query, clean, transform, and stage data (ETL/ELT) across on-prem and cloud environments
· Support data analytics and data science activities by implementing, maintaining, and optimizing production ready data pipelines
· Install and update software to ensure data platform continuity
· Administer a CI/CD compliant code repository during development and update activities
· Research and help implement new technologies to support analytics function
· Interface with other data professionals throughout the organization to embrace cross functional growth in analytics capabilities
· Work to improve data quality by assisting data governance efforts in creating and maintaining data quality standards
· Plan and execute projects according to established milestones and schedules
· Train users in data & analytic tools and processes per best practices and compliance standards
· Contribute to the resolution of service tickets pertaining to data infrastructure
· Serve as an internal consultant to business leaders by advising on system capabilities
EDUCATION/ EXPERIENCE:
· Bachelor’s degree in Computer Science, Software Engineering, Data Science/Analytics, MIS, or other related technical field
· Minimum 2 years relevant technical experience required, focused on data collection, utilization, and analysis.
· Aviation experience preferred
Textron Aviation Inc. must comply with U.S export control laws and regulations. If a position requires access to sensitive information controlled under these laws and regulations, a successful applicant must be eligible to meet any requirements to access controlled information."
2025-12-12T16:07:56,Senior Data Engineer ,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:55,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T16:07:54,Senior Data Engineer,SpotOn: Product,"About SpotOn
We’re not just building restaurant tech—we’re giving independent restaurants the tools to compete and win. From our award-winning point-of-sale to AI-powered profit tools, everything we do helps operators boost profit, work smarter, and keep their best people. And every solution is backed by real humans who actually give a sh*t about helping restaurants succeed.
Named the #1 Restaurant POS by G2 (Fall 2025), based on ratings from real users
Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users
Awarded Great Places to Work and Built In’s Best Workplaces for multiple years running
We move fast, care hard, and fight for independent restaurant operators to do what they love, and love doing it. If you’re looking to make an impact with heart and hustle, SpotOn is the place for you.
As a Senior Data Engineer on our Data and Reporting team, you'll be responsible for designing, building, and maintaining high-performance, scalable data systems and data infrastructure. You will collaborate closely with cross-functional teams, including product management, engineering leadership, to enhance existing platforms and develop innovative solutions for complex data-driven applications.
On a daily basis you will:
Architect, develop, and maintain scalable software solutions for our reporting and analytics platforms.
Design and implement data pipelines, ETL processes, and integrations using ClickHouse, Streamkap, PostgreSQL, Snowflake, MongoDB, Kafka, and AWS.
Write and Optimize SQL queries that drive merchant reporting outcomes and improve database performance across large-scale, distributed systems.
Contribute to defining and refining system architectures, including cloud infrastructure and containerization strategies.
Implement robust data observability monitoring, logging, and alerting solutions using tools like Grafana, Metaplane, and OpenTelemetry.
Mentor junior and mid-level engineers, promoting technical excellence and best practices.
What skills are we looking for?
5+ years of professional software and data engineering experience.
Proficient in Python; experience with GO and TypeScript or JavaScript is highly beneficial.
Extensive experience with databases and data warehouses such as ClickHouse, PostgreSQL, and MongoDB.
Strong understanding of real-time data streaming and messaging systems, especially Kafka.
Experience designing and implementing robust ETL pipelines and handling large-scale data migrations.
Familiarity with cloud services, especially AWS, including IAM roles, S3, RDS, and MSK.
Proven ability in performance tuning and optimization for high-volume, low-latency data systems.
Experience applying core data observability principals to create a transparent and resilient data platform.
Comfortable with containerization technologies such as Docker and orchestration tools like Kubernetes.
Strong experience with infrastructure as code (IaC) tools and best practices.
Deep understanding of software development best practices, CI/CD pipelines, and DevOps methodologies.
An ideal candidate will also have:
Experience in building frontend components or familiarity with React and Next.js.
Knowledge of monitoring and observability tools, including Grafana and OpenTelemetry.
Background or interest in data analytics, machine learning applications, and causal analysis.
Experience in the restaurant or hospitality technology sector.
Compensation:
Our base pay range starts at $122,000 -$165,000 for this role
Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan
Offers will be reflective of the candidate’s location and experience.
The base salary range listed will vary depending on location and experience.
Base salary range
$122,000—$165,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.
SpotOn is an e-verify company."
2025-12-12T15:01:13.806,"Software Engineer III, Infrastructure, Audience Data Processing",Google,"MINIMUM QUALIFICATIONS:

 * Bachelor’s degree or equivalent practical experience.
   
 * 2 years of experience with software development in C++, SQL, Borg, Flume, or
   1 year of experience with an advanced degree.
 * 2 years of experience with developing large-scale infrastructure, distributed
   systems or networks, or experience with compute technologies, storage or
   hardware architecture.



PREFERRED QUALIFICATIONS:

 * Master's degree or PhD in Computer Science or related technical fields.
   
 * 2 years of experience with data structures and algorithms.
 * Experience with Flume and large scale data processing pipelines.
 * Experience developing accessible technologies.
   


ABOUT THE JOB:

Google's software engineers develop the next-generation technologies that change
how billions of users connect, explore, and interact with information and one
another. Our products need to handle information at massive scale, and extend
well beyond web search. We're looking for engineers who bring fresh ideas from
all areas, including information retrieval, distributed computing, large-scale
system design, networking and data storage, security, artificial intelligence,
natural language processing, UI design and mobile; the list goes on and is
growing every day. As a software engineer, you will work on a specific project
critical to Google’s needs with opportunities to switch teams and projects as
you and our fast-paced business grow and evolve. We need our engineers to be
versatile, display leadership qualities and be enthusiastic to take on new
problems across the full-stack as we continue to push technology forward.

As a Software Engineer on the Audience Data Processing Infrastructure team, you
will innovate and optimize planet-scale data processing flows to support Google
Ads.

While we're an infrastructure team, we operate in a fast-paced environment with
evolving requirements. Our focus is on supporting client data processing needs,
enhancing operational excellence and developer velocity, and significantly
improving resource efficiency.


Google Ads is helping power the open internet with the best technology that
connects and creates value for people, publishers, advertisers, and Google.
We’re made up of multiple teams, building Google’s Advertising products
including search, display, shopping, travel and video advertising, as well as
analytics. Our teams create trusted experiences between people and businesses
with useful ads. We help grow businesses of all sizes from small businesses, to
large brands, to YouTube creators, with effective advertiser tools that deliver
measurable results. We also enable Google to engage with customers at scale.

The US base salary range for this full-time position is $141,000-$202,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Write product or system development code in C++ for infrastructure
   responsible for managing and optimizing processing of planet-scale data
   processing.
 * Investigate data storage and processing use cases, techniques, and
   identifying opportunities for future innovation.
 * Review code developed by other developers and provide feedback to ensure best
   practices (e.g., style guidelines, checking code in, accuracy, testability,
   and efficiency).
 * Contribute to existing documentation or educational content and adapt content
   based on product/program updates and user feedback.
 * Triage product or system issues and debug/track/resolve by analyzing the
   sources of issues and the impact on hardware, network, or service operations
   and quality."
2025-12-12T13:26:27,Cleared On Site Data Engineer (4899),SMX,"SMX is seeking a Senior Data Architect to provide strategic and technical leadership for enterprise data architecture and analytics modernization efforts. This individual will design, optimize, and oversee data solutions that enable advanced analytics, business intelligence, and reporting capabilities across multiple secure environments. This role will focus on designing, developing, optimizing, and maintaining data pipelines and backend data engineering solutions that power critical analytical products used by senior FBI leadership. The ideal candidate brings deep technical expertise in ETL processes, SQL, Python, AWS data services, and enterprise-scale data warehousing, with strong familiarity in BI ecosystems such as MicroStrategy (Strategy), ThoughtSpot, and related tools used within the HR Reports program. The position requires close collaboration with government leads, senior data developers, BI engineers, and cross-functional analytics teams to ensure high reliability, performance, and security of data products supporting mission-critical operations. 
This is a full-time position requiring on-site work five days a week at a client’s office in Washington, D.C. An active Top Secret clearance is mandatory.
Essential Duties and Responsibilities: 
Design, build, and maintain scalable, secure ETL/ELT pipelines supporting HR Reports analytics and dashboard products.
Develop and optimize SQL-based transformations, stored procedures, and data models for high-volume enterprise datasets.
Implement data orchestration workflows using AWS services (e.g., Glue, Lambda, Step Functions, CloudWatch).
Ensure data quality, lineage, and integrity across multiple enterprise data sources.
Support and enhance cloud-based warehouse environments within AWS (e.g., Redshift, S3, IAM).
Collaborate with BI developers to ensure backend data structures meet MicroStrategy/Strategy and ThoughtSpot reporting needs.
Troubleshoot complex data pipeline or performance issues and implement long-term remediation solutions.
Translate government stakeholder requirements into technical specifications for new data sources and pipelines.
Partner with Data Analysts, Data Scientists, and BI Developers to support advanced analytics and ad-hoc data requests.
Apply data governance, security, and compliance best practices in alignment with FBI and SMX standards.
Recommend and implement improvements to automation, data architecture, pipeline reliability, and overall performance.
Maintain documentation for pipelines, logic, data flows, and system dependencies.
Stay current with modern data engineering practices and AWS service enhancements relevant to pipeline automation and warehousing.
Required Skills: 
10+ years of experience in data architecture, data warehousing, or enterprise analytics systems.
Expert-level proficiency in SQL and data modeling
Hands-on experience designing and implementing ETL/ELT frameworks (e.g., Apache Airflow, dbt, AWS Glue, Informatica).
Demonstrated success architecting and optimizing large-scale BI/reporting solutions (MicroStrategy, ThoughtSpot, Power BI, Tableau).
Strong knowledge of AWS data ecosystem (Redshift, Athena, S3, Glue, Lambda) or similar cloud environments.
Experience defining and enforcing data governance, quality, and security standards.
Ability to design and document end-to-end data flows and integrations between transactional and analytical systems.
Excellent communication, analytical, and problem-solving skills.
Desired Skills/Experience:
Bachelor’s or Master’s degree in Computer Science, Information Systems, Data Engineering, or related technical field.
10+ years of experience in data engineering, backend data development, or enterprise-scale ETL development.
Experience supporting federal government IT systems or analytics programs.
Familiarity with Agile methodologies and Jira-based workload management.
Experience supporting or modernizing enterprise BI ecosystems.
**This position requires five days a week on site at customer location in Washington DC.
Application deadline 1-16-2026
#LI-SA
#cjpost
The SMX salary determination process takes into account a number of factors, including but not limited to, geographic location, Federal Government contract labor categories, relevant prior work experience, specific skills, education and certifications. At SMX, one of our Core Values is to Invest in Our People so we offer a competitive mix of compensation, learning & development opportunities, and benefits. Some key components of our robust benefits include health insurance, paid leave, and retirement.
The proposed salary for this position is:
$114,600—$192,500 USD
At SMX®, we are a team of technical and domain experts dedicated to enabling your mission. From priority national security initiatives for the DoD to highly assured and compliant solutions for healthcare, we understand that digital transformation is key to your future success.
We share your vision for the future and strive to accelerate your impact on the world. We bring both cutting edge technology and an expansive view of what’s possible to every engagement. Our delivery model and unique approaches harness our deep technical and domain knowledge, providing forward-looking insights and practical solutions to power secure mission acceleration.
SMX is an Equal Opportunity employer including disabilities and veterans.
Selected applicant may be subject to a background investigation and/or education verification.
SMX does not sponsor a new applicant for employment authorization or immigration related support for this position (i.e. H1B, F-1 OPT, F-1 STEM OPT, F-1 CPT, J-1, TN, E-2, E-3, L-1 and O-1, or any EADs or other forms of work authorization that require immigration support from an employer)."
2025-12-12T12:29:19.508,"Data Center Plant Engineer, Mechanical, Electrical",Google,"MINIMUM QUALIFICATIONS:

 * Associate's degree, trade school certification, or other certified training
   in a related technical field, or equivalent practical experience.
 * 7 years of experience in electrical, mechanical/HVAC, or controls/automation
   experience in an industrial or commercial environment.



PREFERRED QUALIFICATIONS:

 * Experience working in data centers, hospitals, or power plants.
 * Knowledge of electrical and mechanical systems used in a data center
   environment (e.g., Feeders, Transformers, Generators, Switchgear, UPS
   systems, ATS/STS units, PDU/PMM units, Chillers, Air handling units, and CRAC
   units).
   
 * Knowledge of meters, devices, sensors, and troubleshooting utilizing standard
   hand tools, digital metering, or calibration/diagnostic equipment.
   
 * Ability to communicate with contractors who perform maintenance or upgrade
   work on the data center systems.
   


ABOUT THE JOB:

The Data Center team designs and operates some of the most sophisticated
electrical engineering, mechanical engineering and HVAC systems in the world.
Facilities Technicians at Google data centers operate, monitor and support
physical facilities conditions. Some of these duties will include heating and
cooling of air and water, power supply, generators, UPS systems, electrical
distribution and control and monitoring systems. You regularly help inspect,
maintain and repair various data center systems such as piping and non-critical
electrical or mechanical system components). You provide daily assistance to
senior technicians as you read blueprints/schematics, conduct tours of systems
and assess their working order.

As a master of exceptional practices, you develop creative approaches to
reducing operational costs while improving overall data center efficiency. You
ensure that environmental and safety standards are consistently met, identifying
problems and making repairs quickly In emergency situations or abnormal
conditions, you manage data center performance issues and outages to minimize
the recovery time from failures.The AI and Infrastructure team is redefining
what’s possible. We empower Google customers with breakthrough capabilities and
insights by delivering AI and Infrastructure at unparalleled scale, efficiency,
reliability and velocity. Our customers include Googlers, Google Cloud
customers, and billions of Google users worldwide.

We're the driving force behind Google's groundbreaking innovations, empowering
the development of our cutting-edge AI models, delivering unparalleled computing
power to global services, and providing the essential platforms that enable
developers to build the future. From software to hardware our teams are shaping
the future of world-leading hyperscale computing, with key teams working on the
development of our TPUs, Vertex AI for Google Cloud, Google Global Networking,
Data Center operations, systems research, and much more.

The US base salary range for this full-time position is $105,000-$151,000 +
bonus + equity + benefits. Our salary ranges are determined by role, level, and
location. Within the range, individual pay is determined by work location and
additional factors, including job-related skills, experience, and relevant
education or training. Your recruiter can share more about the specific salary
range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the
base salary only, and do not include bonus, equity, or benefits. Learn more
about benefits at Google [https://careers.google.com/benefits/].


RESPONSIBILITIES:

 * Inspect, maintain, and repair various data center systems such as piping and
   non-critical electrical or mechanical system components.
   
 * Provide daily assistance to technicians as you read blueprints/schematics,
   conduct tours of systems, and assess their working order.
   
 * Manage the uptime and maintenance of water pumps and treatment systems, HVAC,
   UPS, generators, electrical distribution, and control and monitoring systems.
   
 * Operate, monitor, maintain, and respond to abnormal conditions in the data
   center facilities systems and equipment.
   
 * Support startup, commissioning, and integration of new equipment and systems
   into facilities infrastructure.
   "
2025-12-12T09:01:55.769,Data Engineer II,Microsoft,"Overview
With continued growth in digital data and the desire to leverage data to measure in-production quality and address problems that touch all aspects of our lives, Microsoft’s Windows Servicing & Delivery Org is looking for an equally data- and quality-minded engineer to meet these challenges! Join the Update Platform team for the chance to have an impact on billions of customers every day. The Update Platform Team is responsible for ensuring the seamless delivery and integration of software updates and keeping our customers up-to-date and secure at all times.
As a Data Engineer II member of the Update Platform Insights team, you will be at the forefront of leveraging data to assess the quality of the product, detect issues before they reach broad customer application to assure top product quality for partners and customers alike while keeping billions of devices secure and up-2-date.

In this exciting role, you'll work with a diverse group of talented professionals, innovate for greater platform efficiency as well as leveraging the latest technologies and best practices to streamline our update processes with timely in-depth insights and intelligent features.

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.


Responsibilities
Data Management and Transformation: With guidance, you will apply modification techniques to transform raw data into compatible formats for downstream systems. Utilize software and computing tools to ensure data quality and completeness. Implement code to extract and validate raw data from upstream sources, ensuring accuracy and reliability.
Drive Customer Success: Through Data and Business Insight: You will play a pivotal role in building a metrics-driven culture that directly impacts product quality and customer outcomes. This role goes beyond technical execution—you will design and implement measurement frameworks from the ground up while applying a strategic, top-down perspective to ensure the right metrics are in place. Your ability to translate data into actionable insights, aligned with business priorities and rhythm of business, will enable informed decisions that drive high-quality product outcomes and measurable customer success.

Data Requirements and Modeling: Collaborate with stakeholders to document and understand data requirements. Evaluate project plans to assess data costs, access, and availability. Draft design specifications to model data flow and storage, ensuring data is easy to connect and manage.
Compliance: You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams. You’ll also learn about permissions and approvals for data access within a data pipeline.

Validation and Quality Mindset: Apply and use operational fundamentals to validate and ensure quality of the product as well as the underlying data pipeline and assets to secure trustworthiness in your data daily.

Customer Focus: Be driven by a focus on customer happiness and success. We as a team only succeed if our customers are secure and protected via the updates we deliver.


Qualifications
Required Qualifications:
Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 1+ year(s) experience in business analytics, data science, software development, data modeling, or data engineering
OR Bachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 2+ years experience in business analytics, data science, software development, data modeling, or data engineering
OR equivalent experience.
Other Requirements:
Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include but are not limited to the following specialized security screenings:
Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.
Preferred Qualifications:
3+ years with scripting and coding languages with a focus on data engineering, like SQL, KQL, python, Scope, C# (or similar object-oriented languages) and others.
1+ years of experience with building large data processing frameworks using technologies like Azure Data Factory, Azure Data Explorer, PowerBI and/or other public and Microsoft internal tools.
1+ years of experience in analytics to define, monitor, and optimize key performance indicators (KPIs) and connected business metrics that ensure measurable customer success.
1+ years of proven ability to orchestrate and sustain a data-driven rhythm of business, transforming insights into actionable strategies that align with organizational priorities and deliver impactful outcomes.
A solid quality mindset with the ability to deliver end-to-end data solutions that build partner and customer confidence, ensuring alignment with business objectives and measurable outcomes.
Experience with Git, ADO or equivalent Source Control Systems.
Experience with data visualization tools and how to effectively communicate Insights to consumers of varying types of audiences.
Experience leveraging AI to define and evaluate quality standards


Data Engineering IC3 - The typical base pay range for this role across the U.S. is USD $100,600 - $199,000 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $131,400 - $215,400 per year. 
Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:
https://careers.microsoft.com/us/en/us-corporate-pay

This position will be open for a minimum of 5 days, with applications accepted on an ongoing basis until the position is filled.


Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance with religious accommodations and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations."
2025-12-12T01:54:02.588,"Data Science Engineer, New College Grad- Master's/PhD (Santa Clara, CA)",Applied Materials,"Assist in developing data science software prototypes and interfaces for monitoring semiconductor process tools Develop Python scripts to implement key concepts Collaborate closely with algorithm developers to characterize the algorithms and benchmark their performance, collecting quantitative data assessing effectiveness Evaluate the effectiveness and accuracy of the algorithms by working closely with process and equipment experts, providing feedback to algorithm developers Provide solutions which can be implemented by engineers without a deep statistical or mathematical background Deploy and maintain solutions at service sites Troubleshoot solutions, provide workarounds, and assist users in using solutions Assess effectiveness of solutions and provide data science insight Communicate well with algorithm developers and process experts Train field engineers to use solutions Present work and conclusions clearly and succinctly to peers Work well in team, providing and receiving constructive input with team members Monitor and quantify the results of complex algorithms in a production environment. Train a variety of individuals on the operation of these algorithms. Experience with various Artificial Intelligence Solutions, including Large Language Models, Computer Vision and Generative AI applications. Python, MATLAB Familiarity with common data science techniques, including regression, decision trees, Principle components, PLS, various Neural networks, time-series techniques, Bayesian techniques, etc. Ability to troubleshoot software applications and perform basic DevOps for deployment Ability to interact with Process and Customer Engineers Semiconductor process or equipment experience preferred. Demonstrates depth and/or breadth of expertise in own specialized discipline or field May lead small functional teams or projects with moderate resource requirements, risk, and/or complexity Communicates difficult concepts and negotiates with others to adopt a different point of view Master's or PhD in Computer Science, Data Science, Software Engineering, Mechanical Engineering, or related field. Preferred GPA of 3.0 or above"
2025-12-12T01:52:09.253,"Vice President, Data Engineer",BNY,"Bachelor's or master's degree in computer science or a related discipline, or equivalent work experience is required. 10+ years of data modeling, database design and development or related experience is required. Prior experience in managing DB development team Experience modeling Financial data Prior experience modeling Client and Entitlement Data Good knowledge of Financial Accounts, Transactions and Positions data Hands-on experience with any RDBMS, preferably MS SQL Server or Oracle Good SQL knowledge Excellent communication skills Good Problem Solving & Analytical Skills Work experience in Financial Services Work experience on any data modeling tool, viz. Erwin, DBArtisan etc. Experience with writing ANSI SQL code Prior Experience with a scripting language, preferably Python Experience working with Cloud native databases Bachelor's or Master's degree in Computer Science or a related discipline, or equivalent work experience is required. Advanced degree is preferred. Experience in the Securities or Financial Services industry."
2025-12-12T01:08:33,Data Analytics Engineer,Masimo,"The Data Analytics Engineer will support Masimo’s Quality organization by developing dashboards, performing data analysis, and transforming large datasets into meaningful insights. This role partners closely with Quality Compliance, Product Assurance, Engineering, Operations and cross-functional stakeholders to enhance data visibility, drive data-informed decisions, and support continuous improvement across the organization. The ideal candidate is technically strong in analytics tools, comfortable working with structured and unstructured data, and eager to grow in a fast-paced and evolving environment.
Duties & Responsibilities
Develop and maintain Power BI dashboards and reports that translate complex data sets into clear, actionable information.
Perform data transformation and modeling using SQL, Power Query (M), and DAX to support quality metrics, KPIs, and trend analysis.
Support routine and ad-hoc data analytics requests related to customer feedback, failure analysis, operations, and compliance activities.
Analyze large datasets to identify trends and process improvement opportunities.
Collaborate with Quality Compliance, Product Assurance, and cross-functional engineering teams to ensure data accuracy, consistency, and alignment with business needs.
Communicate findings through effective data storytelling, written summaries, and monthly presentations to cross functional leaders across the organization.
Contribute to continuous improvement efforts in reporting automation, dashboard optimization, and analytics best practices.
Minimum & Preferred Qualifications and Experience
Experience
0–2+ years of experience in data analytics, business intelligence, or engineering analytics; internship or project experience considered.
Hands-on experience with SQL and Power BI (including Power Query/M and DAX).
Experience using Python or R for data manipulation, modeling, or visualization preferred.
Familiarity with data visualization tools (Power BI highly preferred; Tableau or Looker a plus).
Understanding of statistics, data modeling, or quantitative analysis techniques.
Skills & Competencies
Strong analytical and problem-solving skills with high attention to detail.
Ability to translate data into clear insights for technical and non-technical partners.
Strong verbal, written, and visual communication skills, with the ability to present confidently and engage diverse audiences.
Ability to work independently and in a team environment.
Curiosity and willingness to learn new tools, systems, and techniques.
Education
Bachelor’s degree in Data Analytics, Data Science, Business Intelligence, Computer Science, Engineering, or a related field required.
Master’s degree in a relevant field is a plus but not required.
Compensation:
The anticipated salary range for this position is $90,000 - $110,000 plus benefits. Actual placement within the range is dependent on multiple factors, including but not limited to skills, education, and experience. 
This position also qualifies for up to 10% annual bonus based on Company, department, and individual performance. 
Masimo offers benefits such as Medical, Dental, Vision, Life/AD&D, Disability Insurance, 401(k), Vacation, Sick, Holiday, Paid Maternity Leave, Flexible Spending Accounts, Voluntary Accident, Critical Illness, Hospital, Long-Term Care, Employee Assistance Program, Pet Insurance, On-site wellness clinic, fitness center, and cafe. All benefits are subject to eligibility requirements."
2025-12-12T00:39:10,Data Engineer,HealthPartners/GHI,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:39:10,Data Engineer,HealthPartners,"HealthPartners is currently hiring a Data Engineer. Our mission is to make healthcare simple and affordable. At HealthPartners, teams use data to enhance patient and member experiences, improve health outcomes, and reduce the per capita cost of care. Data engineers are essential to this mission. They design, build, and optimize data pipelines that ensure reliable and efficient data movement. Their work supports high data quality and integrity, enabling better decision-making across the organization. They collaborate in scrum teams with developers, analysts, and data scientists, often sharing responsibilities to meet sprint goals. They follow industry best practices and develop scalable processes for storing, managing, and delivering data. In their role, data engineers focus on reducing manual data tasks and increasing productivity. They explore and test innovative tools, techniques, and architectures to identify patterns and automate repetitive data preparation and integration tasks.
Required Qualifications:
Bachelor’s degree in computer science, data or social science, operations research, statistics, applied mathematics, econometrics, or a related quantitative field. Alternate experience and education in equivalent areas such as economics, engineering or physics is acceptable.
Two (2) years' experience in a hands-on data engineering role (a master’s degree is acceptable in lieu of experience)
Two (2) years’ experience with Python and/or R data science programming languages
Two (2) years’ experience with SQL (e.g., PL/SQL or PySpark SQL) relational database programming language(s).
Experience with CI/CD and version control tools (Git preferred).
Demonstrate understanding of data modeling techniques such as Star-/Snowflake-Schema, denormalized data modeling, 3NF etc.
Demonstrate understanding working with data formats such as Parquet, Avro, Delta, CSV, JSON, etc.
Demonstrate understanding about data processing techniques like full-batch processing, time-based partitioning, distributed- and real-time processing etc.
Demonstrate strong data profiling and analytic skills; ability to discover and highlight unique patterns/trends within data to identify and solve complex problems.
Must be motivated, self-driven, curious, and creative.
Must be a skilled communicator and demonstrate an ability to work with end users and partners.
Demonstrate the ability to support and complement the work of a diverse development and/or operations team.
Preferred Qualifications:
Knowledge of health care operations
Knowledge/experience of basic accounting principles
Exposure to Agile/Scrum
Experience with a hybrid cloud environment consisting of an on-premises and public cloud infrastructure. An ideal candidate will have experience with one or more of the following skill sets.
Experience with Relational databases like Oracle, SQL Server
Experience Optimizing and tuning SQL/Oracle queries, stored procedures, and triggers.
Experience with Python (numpy, pandas, matplotlib etc.) and Jupyter notebooks for exploratory data analysis, machine learning, and process automation
Experience in areas of CI/CD, continuous testing, and site reliability engineering.
Familiarity in Microsoft Azure applications such as Azure Data Factory, Synapse, Purview, Databricks /Spark, Power BI, PowerApps.
Familiarity working with Document or NoSQL datastores, particularly MongoDB.
Familiarity in Power BI data models using advanced Power Query and DAX
Interest and desire to contribute to emerging practices around DataOps (CI/CD, IaC, configuration management, etc.)
Hours/Location:
M-F; core business hours
May work in a remote capacity but will prefer local/regional candidates for occasional onsite needs.
Responsibilities:
All team members must champion and model our values of partnership, curiosity, compassion, integrity, and excellence, and must contribute to a culture of continuous learning.
Collaborate with stakeholders, data scientists and analysts to frame problems, clean and integrate data, and determine the best way to provision that data on demand.
Collaborate with other developers to design technology solutions that achieve measurable results at scale.
Help design and develop scalable, efficient data pipeline processes to manage data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets for analysts and data scientists.
Utilize development best practices including technical design reviews, implementing test plans, monitoring/alerting, peer code reviews, and documentation.
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products.
Incorporate core data management competencies including data governance, data security and data quality.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Assist Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Perform other duties as required, to meet team sprint goals."
2025-12-12T00:14:05.56,Sr. Data Engineer,Apple,"As a Data Engineer on the Capacity Engineering team, you will help design,
build, and operate the data foundation that drives capacity, cost, and
power-related decisions across Apple’s infrastructure footprint. In this role,
you will: Architect, implement, and maintain large-scale batch and streaming
pipelines that ingest, process, and model infrastructure telemetry, cost,
metering, utilization, forecasting, and power metrics from multiple clouds and
bare metal environments. Design and evolve robust data models (with a strong
focus on dimensional modeling) and storage patterns that support analytics,
internal billing, and efficiency use-cases. Treat data as a product: define
quality checks, SLAs, and observability to ensure data is accurate, timely, and
trusted by stakeholders across Apple. Integrate and enrich raw signals with
metadata and attribution to power use cases such as internal billing/showback,
usage understanding, efficiency and optimization, clawbacks, planning, and
procurement. Collaborate closely with data scientists, software engineers,
platform teams, finance partners, program managers, and leadership to translate
requirements into scalable, reliable data solutions and services. Implement
standard methodologies for data governance, lineage, metadata management, and
security, in alignment with Apple’s standards for data protection and privacy.
Build end-to-end data solutions that include logging, anomaly detection, data
validation, cleaning, and transformation, with strong emphasis on monitoring,
debuggability, and continuous improvement. Contribute to the evolution of our
data and platform stack, including tooling, frameworks, and standards for
development, testing, deployment, and operations (CI/CD, infrastructure as code,
etc.).


DESCRIPTION


Apple’s Capacity data engineering team, within the Apple Services Engineering
organization, is building the centralized data backbone that powers how Apple
understands, plans, and optimizes its cloud and data center infrastructure. We
engineer a unified, trusted data lake that consolidates cost, metering,
utilization, forecasting, and power metrics produced by Apple platforms and
systems (including bare metal) across both third-party and Apple internal
clouds. Enriched with metadata and attribution, this becomes the single source
of truth for internal billing, understanding usage and utilization, clawbacks,
planning, procurement, and efficiency initiatives. We collaborate with platform
engineering, finance, capacity engineering, and leadership teams to build
large-scale data pipelines, enable descriptive and predictive analytics, and
power dashboards and products that support critical business decisions. This is
your opportunity to help design and operate highly visible, global-scale systems
processing petabytes of data and supporting hundreds of users across Apple. Come
join us to help deliver the next generation of infrastructure insights at Apple.


MINIMUM QUALIFICATIONS


Bachelors degree or equivalent experience in Computer Science, Information
systems, Software Engineering, Data Science or related field. Advanced degree in
a related field a plus. 5+ years of experience in data engineering (or
equivalent practical experience), including: Building and maintaining
large-scale ETL/ELT data pipelines Distributed computing (e.g., Spark / PySpark)
for data processing and automation Query performance optimization and tuning at
scale Hands-on experience with: Apache Spark and Airflow (or similar
workflow/orchestration tools) for efficient large-scale data pipelines Data
modeling, especially dimensional modeling, and designing schemas optimized for
analytics and reporting Big data platforms and/or data lake architectures


PREFERRED QUALIFICATIONS


Experience with cloud technologies, specifically AWS (e.g., S3, EMR, Lambda,
Glue, RDS/Redshift, or similar services) Tooling & ecosystem: Experience with
CI/CD tooling such as Jenkins (or similar tools) Experience with data
visualization / BI tools, such as Superset or Tableau (other tools like
QuickSight, QlikView, Cognos, or Business Objects are a plus) Experience with
containerization and orchestration, such as Docker and Kubernetes/EKS is a plus
Understanding of authentication and authorization (AuthN/AuthZ) patterns
Knowledge of data governance principles, data security best practices, and data
privacy regulations"
2025-12-12T00:00:00,Lead Data Engineer,Nuna,"At Nuna, our mission is to make high-quality healthcare affordable for everyone. We are dedicated to tackling one of our nation’s biggest problems with ingenuity, creativity, and a keen moral compass.
Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why.
Nuna has established its brand in the B2B space over the last decade by shifting the US healthcare system towards an incentive model that rewards healthcare providers for positive outcomes. Marshalling our collective backgrounds and insights, we are now crafting an innovative, consumer app - a clinically driven healthcare companion experience that leverages AI, gamification and social support techniques to improve outcomes for people with chronic conditions.
As a sign of the impact Nuna has already made in this space, Nuna was recently selected to join the Centers for Medicare & Medicaid Services (CMS) Health Tech Ecosystem, a landmark public-private initiative designed to transform healthcare for Americans.
YOUR TEAM
The Data org at Nuna is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research.
The Data Engineer team is a core part of the broader Data organization, which is an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and research. The Data Engineer team acts as the technical backbone for data architecture, platform development, and data operations, empowering the organization to deliver impactful data-driven solutions in healthcare.
YOUR OPPORTUNITIES
We are looking for someone who is excited to use their creativity and engineering skills to make a difference in healthcare. You will have a foundational role on a team building a consumer product that incentivizes healthy behavior. You will be responsible for the data architecture and direction of the data platform that powers our data operations and data science initiatives.
Own the architecture and evolution of the data platform, based on business needs and considering trade-offs in timelines, cost, and resources
Define and enforce standards for code development, contribution, and deployment for data engineering workflows.
Oversee integrations with external services, including data ingestion, distribution, and service-to-service data flows.
Contribute hands-on to data transformations and optimizations
Establish security, governance, and operational best practices for the data platform in collaboration with security and enterprise data engineering teams.
Curate and develop datasets needed to support Data org project deliverables
Collaborate with cross-functional partners in engineering, design, and product to develop solutions
Generate and prioritize new opportunities for improvements
Provide build vs buy assessments and recommendations as the platform expands
QUALIFICATIONS
Required Qualifications
Deep hands-on expertise in designing, coding, developing, and maintaining data platforms that support data analytics and data science use cases
Proven ability to design, develop and implement robust data ingestion pipelines (ETL) from external sources into a data platform.
Experience establishing standards for code development, deployment, and contributions in a data engineering environment.
Ability to solicit and translate customer and business needs into requirements and an evaluation framework
Interest in improving healthcare and working with interdisciplinary project teams
Clear communication and presentation skills
Experience with Databricks
Expertise in data platform languages such as python, pyspark and SQL
+ 5-10 years of industry experience with technical lead experience of running a data platform for business operations
Preferred Qualifications
MS in quantitative field (e.g. Data Science, Economics, Statistics, Engineering)
Experience building a data platform from zero to one
Experience working with healthcare data
Experience with SDLC and management of machine learning models (MLOps)
Bonus points if experience with MLOps on LLM/GenAi features (evals, context building, …)
We take into account an individual’s qualifications, skillset, and experience in determining final salary. This role is eligible for health insurance, life insurance, retirement benefits, participation in the company’s equity program, paid time off, including vacation and sick leave. The expected salary range for this position is $208,000 - $260,000. The actual offer will be at the company’s sole discretion and determined by relevant business considerations, including the final candidate’s qualifications, years of experience, and skillset.
Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status.
#LI-FK1"
2025-12-12T00:00:00,Development Project Engineer (Data Center Construction),QTS Data Centers,"Who we are: It's pretty exciting to find yourself standing in a pivotal moment in time. It’s even more exciting to be out front leading it. At QTS, our world-class data centers are supporting our customers’ most strategic growth initiatives, positioning us at the forefront of today’s dynamic digital transformation. As AI and cloud drive the demand for increased speed, capacity and capability, QTS has emerged as the global digital infrastructure leader, committed to connecting the world for good. Driven by purpose and fueled by a spirit of innovation, QTS designs, builds and operates some of the world’s most advanced, forward-thinking data centers. QTS is a portfolio company of Blackstone. QTS is Powered by People. People who play a vital role in our company’s culture, innovation and growth. People who are committed to contributing to the communities where we operate and work. People who are knowledgeable, resourceful and mission driven. Together, we do great things. Who You Are: The Development Project Engineer (Data Center Construction) is primarily responsible for assisting with the design, preconstruction and construction activities on a given project(s). The Development Project Engineer will interact on a daily basis with Facilities, Contractors, Designers, Engineers, Commissioning Agents, Vendors, and Data Center Operations & Corporate real estate staff and should have both written and oral communication skills commensurate with this level of regular communication. What You Will Do: Assist Development leadership and Project Manager with day to day activities and responsibilities Assist with multiple projects on a campus(es) and maintain updated budgets, schedules, and status reports for each Assist with updates on development program & project status on a monthly basis suitable for executive level reviews. Work with QTS stakeholders, design, and construction teams to help with master development program for site(s), including a complete campus design solution and capital budget. Assist with entitlement and permitting needs for each assigned site project(s) Assist with scopes of work for design, construction, commissioning services & participate in procurement and project cost estimates Evaluate and level pricing proposals for design, construction, and commissioning services Work closely with strategic procurement team on equipment procurement and delivery process Ensure appropriate submittals are coordinated with site stakeholders Assist with monitoring project budget / cost-to-date against overall project budget. Review project schedules and manage teams to on-time completion Review change order requests from contractors and negotiate pricing Assist with establishing site construction security procedures in conjunction with site security team Establish and maintain relationships serving as liaison with key QTS stakeholders Represent QTS Interests in OAC meetings Create & build relationships that enhance QTS’s ability to be a leader in creating the World’s Most Valuable Data Center Real Estate Aid in due diligence efforts on an as-needed basis by participating with real estate efforts on potential or new land banks and properties, including: Evaluate opportunities to design & build new data centers by working with key stakeholders: Corporate Real Estate, Connectivity, Power & Construction teams. Assist with establishing and monitoring entitlement and permit processes for individual projects as needed Work with the internal development team to enhance project management processes and protocols What You Will Need to be Successful (basic qualifications): Bachelor’s degree in Engineering or Construction Management field or equivalent professional experience Experience with Microsoft Office suite, specifically PowerPoint for use in communicating program updates to executive level, and Excel to create and maintain site program & individual project budgets Excellent interpersonal skills with the ability to interface with all levels of the organization Must be a capable, proven team player that both fosters and operates well within internal and external team environments. Able to solve problems at a tactical and functional level Strong Verbal and Written Communication Skills Ability to manage multiple projects simultaneously Other Key Skills: One or more years of professional experience in commercial construction practices and procedures, including management of Lump Sum, Construction Management @ Risk, and Design Build project delivery methods from conceptual development through procurement to close out Documented experience using AutoCAD, BlueBeam, P6, and CxAlloy Experience or exposure in mission critical data center facilities Experience with management of MEP trades Experience managing document control for active data center build sites The Perks (and these are just a few!): Q-Rest Sabbatical Employee Stock Purchase Plan QTS scholarship for dependents Eagle Club Award Trip Eligibility Paid Volunteer and Floating days Tuition Assistance, Parental Leave and Military Leave Assistance We conform to all the laws, statutes, and regulations concerning equal employment opportunities and affirmative action. We strongly encourage women, minorities, individuals with disabilities and veterans to apply to all of our job openings. We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, gender identity, or national origin, age, disability status, Genetic Information & Testing, Family & Medical Leave, protected veteran status, or any other characteristic protected by law. We prohibit retaliation against individuals who bring forth any complaint, orally or in writing, to the employer or the government, or against any individuals who assist or participate in the investigation of any complaint or discrimination claim. The ""Know Your Rights"" Poster is included here: Know Your Rights (English) Know Your Rights (Spanish) The pay transparency policy is available here: Pay Transparency Nondiscrimination Poster-Formatted QTS is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please send an e-mail to talentacquisition@qtsdatacenters.com and let us know the nature of your request and your contact information. It’s exhilarating to find yourself at a pivotal moment in history— and even more so to be leading the way. At QTS Data Centers, we are proud to stand at the forefront of today’s dynamic digital transformation. Our world-class data centers empower our customers’ most strategic growth initiatives, positioning us as a global leader in digital infrastructure. As AI and cloud technologies fuel the demand for increased speed, capacity, and innovation, QTS has emerged as the global digital infrastructure leader. We are committed to connecting the globe for good. Driven by purpose and a spirit of innovation, we design, build, and operate some of the most advanced data centers worldwide. In addition to our cutting-edge technology, we are dedicated to sustainability, incorporating renewable energy solutions to minimize our environmental footprint and drive meaningful impact. As a proud portfolio company of Blackstone, QTS is uniquely positioned to achieve ambitious growth and innovation goals. At QTS, we are Powered by People. Our team members are the cornerstone of our culture, innovation, and growth. They are mission-driven, resourceful, and committed to making a positive impact in the communities where we live and work. Together, we’re achieving remarkable things and shaping the future of digital infrastructure. And we’d like to invite you to join us. In addition to a variety of benefit packages, QTS goes above and beyond for our employees: Roth and Traditional 401(k) matching contributions with immediate vesting Every employee is bonus or commission eligible Generous PTO, Paid Volunteer Days Plus Floating Holidays Stock Purchase Plan (SPP) 11 paid Holidays Annually/Holiday compensation when worked Pet and Legal Insurance Q-Rest Sabbatical Program Q-Anniversary Service Award Program Parental Leave for primary and secondary caregivers Military Benefits Package QTS Charitable Matching Gift Program QTS Scholarship for Employee Dependents QTS Crisis Fund Wellness Program Tuition Reimbursement Program"
2025-12-12T00:00:00,"Data Engineer I, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $109,300.00 - $180,200.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data across the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape by designing, building, and deploying data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning, and business intelligence initiatives. You will work closely with Data Science and Decision Science teams to build, test, and maintain data pipelines and model workflows that support both analytical research and production use cases in our Databricks/AWS/Snowflake environment. In addition to your strong analytical mind, you will bring an inquisitive attitude and the ability to translate the stories found in data into actionable insights while contributing to technical discussions and process improvements. Applicants must be authorized to work for ANY employer in the U.S. The company does not sponsor/support H-1B petitions, TN, or Forms I-983/STEM OPT, for this role. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions. Design data solutions. Analyze sources to determine value and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Collaborate within and across teams to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate. Test data movement, transformation code, and data components. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent. Six years of related experience. Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions. Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on. Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems. Strong verbal and written communication skills with the ability to interact with team members and business partners. Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Four years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,"Senior Data Engineer, Personal Insurance",Travelers,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 170 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $139,400.00 - $230,000.00 Target Openings 1 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions. Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies. Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment. Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate. Collaborate across team to support delivery and educate end users on complex data products/analytic environment. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent Ten years of related experience Primary Job Requirements: Architect and design scalable, secure data solutions using AWS, Databricks, and Ab Initio. Lead technical direction for data engineering initiatives across cloud and on-premises infrastructure. Hands-on development: build ETL pipelines, optimize Spark jobs, and create Ab Initio graphs. Troubleshoot production issues and provide technical guidance to junior engineers. Conduct mentoring sessions and offer technical guidance to the 20-person admin team. Collaborate with DBA teams, business analysts, and QA teams to ensure data governance and quality. Manage infrastructure deployment and optimize cloud resources. Lead technical design reviews and architecture discussions. Implement data integration solutions and ensure compliance with data protection regulations. Establish and enforce coding standards, best practices, and data governance policies. Technical Skills: AbInitio: Expert proficiency with GDE, Co>Operating System, EME, BRE, Express>It, metaprogramming (PDL) Programming: Python, PySpark, SQL Cloud: AWS architecture and services Databricks: Workspace management, cluster configuration, Delta Lake, Unity Catalog Data Warehousing: Strong understanding of data modeling, dimensional modeling (star/snowflake schemas) ETL/ELT: End-to-end ETL development lifecycle Version Control: Git, CI/CD pipelines Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices. Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems. Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers. Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize. Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas. Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Five years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 30,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here."
2025-12-12T00:00:00,Data Flow Engineer,Scientific Research Corporation,"Description
The Data Flow Engineer will be a member of a Cryptologic Carry-On Program (CCOP) and Ship’s Signals Exploitation Equipment (SSEE) Systems Engineering team primarily responsible for ensuring the processing and distribution of data to and from intelligence community networks. The ideal candidate will have a history of direct involvement with successful NiFi data flow engineering and resolving Navy hardware and software functionality problems by providing a high degree of timely customer service and technical expertise in support of the US Navy information warfare community.
Installing, configuring, integrating, and maintaining NiFi servers and processors into new or existing system architectures
Verifying and maintaining all NiFi processors and flows to and from deployed (and test) systems, from the field system through customer back-end repositories
Assisting end users with the operational readiness and configuration of deployed systems for optimal data flow to satisfy customer requirements
Designing and developing NiFi processors and flows for deployed systems, containing multiple subsystems and requiring integration with external networks
Implementing expression language in NiFi processors in response to emerging customer requirements
Exhibiting developed verbal and written communication skills and the ability to express concepts and ideas in a clear and concise manner; employing technical writing techniques
Performing as a team player, dedicated to the endeavors of the mission, the customer, and the team itself
Being a self-starter who is accountable and requires minimal direction and supervision; capable of multitasking and working several complex and diverse tasks with simultaneous or near simultaneous deadlines
#LI-LL1
Requirements
Must possess an active TS/SCI clearance and be able to obtain a CI Polygraph
Requires a bachelor’s degree in related technical field or equivalent work experience
Intermediate Linux Command Line Interface (CLI) experience
1-3 years of Apache Niagara Files (NiFi) experience (negotiable with other qualifications)
Strong background in using and troubleshooting Software Defined Radio (SDR) systems
Fundamental knowledge of wireless protocols in common use
Experience providing technical support to customers over Internet Relay Chat (IRC) or similar applications
Familiarity with back-end databases and repositories
Must be willing to travel up to 10% of the year
Must currently be DoD 8570-compliant with the equivalent of an IAT II certification or have the ability to do so within 6 months of employment
Desired Skills
Current Linux+/LPIC 1 and/or Network+ certification
Familiarity with Regular Expression (REGEX), Cisco Networking, and Amazon Web Services (AWS)
Expert-level SDR knowledge and experience
Experience with strategic-level intelligence processes
Basic computer programing experience (i.e. Python, JavaScript, bash)
Prior Navy CTR/CTM/CTN with shipborne, expeditionary, or other comparable experience 
Clearance Information
SRC IS A CONTRACTOR FOR THE U.S. GOVERNMENT. THIS POSITION WILL REQUIRE U.S. CITIZENSHIP AS WELL AS A U.S. GOVERNMENT SECURITY CLEARANCE AT THE TOP SECRET / SCI LEVEL with CI POLY ELIGIBILITY
Travel Requirements
up to 10% travel may be required
About Us
Scientific Research Corporation is an advanced information technology and engineering company that provides innovative products and services to government and private industry, as well as independent institutions. At the core of our capabilities is a seasoned team of highly skilled engineers and scientists with multidisciplinary backgrounds. This team is challenged daily to provide cutting edge technology solutions to our clients.
SRC offers a generous benefit package, including medical, dental, and vision plans, 401(k) with a company match, life insurance, vacation and sick paid time off accruals starting at 10 days of vacation and 5 days of sick leave annually, 11 paid holidays, tuition reimbursement, and a work environment that encourages excellence and more. For positions requiring a security clearance, selected applicants will be subject to a government security investigation and must meet eligibility requirements for access to classified information.
EEO
Scientific Research Corporation is an equal opportunity employer that does not discriminate in employment.
All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other protected characteristic under federal, state or local law.
Scientific Research Corporation endeavors to make www.scires.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact jobs@scires.com for assistance. This contact information is for accommodation requests only and cannot be used to inquire about the status of applications."
2025-12-12T00:00:00,"Research Data Engineer II, CHeT Analytics",University of Rochester,"As a community, the University of Rochester is defined by a deep commitment to Meliora - Ever Better. Embedded in that ideal are the values we share: equity, leadership, integrity, openness, respect, and accountability. Together, we will set the highest standards for how we treat each other to ensure our community is welcoming to all and is a place where all can thrive. Job Location (Full Address): 265 Crittenden Blvd, Rochester, New York, United States of America, 14642 Opening: Worker Subtype: Regular Time Type: Full time Scheduled Weekly Hours: 40 Department: 400980 Neuro-Ctr Health & Tech/Admin Work Shift: UR - Day (United States of America) Range: UR URG 113 Compensation Range: $77,216.00 - $115,824.00 The referenced pay range represents the minimum and maximum compensation for this job. Individual annual salaries/hourly rates will be set within the job's compensation range, and will be determined by considering factors including, but not limited to, market data, education, experience, qualifications, expertise of the individual, and internal equity considerations. Responsibilities: GENERAL PURPOSE Participates in the design, implementation and maintenance of analytical and data science-based software and data pipelines to support scientific workflows. Focuses on developing and supporting data collection frameworks that integrate structured and unstructured data from multiple sources and systems to support specific research study teams. Supports the development and maintenance of infrastructure systems (e.g., data warehouses, data lakes), including data access Application Programming Interface(s) (APIs). Works in partnership with team members to provide robust, scalable software solutions to the research enterprise. ESSENTIAL FUNCTIONS Builds, maintains and evolves general Extract, Transform and Load (ETL) data pipelines and overall data architecture to accommodate a growing amount of data from a variety of large research data sources. Works with research team members to convert business and technical requirements into professional software solutions. Ensures timely completion of tasks while managing multiple assignments, project timelines and business user expectations. Designs and implements custom research project-specific data workflow solutions for data collection, management, reporting and analytics. Contributes to the scientific research. Adheres to defined application development life-cycle practices, including but not limited to, requirements gathering, writing test plans, source code management, peer code review and quality assurance through unit/system/user acceptance testing. Participates in specification, implementation and execution of testing procedures to ensure quality of deliverables, system and data workflow reliability. Produces and maintains comprehensive technical documentation for all systems under the Engineer's responsibilities. Keeps abreast of current application developments through continuing education, professional reading, online forums, conferences, workshops and professional groups. Other duties as assigned. MINIMUM EDUCATION & EXPERIENCE Bachelor's degree in Data Science, Biomedical Science, Computer Science, Mathematics, Statistics or similar discipline and 2 years of experience in technology and data intensive roles and environments required Or equivalent combination of education and experience Programming experience in Structured Query Language (SQL) and one other applicable language (Java, Python, and/or R) required Experience with Change Management solutions required Experience with Version Control solutions (e.g. Git) required Experience implementing and supporting data management systems in a scientific, research context (e.g. biospecimen software, electronic laboratory notebooks, REDCap) preferred Experience with Linux, container and cloud technologies (e.g. HPC, IaaS and PaaS) preferred KNOWLEDGE, SKILLS AND ABILITIES Understanding of data analytics and statistical methods required Expertise of software engineering best practices such as version control and software release management required Strong analytical and problem-solving skills required Strong organizational skills required Ability to work with others in a matrix management environment required Excellent communication skills for describing progress and challenges to stakeholders required Attention to detail, patience and a positive, customer-centric attitude required Strong technical presentation skills required Demonstrated ability to develop proficiency with unfamiliar toolsets preferred Familiarity with file formats, metadata, and data exchange and storage standards applicable in management of scientific and clinical research required The University of Rochester is committed to fostering, cultivating, and preserving an inclusive and welcoming culture to advance the University’s Mission to Learn, Discover, Heal, Create – and Make the World Ever Better. In support of our values and those of our society, the University is committed to not discriminating on the basis of age, color, disability, ethnicity, gender identity or expression, genetic information, marital status, military/veteran status, national origin, race, religion, creed, sex, sexual orientation, citizenship status, or any other characteristic protected by federal, state, or local law (Protected Characteristics). This commitment extends to non-discrimination in the administration of our policies, admissions, employment, access, and recruitment of candidates, for all persons consistent with our values and based on applicable law. Notice: If you are a Current Employee, please log into myURHR to search for and apply to jobs using the Jobs Hub. Your application, if submitted using this portal, cannot be moved forward. Learn. Discover. Heal. Create. Located in western New York, Rochester is our namesake and our home. One of the world’s leading research universities, Rochester has a long tradition of breaking boundaries—always pushing and questioning, learning and unlearning. We transform ideas into enterprises that create value and make the world ever better. If you’re looking for a career in higher education or health care, the University of Rochester may offer the perfect opportunity for your background and goals. At the University of Rochester, we are committed to fostering, cultivating, and preserving an inclusive and welcoming culture and are united by a strong commitment to be ever better—Meliora. It is an ideal that informs our shared mission to ensure all members of our community feel safe, respected, included, and valued."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,"Data Engineer, Senior",Booz Allen Hamilton,"Data Engineer, Senior The Opportunity: As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to help support our nation's warfighters. As a client-facing data analyst on our national security team, you’ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you’ll also advise your client on what the information means and how it can be used to make an impact on our defense priorities. How You’ll Contribute: As a data analyst on our team, you’ll: Use your data analytics expertise to support client and stakeholder relationships. Research, develop, and test data methodologies, and generate cross-functional solutions through analysis and visualization of large data sets. Contribute to impactful work and guide decision-making across multiple organizations. Apply communication skills and data analytics expertise by simplifying technical requirements and trends, based on audience. Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages and Microsoft Office Suite. Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. Apply data visualization through different formats. Grow your communication and technical skills by creating data-centric solutions across mission areas. Work with us to drive large-scale business and process decisions through data insights. Join us. The world can’t wait. You Have: 3+ years of experience in a data engineering, application development, or data science field 3+ years of experience with designing, developing, operationalizing, and maintaining data applications for reporting and analytics at enterprise scale 3+ years of experience with Python, SQL, Scala, or R 2+ years of experience with data visualization or geospatial tools, such as Tableau, Qlik, Power BI, or ArcGIS Experience working in IC or DOD environments Experience creating solutions within a collaborative, cross-functional team environment TS/SCI clearance with a polygraph Bachelor's degree in a Computer Science, Data Science, or Mathematics field Nice If You Have: Experience with Palantir tools, such as Foundry or Gaia Experience with Large Language Models, including both applied and theoretical Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Note: Microsoft Internet Explorer is not fully compatible with Workday and users may experience systems issues with this browser. We recommend that you use one of the following browsers to avoid problems: Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari, Opera Browser or Blackberry Browser. If you continue to experience issues, it is sometimes necessary to reset your browser by clearing your cache. About Booz Allen Hamilton Booz Allen is an advanced technology company delivering outcomes with speed for America’s most critical defense, civil, and national security priorities. We build technology solutions using AI, cyber, and other cutting-edge technologies to advance and protect the nation and its citizens. By focusing on outcomes, we enable our people, clients, and their missions to succeed—accelerating the nation to realize our purpose: Empower People to Change the World®. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law. Know Your Rights Poster Accommodations If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of our employment process, please contact the Booz Allen Help Desk by calling 1-877-927-8278 or sending an email to helpdesk@bah.com. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries. Data Privacy For more information on how Booz Allen uses your information, please see our Careers Privacy Policy."
2025-12-12T00:00:00,Data Engineer II (Onsite),RTX,"Date Posted: 2025-12-12 Country: United States of America Location: PW147: PW OKC Campus 8120 S. Air Depot Blvd , Oklahoma City, OK, 73135 USA Position Role Type: Onsite U.S. Citizen, U.S. Person, or Immigration Status Requirements: U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Security Clearance: None/Not Required Pratt & Whitney is working to once again transform the future of flight—designing, building and servicing engines unlike any the world has ever seen. And because transformation begins from within, we’re seeking the people to drive it. So, calling all curious. Come ready to explore and you’ll find a place where your talent takes flight—beyond the borders of title, a country or your comfort zone. Bring your passion and commitment and we’ll welcome you into a tight-knit team that takes our mission personally. Channel your drive to make a difference into shaping an organization and an industry that’s evolving fast to the future. At Pratt & Whitney, the difference you make is on display every day. Just look up. Are you ready to go beyond? You will be an integral part of Pratt & Whitney’s Sustainment Operational Excellence Data Engineering & Analytics team. This team supports the global aftermarket maintenance and overhaul of engines for the F117, F119, and F135 programs. We are looking for a Data Engineer II to advance the digital and data capability of the Military Engines Global Depot Network organization. You will be working on exciting new technologies like cloud and open-source tools among others, and be responsible for cleaning, standardizing, transforming, and configuring data products within our emerging data mesh. What You Will Do: Create and maintain scripts written in Spark SQL or Pyspark in Databricks Notebooks. Also, work with SMEs to understand complex datasets for next generation data products and data visualizations to create data mesh tables. Develop scalable and sustainable data product transformations that curate, clean and store data efficiently; perform statistical analysis to quantify completeness and validity; perform bug fixes and apply enhancements to the models when the need arises. Ensure high performance and reliability of data transformation processes and pipelines. Collaborate cross-functionally to gather insights, refine requirements, and ensure alignment between product goals and team efforts. Document data processes, logic, and data sources to ensure transparency and knowledge sharing as well as support the overall team with any ad-hoc data related tasks. Work to convert our existing data visualizations in Power BI to use Databricks instead of Azure Synapse. Keep up to date with technologies and use advanced cloud data warehouse and data transformation techniques to build innovative solutions. Qualifications You Must Have: A degree in Science, Technology, Engineering or Mathematics (STEM) with 2+ years of experience in the use of SQL and/or Python to transform, clean, and integrate data from a variety of source pipelines. U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. Qualifications We Prefer: Experience with transformation tools such as dbt, Databricks pipelines, or relevant tools such as SSIS, ADF, or Matillion. Demonstrated experience with Git/GitHub; experience working in cloud data warehouses like Databricks. Familiarity with agile methodologies and Kanban boards. Self-motivated, team player with good communication skills. Ability to focus on results and successfully manage multiple tasks/projects. An astute individual, with the ability to build strong cross-functional relationships; excited at the prospect of developing and implementing new data products that add organizational value & improve decision making capabilities. Business experience with Aerospace or other heavy manufacturing industry. An understanding of ER Diagrams for data modeling. Demonstrated understanding of data mesh design principles and data engineering best practices. Learn More & Apply Now! What is my role type? In addition to transforming the future of flight, we are also transforming how and where we work. We’ve introduced role types to help you understand how you will operate in our blended work environment. This role is: Onsite: Employees who are working in Onsite roles will work primarily onsite. This includes all production and maintenance workers, as they are essential to the development of our engines. Candidates will learn more about role type and current site status throughout the recruiting process. For onsite and hybrid roles, commuting to and from the assigned site is the employee’s personal responsibility. As part of our commitment to maintaining a secure hiring process, candidates may be asked to attend select steps of the interview process in-person at one of our office locations, regardless of whether the role is designated as on-site, hybrid or remote. The salary range for this role is 66,000 USD - 130,000 USD. The salary range provided is a good faith estimate representative of all experience levels. RTX considers several factors when extending an offer, including but not limited to, the role, function and associated responsibilities, a candidate’s work experience, location, education/training, and key skills. Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement. Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company’s performance. This role is a U.S.-based role. If the successful candidate resides in a U.S. territory, the appropriate pay structure and benefits will apply. RTX anticipates the application window closing approximately 40 days from the date the notice was posted. However, factors such as candidate flow and business necessity may require RTX to shorten or extend the application window. RTX is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or veteran status, or any other applicable state or federal protected class. RTX provides affirmative action in employment for qualified Individuals with a Disability and Protected Veterans in compliance with Section 503 of the Rehabilitation Act and the Vietnam Era Veterans’ Readjustment Assistance Act. Privacy Policy and Terms: Click on this link to read the Policy and Terms RTX is an aerospace and defense company that provides advanced systems and services for commercial, military and government customers worldwide. It comprises three industry-leading businesses – Collins Aerospace, Pratt & Whitney, and Raytheon. Its 195,000 employees enable the company to operate at the edge of known science as they imagine and deliver solutions that push the boundaries in quantum physics, electric propulsion, directed energy, hypersonics, avionics and cybersecurity. The company, formed in 2020 through the combination of Raytheon Company and the United Technologies Corporation aerospace businesses, is headquartered in Arlington, Virginia."
2025-12-12T00:00:00,"Senior Engineer, BAW R&D Trimming and Data Infrastructure",Qorvo,"
                Qorvo (Nasdaq: QRVO) supplies innovative semiconductor solutions that make a better world possible. We combine product and technology leadership, systems-level expertise and global manufacturing scale to quickly solve our customers' most complex technical challenges. Qorvo serves multiple high-growth segments of large global markets, including consumer electronics, smart home/IoT, automotive, EVs, battery-powered appliances, network infrastructure, healthcare and aerospace/defense. Visit www.qorvo.com to learn how our innovative team is helping connect, protect and power our planet.

 
Summary:
 Qorvo’s BAW R&D Data Infrastructure team is seeking a talented engineer for semiconductor data infrastructure, frequency trimming and process automation. The candidate chosen for this role will develop data infrastructure and software tools to support efficient development and production of new Bulk Acoustic Wave (BAW) filter technologies. The candidate will use MATLAB, data analysis tools (SpotFire), databases and other software tools for process control improvements, faster design cycles, and general automation to efficiently develop and produce new technologies.
 
Key Roles and responsibilities:

Research, implement, deploy, and maintain internal software applications used by Manufacturing and R&D Engineering teams to process and trim BAW filters wafers.
Work closely with Process Integration and Process Engineering teams to understand new BAW technology needs to define requirements and implement.
Provide comprehensive support to internal customers: resolve outstanding issues for R&D engineers, designers, and production at Qorvo’s fabrication facility.
Own critical data infrastructure projects and successfully deliver results in a timely manner

 
Technical Knowledge/Skills/Abilities Required:

Excellent MATLAB or Python programming capabilities
Knowledge of semiconductor processing
Practical knowledge of software development and object-oriented programming
Excellent debugging and problem-solving skills


Strong data analysis and mathematical skills


Experience with version control utilizing Git and GitLab
Good knowledge of SQL database (Oracle is a plus)
Experience in the full life cycle of the software design process including requirement analysis, design, prototyping, coding, documentation, implementation, and maintenance

 
Personal Skills:

Self-motivated, independent, proactive, detail oriented, and responsible team-player
Excellent analytical skills
Comfortable working in a dynamic and fast paced environment
Passion for innovation and emerging technologies
Excellent communication and interpersonal skills
Able to handle multiple priorities
Proficient in English

 
Desired experiences:

Experience with software development for semiconductor processing 
Expertise in electromagnetics, physics, or material science
Expertise in Oracle PL/SQL databases
Experience with data analysis tools such as Spotfire or similar application
Experience with GitLab workflows and pipeline automation 
Experience with Visual Studio Code and GitHub Copilot
Experience with unit testing in past development projects

 
Qualifications:
Education & Experience:

BS or MS in Computer Science, Electrical Engineering, Physics or Material Science
5+ years of code development experience.(or if Master's degree 2+ years experience)

 
This position is not eligible for visa sponsorship by the Company.
 
#LI-KR1
 MAKE A DIFFERENCE AT QORVO   

 We are Qorvo. We do more than create innovative RF and Power solutions for the mobile, defense and infrastructure markets – we are a place to innovate and shape the future of wireless communications. It starts with our employees. As a unified global team, we bring a commitment to excellence, growth and a passion for creating what's next. Explore the possibilities with us.

We are an Equal Employment Opportunity (EEO) employer and welcome all qualified applicants. Applicants will receive fair and impartial consideration without regard to any characteristics protected by applicable law, including race, color, religion, sex (as defined by law), national origin, age, military or veteran status, genetic information, or disability.  
                
    "
